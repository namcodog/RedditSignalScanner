"""
é›†æˆæµ‹è¯•ï¼šéªŒè¯å¢é‡çˆ¬è™«çš„å†·çƒ­åŒå†™åŠŸèƒ½

æµ‹è¯•åœºæ™¯ï¼š
1. é€šè¿‡ IncrementalCrawler è§¦å‘çˆ¬å–
2. éªŒè¯ posts_raw (å†·åº“) æœ‰æ•°æ®
3. éªŒè¯ posts_hot (çƒ­åº“) æœ‰æ•°æ®
4. éªŒè¯ç‰ˆæœ¬æ§åˆ¶æ­£ç¡®
5. éªŒè¯å»é‡é€»è¾‘æ­£ç¡®
"""
import asyncio
from datetime import datetime, timezone
from typing import List

import pytest
from sqlalchemy import select, text
from sqlalchemy.ext.asyncio import AsyncSession

from app.db.session import SessionFactory
from app.models.community_cache import CommunityCache
from app.models.posts_storage import PostHot, PostRaw
from app.services.incremental_crawler import IncrementalCrawler
from app.services.reddit_client import RedditAPIClient, RedditPost


class MockRedditClient(RedditAPIClient):
    """Mock Reddit å®¢æˆ·ç«¯ï¼Œè¿”å›æµ‹è¯•æ•°æ®"""

    def __init__(self):
        # ä¸è°ƒç”¨çˆ¶ç±» __init__ï¼Œé¿å…çœŸå® API åˆå§‹åŒ–
        self.mock_posts: List[RedditPost] = []
        # æ·»åŠ å¿…è¦çš„å±æ€§ä»¥é¿å… AttributeError
        self.access_token = "mock_token"
        self.token_expires_at = None

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        pass

    def set_mock_posts(self, posts: List[RedditPost]) -> None:
        """è®¾ç½® mock æ•°æ®"""
        self.mock_posts = posts

    async def authenticate(self) -> None:
        """Mock è®¤è¯ï¼Œä¸åšä»»ä½•äº‹"""
        pass

    async def fetch_subreddit_posts(
        self,
        subreddit: str,
        *,
        limit: int = 100,
        time_filter: str = "week",
        sort: str = "top",
    ) -> List[RedditPost]:
        """è¿”å› mock æ•°æ®"""
        return self.mock_posts

    async def get_hot_posts(
        self,
        subreddit: str,
        limit: int = 100,
        time_filter: str = "day",
    ) -> List[RedditPost]:
        """è¿”å› mock æ•°æ®"""
        return self.mock_posts


@pytest.fixture
async def db_session():
    """æä¾›æµ‹è¯•æ•°æ®åº“ä¼šè¯"""
    async with SessionFactory() as session:
        yield session


@pytest.fixture
async def mock_reddit_client():
    """æä¾› mock Reddit å®¢æˆ·ç«¯"""
    client = MockRedditClient()
    return client


@pytest.fixture
async def cleanup_test_data(db_session: AsyncSession):
    """æ¸…ç†æµ‹è¯•æ•°æ®"""
    # æµ‹è¯•å‰æ¸…ç†
    await db_session.execute(
        text("DELETE FROM posts_raw WHERE subreddit = 'test_integration'")
    )
    await db_session.execute(
        text("DELETE FROM posts_hot WHERE subreddit = 'test_integration'")
    )
    await db_session.execute(
        text(
            "DELETE FROM community_cache WHERE community_name = 'test_integration'"
        )
    )
    await db_session.commit()

    yield

    # æµ‹è¯•åæ¸…ç†
    await db_session.execute(
        text("DELETE FROM posts_raw WHERE subreddit = 'test_integration'")
    )
    await db_session.execute(
        text("DELETE FROM posts_hot WHERE subreddit = 'test_integration'")
    )
    await db_session.execute(
        text(
            "DELETE FROM community_cache WHERE community_name = 'test_integration'"
        )
    )
    await db_session.commit()


@pytest.mark.asyncio
async def test_incremental_crawler_dual_write(
    db_session: AsyncSession,
    mock_reddit_client: MockRedditClient,
    cleanup_test_data,
):
    """æµ‹è¯•å¢é‡çˆ¬è™«çš„å†·çƒ­åŒå†™åŠŸèƒ½"""
    print("\n" + "=" * 70)
    print("ğŸ§ª é›†æˆæµ‹è¯•ï¼šå¢é‡çˆ¬è™«å†·çƒ­åŒå†™")
    print("=" * 70)

    # 1. å‡†å¤‡ mock æ•°æ®
    test_community = "test_integration"
    now = datetime.now(timezone.utc)
    mock_posts = [
        RedditPost(
            id="post_001",
            title="Test Post 1",
            selftext="This is test post 1",
            author="test_author_1",
            created_utc=now.timestamp(),
            score=100,
            num_comments=10,
            url="https://reddit.com/r/test/post_001",
            permalink="/r/test/comments/post_001",
            subreddit=test_community,
        ),
        RedditPost(
            id="post_002",
            title="Test Post 2",
            selftext="This is test post 2",
            author="test_author_2",
            created_utc=now.timestamp() + 100,
            score=200,
            num_comments=20,
            url="https://reddit.com/r/test/post_002",
            permalink="/r/test/comments/post_002",
            subreddit=test_community,
        ),
        RedditPost(
            id="post_003",
            title="Test Post 3",
            selftext="This is test post 3",
            author="test_author_3",
            created_utc=now.timestamp() + 200,
            score=300,
            num_comments=30,
            url="https://reddit.com/r/test/post_003",
            permalink="/r/test/comments/post_003",
            subreddit=test_community,
        ),
    ]
    mock_reddit_client.set_mock_posts(mock_posts)

    print(f"\nğŸ“ å‡†å¤‡äº† {len(mock_posts)} æ¡ mock å¸–å­")

    # 2. åˆ›å»ºå¢é‡çˆ¬è™«å¹¶æ‰§è¡Œ
    crawler = IncrementalCrawler(
        db=db_session,
        reddit_client=mock_reddit_client,
        hot_cache_ttl_hours=24,
    )

    print(f"\nğŸš€ å¼€å§‹çˆ¬å–ç¤¾åŒº: {test_community}")
    result = await crawler.crawl_community_incremental(
        community_name=test_community,
        limit=100,
        time_filter="day",
        sort="hot",
    )

    print(f"\nâœ… çˆ¬å–å®Œæˆ:")
    print(f"   - æ–°å¸–å­: {result['new_posts']}")
    print(f"   - æ›´æ–°å¸–å­: {result['updated_posts']}")
    print(f"   - é‡å¤å¸–å­: {result['duplicates']}")
    print(f"   - æ°´ä½çº¿æ›´æ–°: {result['watermark_updated']}")

    # 3. éªŒè¯å†·åº“ (posts_raw)
    print("\n" + "=" * 70)
    print("1ï¸âƒ£  éªŒè¯å†·åº“ (posts_raw)")
    print("=" * 70)

    cold_result = await db_session.execute(
        select(PostRaw).where(PostRaw.subreddit == test_community)
    )
    cold_posts = cold_result.scalars().all()

    print(f"\nâœ… å†·åº“è®°å½•æ•°: {len(cold_posts)}")
    assert len(cold_posts) == 3, f"æœŸæœ›3æ¡è®°å½•ï¼Œå®é™…{len(cold_posts)}æ¡"

    for post in cold_posts:
        print(f"\n   ğŸ“„ Post ID: {post.source_post_id}")
        print(f"      - Version: {post.version}")
        print(f"      - Title: {post.title}")
        print(f"      - Score: {post.score}")
        print(f"      - Comments: {post.num_comments}")
        print(f"      - Is Current: {post.is_current}")

        # éªŒè¯å­—æ®µ
        assert post.source == "reddit"
        assert post.version == 1
        assert post.is_current is True
        assert post.score > 0
        assert post.num_comments > 0

    # 4. éªŒè¯çƒ­åº“ (posts_hot)
    print("\n" + "=" * 70)
    print("2ï¸âƒ£  éªŒè¯çƒ­åº“ (posts_hot)")
    print("=" * 70)

    hot_result = await db_session.execute(
        select(PostHot).where(PostHot.subreddit == test_community)
    )
    hot_posts = hot_result.scalars().all()

    print(f"\nâœ… çƒ­åº“è®°å½•æ•°: {len(hot_posts)}")
    assert len(hot_posts) == 3, f"æœŸæœ›3æ¡è®°å½•ï¼Œå®é™…{len(hot_posts)}æ¡"

    for post in hot_posts:
        print(f"\n   ğŸ“„ Post ID: {post.source_post_id}")
        print(f"      - Title: {post.title}")
        print(f"      - Score: {post.score}")
        print(f"      - Comments: {post.num_comments}")
        print(f"      - Expires At: {post.expires_at}")

        # éªŒè¯å­—æ®µ
        assert post.source == "reddit"
        assert post.score > 0
        assert post.num_comments > 0
        assert post.expires_at > now

    # 5. éªŒè¯æ°´ä½çº¿
    print("\n" + "=" * 70)
    print("3ï¸âƒ£  éªŒè¯æ°´ä½çº¿ (community_cache)")
    print("=" * 70)

    watermark_result = await db_session.execute(
        select(CommunityCache).where(
            CommunityCache.community_name == test_community
        )
    )
    watermark = watermark_result.scalar_one_or_none()

    assert watermark is not None, "æ°´ä½çº¿åº”è¯¥å­˜åœ¨"
    print(f"\nâœ… æ°´ä½çº¿è®°å½•:")
    print(f"   - Community: {watermark.community_name}")
    print(f"   - Last Seen Post ID: {watermark.last_seen_post_id}")
    print(f"   - Last Seen Created At: {watermark.last_seen_created_at}")
    print(f"   - Total Posts Fetched: {watermark.total_posts_fetched}")
    print(f"   - Dedup Rate: {watermark.dedup_rate:.2f}%")

    assert watermark.last_seen_post_id == "post_003"
    assert watermark.total_posts_fetched == 3

    print("\n" + "=" * 70)
    print("ğŸ‰ é›†æˆæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
    print("=" * 70)


if __name__ == "__main__":
    asyncio.run(
        test_incremental_crawler_dual_write(
            db_session=SessionFactory(),
            mock_reddit_client=MockRedditClient(),
            cleanup_test_data=None,
        )
    )

