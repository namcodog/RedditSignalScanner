#!/usr/bin/env python3
"""
æŠ½æ · 200 æ¡å¸–å­ç”¨äºäººå·¥æ ‡æ³¨

åŸºäº Spec 007 User Story 5 (US5) - Task T052
ä» posts_raw è¡¨ä¸­æŠ½æ · 200 æ¡å¸–å­ï¼Œç”¨äºé˜ˆå€¼æ ¡å‡†çš„äººå·¥æ ‡æ³¨

æŠ½æ ·ç­–ç•¥ï¼š
1. åªæŠ½å–æœ€è¿‘ 30 å¤©çš„å¸–å­ï¼ˆä¿è¯æ—¶æ•ˆæ€§ï¼‰
2. åªæŠ½å– is_current=True çš„å¸–å­ï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰
3. æŒ‰ score åˆ†å±‚æŠ½æ ·ï¼šé«˜åˆ†ï¼ˆ50æ¡ï¼‰ã€ä¸­åˆ†ï¼ˆ100æ¡ï¼‰ã€ä½åˆ†ï¼ˆ50æ¡ï¼‰
4. ç¡®ä¿å¤šæ ·æ€§ï¼šè¦†ç›–ä¸åŒ subreddit

ç”¨æ³•:
    python scripts/sample_posts_for_annotation.py
    python scripts/sample_posts_for_annotation.py --output data/annotations/sample_200.csv
"""
import asyncio
import csv
import sys
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
backend_dir = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(backend_dir))

from sqlalchemy import func, select
from sqlalchemy.ext.asyncio import AsyncSession

from app.db.session import get_session_context
from app.models.posts_storage import PostRaw


async def sample_posts(
    *,
    total_samples: int = 200,
    days_back: int = 30,
    high_score_threshold: int = 100,
    low_score_threshold: int = 10,
) -> List[PostRaw]:
    """ä»æ•°æ®åº“ä¸­æŠ½æ ·å¸–å­
    
    Args:
        total_samples: æ€»æŠ½æ ·æ•°é‡ï¼ˆé»˜è®¤ 200ï¼‰
        days_back: æŠ½æ ·æ—¶é—´èŒƒå›´ï¼ˆé»˜è®¤æœ€è¿‘ 30 å¤©ï¼‰
        high_score_threshold: é«˜åˆ†é˜ˆå€¼ï¼ˆé»˜è®¤ 100ï¼‰
        low_score_threshold: ä½åˆ†é˜ˆå€¼ï¼ˆé»˜è®¤ 10ï¼‰
    
    Returns:
        List[PostRaw]: æŠ½æ ·çš„å¸–å­åˆ—è¡¨
    """
    async with get_session_context() as session:
        # è®¡ç®—æ—¶é—´èŒƒå›´
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=days_back)
        
        # åˆ†å±‚æŠ½æ ·æ•°é‡
        high_score_count = int(total_samples * 0.25)  # 25% é«˜åˆ†
        mid_score_count = int(total_samples * 0.50)   # 50% ä¸­åˆ†
        low_score_count = total_samples - high_score_count - mid_score_count  # 25% ä½åˆ†
        
        # åŸºç¡€æŸ¥è¯¢æ¡ä»¶ï¼ˆæ’é™¤æµ‹è¯•æ•°æ®ï¼‰
        base_query = (
            select(PostRaw)
            .where(
                PostRaw.is_current.is_(True),
                PostRaw.created_at >= cutoff_date,
                PostRaw.title.isnot(None),
                PostRaw.title != "",
                ~PostRaw.subreddit.like('r/test_%'),  # æ’é™¤æµ‹è¯•æ•°æ®
            )
        )
        
        # 1. æŠ½æ ·é«˜åˆ†å¸–å­ï¼ˆscore >= high_score_thresholdï¼‰
        high_score_query = (
            base_query
            .where(PostRaw.score >= high_score_threshold)
            .order_by(func.random())
            .limit(high_score_count)
        )
        high_score_posts = (await session.execute(high_score_query)).scalars().all()
        
        # 2. æŠ½æ ·ä¸­åˆ†å¸–å­ï¼ˆlow_score_threshold <= score < high_score_thresholdï¼‰
        mid_score_query = (
            base_query
            .where(
                PostRaw.score >= low_score_threshold,
                PostRaw.score < high_score_threshold,
            )
            .order_by(func.random())
            .limit(mid_score_count)
        )
        mid_score_posts = (await session.execute(mid_score_query)).scalars().all()
        
        # 3. æŠ½æ ·ä½åˆ†å¸–å­ï¼ˆscore < low_score_thresholdï¼‰
        low_score_query = (
            base_query
            .where(PostRaw.score < low_score_threshold)
            .order_by(func.random())
            .limit(low_score_count)
        )
        low_score_posts = (await session.execute(low_score_query)).scalars().all()
        
        # åˆå¹¶æ‰€æœ‰æŠ½æ ·ç»“æœ
        all_posts = list(high_score_posts) + list(mid_score_posts) + list(low_score_posts)
        
        print(f"âœ… æŠ½æ ·å®Œæˆ:")
        print(f"   - é«˜åˆ†å¸–å­ (score >= {high_score_threshold}): {len(high_score_posts)} æ¡")
        print(f"   - ä¸­åˆ†å¸–å­ ({low_score_threshold} <= score < {high_score_threshold}): {len(mid_score_posts)} æ¡")
        print(f"   - ä½åˆ†å¸–å­ (score < {low_score_threshold}): {len(low_score_posts)} æ¡")
        print(f"   - æ€»è®¡: {len(all_posts)} æ¡")
        
        return all_posts


def export_to_csv(posts: List[PostRaw], output_path: Path):
    """å¯¼å‡ºå¸–å­åˆ° CSV æ–‡ä»¶
    
    Args:
        posts: å¸–å­åˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # å†™å…¥ CSV
    with open(output_path, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(
            f,
            fieldnames=[
                "post_id",
                "subreddit",
                "title",
                "body",
                "score",
                "num_comments",
                "created_at",
                "url",
                "label",
                "strength",
                "notes",
            ],
        )
        writer.writeheader()
        
        for post in posts:
            # æ„é€  Reddit URL
            reddit_url = post.url or f"https://reddit.com/r/{post.subreddit}/comments/{post.source_post_id}"
            
            writer.writerow({
                "post_id": post.source_post_id,
                "subreddit": post.subreddit,
                "title": post.title,
                "body": (post.body or "")[:500],  # é™åˆ¶ body é•¿åº¦ï¼Œé¿å… CSV è¿‡å¤§
                "score": post.score,
                "num_comments": post.num_comments,
                "created_at": post.created_at.isoformat() if post.created_at else "",
                "url": reddit_url,
                "label": "",  # å¾…äººå·¥æ ‡æ³¨
                "strength": "",  # å¾…äººå·¥æ ‡æ³¨
                "notes": "",  # å¾…äººå·¥æ ‡æ³¨
            })
    
    print(f"âœ… å·²å¯¼å‡ºåˆ°: {output_path}")
    print(f"   - æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024:.2f} KB")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse

    # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆbackend çš„çˆ¶ç›®å½•ï¼‰
    project_root = backend_dir.parent
    default_output = project_root / "data" / "annotations" / "sample_200.csv"

    parser = argparse.ArgumentParser(description="æŠ½æ ·å¸–å­ç”¨äºäººå·¥æ ‡æ³¨")
    parser.add_argument(
        "--output",
        type=Path,
        default=default_output,
        help=f"è¾“å‡º CSV æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: {default_output}ï¼‰",
    )
    parser.add_argument(
        "--count",
        type=int,
        default=200,
        help="æŠ½æ ·æ•°é‡ï¼ˆé»˜è®¤: 200ï¼‰",
    )
    parser.add_argument(
        "--days",
        type=int,
        default=30,
        help="æŠ½æ ·æ—¶é—´èŒƒå›´ï¼ˆå¤©æ•°ï¼Œé»˜è®¤: 30ï¼‰",
    )
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("ğŸ“Š æŠ½æ ·å¸–å­ç”¨äºäººå·¥æ ‡æ³¨")
    print("=" * 80)
    print()
    print(f"ğŸ“‹ é…ç½®:")
    print(f"   - æŠ½æ ·æ•°é‡: {args.count}")
    print(f"   - æ—¶é—´èŒƒå›´: æœ€è¿‘ {args.days} å¤©")
    print(f"   - è¾“å‡ºæ–‡ä»¶: {args.output}")
    print()
    
    # æŠ½æ ·å¸–å­
    posts = await sample_posts(
        total_samples=args.count,
        days_back=args.days,
    )
    
    if not posts:
        print("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¸–å­")
        return 1
    
    # å¯¼å‡ºåˆ° CSV
    export_to_csv(posts, args.output)
    
    print()
    print("=" * 80)
    print("âœ… æŠ½æ ·å®Œæˆ")
    print("=" * 80)
    print()
    print("ğŸ“ ä¸‹ä¸€æ­¥:")
    print(f"   1. æ‰“å¼€æ–‡ä»¶: {args.output}")
    print("   2. äººå·¥æ ‡æ³¨ label åˆ—ï¼ˆopportunity / non-opportunityï¼‰")
    print("   3. äººå·¥æ ‡æ³¨ strength åˆ—ï¼ˆstrong / medium / weakï¼‰")
    print("   4. å¯é€‰ï¼šåœ¨ notes åˆ—æ·»åŠ å¤‡æ³¨")
    print()
    
    return 0


if __name__ == "__main__":
    sys.exit(asyncio.run(main()))

