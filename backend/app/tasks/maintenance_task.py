"""
ç»´æŠ¤ä»»åŠ¡ï¼šæ•°æ®åº“æ¸…ç†ã€å¤‡ä»½ç­‰

åŒ…å«:
- refresh_posts_latest: åˆ·æ–° posts_latest ç‰©åŒ–è§†å›¾
- cleanup_expired_posts_hot: æ¸…ç†è¿‡æœŸçš„ posts_hot æ•°æ®
- cleanup_old_posts: æ¸…ç†è¶…è¿‡ä¿ç•™æœŸçš„ posts_raw å†·æ•°æ®
- collect_storage_metrics: é‡‡é›†å­˜å‚¨å±‚æŒ‡æ ‡å¿«ç…§
- archive_old_posts: å°†å†å²ç‰ˆæœ¬å½’æ¡£è‡³ posts_archive
- check_storage_capacity: æ£€æŸ¥æ•°æ®åº“å®¹é‡å¹¶é¢„è­¦
"""
from __future__ import annotations

import logging
import os
from datetime import datetime, timezone
from typing import Any

from celery.utils.log import get_task_logger  # type: ignore[import-untyped]
from sqlalchemy import text

from app.core.celery_app import celery_app
from app.db.session import SessionFactory

logger = get_task_logger(__name__)
_MODULE_LOGGER = logging.getLogger(__name__)

DEFAULT_STORAGE_CAPACITY_THRESHOLD_GB = float(
    os.getenv("STORAGE_CAPACITY_THRESHOLD_GB", "50")
)

async def refresh_posts_latest_impl() -> dict[str, Any]:
    """
    åˆ·æ–° posts_latest ç‰©åŒ–è§†å›¾çš„å®ç°å‡½æ•°ã€‚
    """
    start_time = datetime.now(timezone.utc)

    async with SessionFactory() as db:
        result = await db.execute(
            text("SELECT refresh_posts_latest() AS refreshed_count")
        )
        refreshed_count = int(result.scalar() or 0)
        await db.commit()

    duration = (datetime.now(timezone.utc) - start_time).total_seconds()
    _MODULE_LOGGER.info(
        "ğŸ”„ posts_latest ç‰©åŒ–è§†å›¾åˆ·æ–°å®Œæˆ: count=%s, duration=%.2fs",
        refreshed_count,
        duration,
    )
    return {
        "status": "completed",
        "refreshed_count": refreshed_count,
        "duration_seconds": duration,
    }


@celery_app.task(name="tasks.maintenance.refresh_posts_latest")  # type: ignore[misc]
def refresh_posts_latest() -> dict[str, Any]:
    """
    Celery ä»»åŠ¡ï¼šåˆ·æ–° posts_latest ç‰©åŒ–è§†å›¾ã€‚
    """
    import asyncio

    logger.info("ğŸ”„ å¼€å§‹æ‰§è¡Œ posts_latest ç‰©åŒ–è§†å›¾åˆ·æ–°ä»»åŠ¡")
    result = asyncio.run(refresh_posts_latest_impl())
    logger.info("âœ… ç‰©åŒ–è§†å›¾åˆ·æ–°ä»»åŠ¡å®Œæˆ: %s", result)
    return result


async def cleanup_expired_posts_hot_impl() -> dict[str, Any]:
    """
    æ¸…ç†è¿‡æœŸçš„ posts_hot æ•°æ®ï¼ˆå®ç°å‡½æ•°ï¼‰ã€‚
    """
    start_time = datetime.now(timezone.utc)

    async with SessionFactory() as db:
        result = await db.execute(
            text("SELECT cleanup_expired_hot_cache() AS deleted_count")
        )
        await db.commit()

    deleted_count = int(result.scalar() or 0)
    duration = (datetime.now(timezone.utc) - start_time).total_seconds()

    _MODULE_LOGGER.info(
        "ğŸ§¹ posts_hot æ¸…ç†å®Œæˆ: deleted=%s, duration=%.2fs",
        deleted_count,
        duration,
    )

    return {
        "status": "completed",
        "deleted_count": deleted_count,
        "duration_seconds": duration,
    }


@celery_app.task(name="tasks.maintenance.cleanup_expired_posts_hot")  # type: ignore[misc]
def cleanup_expired_posts_hot() -> dict[str, Any]:
    """
    Celery ä»»åŠ¡: æ¸…ç†è¿‡æœŸçš„ posts_hot æ•°æ®ã€‚
    """
    import asyncio
    
    logger.info("ğŸ§¹ å¼€å§‹æ‰§è¡Œ posts_hot æ¸…ç†ä»»åŠ¡")
    result = asyncio.run(cleanup_expired_posts_hot_impl())
    logger.info(f"âœ… æ¸…ç†ä»»åŠ¡å®Œæˆ: {result}")
    
    return result


async def collect_storage_metrics_impl() -> dict[str, Any]:
    """é‡‡é›†å¹¶å†™å…¥ storage_metrics è¡¨çš„å®ç°å‡½æ•°ã€‚"""
    start_time = datetime.now(timezone.utc)

    async with SessionFactory() as db:
        metrics_result = await db.execute(text("SELECT metric, value FROM get_storage_stats()"))
        stats = {row.metric: int(row.value) for row in metrics_result}

        posts_raw_total = stats.get("posts_raw_total", 0)
        posts_raw_current = stats.get("posts_raw_current", 0)
        posts_hot_total = stats.get("posts_hot_total", 0)
        posts_hot_expired = stats.get("posts_hot_expired", 0)
        unique_subreddits = stats.get("unique_subreddits", 0)
        total_versions = stats.get("total_versions", 0)

        duplicates = posts_raw_total - posts_raw_current
        dedup_rate = duplicates / posts_raw_total if posts_raw_total else 0.0

        insert_result = await db.execute(
            text(
                """
                INSERT INTO storage_metrics (
                    posts_raw_total,
                    posts_raw_current,
                    posts_hot_total,
                    posts_hot_expired,
                    unique_subreddits,
                    total_versions,
                    dedup_rate
                )
                VALUES (
                    :posts_raw_total,
                    :posts_raw_current,
                    :posts_hot_total,
                    :posts_hot_expired,
                    :unique_subreddits,
                    :total_versions,
                    :dedup_rate
                )
                RETURNING id, collected_at
                """
            ),
            {
                "posts_raw_total": posts_raw_total,
                "posts_raw_current": posts_raw_current,
                "posts_hot_total": posts_hot_total,
                "posts_hot_expired": posts_hot_expired,
                "unique_subreddits": unique_subreddits,
                "total_versions": total_versions,
                "dedup_rate": round(dedup_rate, 6),
            },
        )
        inserted = insert_result.one()
        await db.commit()

    duration = (datetime.now(timezone.utc) - start_time).total_seconds()
    snapshot = {
        "status": "completed",
        "id": int(inserted.id),
        "collected_at": inserted.collected_at.isoformat(),
        "posts_raw_total": posts_raw_total,
        "posts_raw_current": posts_raw_current,
        "posts_hot_total": posts_hot_total,
        "posts_hot_expired": posts_hot_expired,
        "unique_subreddits": unique_subreddits,
        "total_versions": total_versions,
        "dedup_rate": round(dedup_rate, 6),
        "duration_seconds": duration,
    }
    _MODULE_LOGGER.info("ğŸ“Š å­˜å‚¨æŒ‡æ ‡é‡‡é›†å®Œæˆ: %s", snapshot)
    return snapshot


@celery_app.task(name="tasks.maintenance.collect_storage_metrics")  # type: ignore[misc]
def collect_storage_metrics() -> dict[str, Any]:
    """Celery ä»»åŠ¡ï¼šé‡‡é›†å­˜å‚¨å±‚è´¨é‡æŒ‡æ ‡ã€‚"""
    import asyncio

    logger.info("ğŸ“Š å¼€å§‹é‡‡é›†å­˜å‚¨å±‚æŒ‡æ ‡")
    result = asyncio.run(collect_storage_metrics_impl())
    logger.info("âœ… å­˜å‚¨å±‚æŒ‡æ ‡é‡‡é›†å®Œæˆ: %s", result)
    return result


async def cleanup_old_posts_impl(retention_days: int = 90) -> dict[str, Any]:
    """
    æ¸…ç† posts_raw ä¸­è¶…è¿‡ä¿ç•™æœŸçš„å†å²æ•°æ®ã€‚
    """
    start_time = datetime.now(timezone.utc)

    async with SessionFactory() as db:
        result = await db.execute(
            text("SELECT cleanup_old_posts(:retention_days) AS deleted_count"),
            {"retention_days": retention_days},
        )
        await db.commit()

    deleted_count = int(result.scalar() or 0)
    duration = (datetime.now(timezone.utc) - start_time).total_seconds()
    _MODULE_LOGGER.info(
        "ğŸ§Š posts_raw å†·åº“æ¸…ç†å®Œæˆ: retention=%s, deleted=%s, duration=%.2fs",
        retention_days,
        deleted_count,
        duration,
    )

    return {
        "status": "completed",
        "retention_days": retention_days,
        "deleted_count": deleted_count,
        "duration_seconds": duration,
    }


@celery_app.task(name="tasks.maintenance.cleanup_old_posts")  # type: ignore[misc]
def cleanup_old_posts(retention_days: int = 90) -> dict[str, Any]:
    """
    Celery ä»»åŠ¡ï¼šæ¸…ç†è¶…è¿‡ä¿ç•™æœŸçš„ posts_raw å†·æ•°æ®ã€‚
    """
    import asyncio

    logger.info("ğŸ§Š å¼€å§‹æ‰§è¡Œ posts_raw å†·åº“æ¸…ç†ä»»åŠ¡ (retention=%s å¤©)", retention_days)
    result = asyncio.run(cleanup_old_posts_impl(retention_days=retention_days))
    logger.info("âœ… å†·åº“æ¸…ç†ä»»åŠ¡å®Œæˆ: %s", result)
    return result


async def archive_old_posts_impl(
    retention_days: int = 90, batch_size: int = 1000
) -> dict[str, Any]:
    """å°†å†å²ç‰ˆæœ¬å½’æ¡£è‡³ posts_archiveã€‚"""
    start_time = datetime.now(timezone.utc)

    async with SessionFactory() as db:
        result = await db.execute(
            text(
                "SELECT archive_old_posts(:retention_days, :batch_size) AS archived_count"
            ),
            {"retention_days": retention_days, "batch_size": batch_size},
        )
        await db.commit()

    archived_count = int(result.scalar() or 0)
    duration = (datetime.now(timezone.utc) - start_time).total_seconds()
    payload = {
        "status": "completed",
        "retention_days": retention_days,
        "batch_size": batch_size,
        "archived_count": archived_count,
        "duration_seconds": duration,
    }
    _MODULE_LOGGER.info("ğŸ—„ï¸ å½’æ¡£ä»»åŠ¡å®Œæˆ: %s", payload)
    return payload


@celery_app.task(name="tasks.maintenance.archive_old_posts")  # type: ignore[misc]
def archive_old_posts(retention_days: int = 90, batch_size: int = 1000) -> dict[str, Any]:
    """Celery ä»»åŠ¡ï¼šå½’æ¡£å†å²ç‰ˆæœ¬æ•°æ®ã€‚"""
    import asyncio

    logger.info(
        "ğŸ—„ï¸ å¼€å§‹æ‰§è¡Œ posts_raw å½’æ¡£ä»»åŠ¡ (retention=%s, batch=%s)",
        retention_days,
        batch_size,
    )
    result = asyncio.run(
        archive_old_posts_impl(retention_days=retention_days, batch_size=batch_size)
    )
    logger.info("âœ… å½’æ¡£ä»»åŠ¡å®Œæˆ: %s", result)
    return result


async def check_storage_capacity_impl(
    threshold_gb: float | None = None,
) -> dict[str, Any]:
    """æ£€æŸ¥æ•°æ®åº“å®¹é‡å¹¶è¿”å›è¯„ä¼°ç»“æœã€‚"""
    threshold = (
        threshold_gb
        if threshold_gb is not None
        else DEFAULT_STORAGE_CAPACITY_THRESHOLD_GB
    )

    async with SessionFactory() as db:
        result = await db.execute(
            text(
                """
                SELECT
                    pg_database_size(current_database()) AS database_size,
                    pg_total_relation_size('posts_raw'::regclass) AS posts_raw_size,
                    pg_total_relation_size('posts_hot'::regclass) AS posts_hot_size
                """
            )
        )
        row = result.one()

    database_size_gb = row.database_size / 1024**3
    posts_raw_size_gb = row.posts_raw_size / 1024**3
    posts_hot_size_gb = row.posts_hot_size / 1024**3
    above_threshold = database_size_gb >= threshold

    payload = {
        "status": "alert" if above_threshold else "ok",
        "database_size_gb": round(database_size_gb, 3),
        "posts_raw_size_gb": round(posts_raw_size_gb, 3),
        "posts_hot_size_gb": round(posts_hot_size_gb, 3),
        "threshold_gb": threshold,
    }

    if above_threshold:
        _MODULE_LOGGER.warning("âš ï¸ æ•°æ®åº“å®¹é‡æ¥è¿‘é˜ˆå€¼: %s", payload)
    else:
        _MODULE_LOGGER.info("ğŸ“¦ æ•°æ®åº“å®¹é‡æ£€æŸ¥é€šè¿‡: %s", payload)
    return payload


@celery_app.task(name="tasks.maintenance.check_storage_capacity")  # type: ignore[misc]
def check_storage_capacity(threshold_gb: float | None = None) -> dict[str, Any]:
    """Celery ä»»åŠ¡ï¼šæ£€æŸ¥æ•°æ®åº“å®¹é‡å¹¶è¾“å‡ºé¢„è­¦ã€‚"""
    import asyncio

    result = asyncio.run(check_storage_capacity_impl(threshold_gb=threshold_gb))
    logger.info("ğŸ“¦ å­˜å‚¨å®¹é‡æ£€æŸ¥ç»“æœ: %s", result)
    return result
