# Reddit Signal Scanner ç³»ç»Ÿæ¶æ„å®Œæ•´è®²è§£

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æ›´æ–°æ—¥æœŸ**: 2025-10-21  
**ç›®æ ‡è¯»è€…**: äº§å“ç»ç†ã€æŠ€æœ¯å›¢é˜Ÿ

---

## ğŸ“š ç›®å½•

1. [ç³»ç»Ÿæ¦‚è§ˆ](#1-ç³»ç»Ÿæ¦‚è§ˆ)
2. [æ•°æ®åº“è®¾è®¡](#2-æ•°æ®åº“è®¾è®¡)
3. [ç”¨æˆ·æäº¤éœ€æ±‚åçš„å®Œæ•´æµç¨‹](#3-ç”¨æˆ·æäº¤éœ€æ±‚åçš„å®Œæ•´æµç¨‹)
4. [è‡ªåŠ¨æŠ“å–æ•°æ®ç³»ç»Ÿ](#4-è‡ªåŠ¨æŠ“å–æ•°æ®ç³»ç»Ÿ)
5. [æ•°æ®å­˜å‚¨è§„åˆ™](#5-æ•°æ®å­˜å‚¨è§„åˆ™)
6. [å…³é”®æŠ€æœ¯ç»„ä»¶](#6-å…³é”®æŠ€æœ¯ç»„ä»¶)
7. [å®Œæ•´æ•°æ®æµå›¾](#7-å®Œæ•´æ•°æ®æµå›¾)

---

## 1. ç³»ç»Ÿæ¦‚è§ˆ

### 1.1 æ ¸å¿ƒæ‰¿è¯º

**"30ç§’è¾“å…¥ï¼Œ5åˆ†é’Ÿåˆ†æ"**

- ç”¨æˆ·è¾“å…¥äº§å“æè¿°ï¼ˆ30ç§’ï¼‰
- ç³»ç»Ÿè‡ªåŠ¨åˆ†æ Reddit æ•°æ®ï¼ˆ5åˆ†é’Ÿï¼‰
- ç”Ÿæˆå®Œæ•´çš„å¸‚åœºæ´å¯ŸæŠ¥å‘Š

### 1.2 æŠ€æœ¯æ ˆ

**åç«¯**:
- FastAPIï¼ˆHTTP APIï¼‰
- Celeryï¼ˆå¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ï¼‰
- Redisï¼ˆæ¶ˆæ¯é˜Ÿåˆ— + ç¼“å­˜ï¼‰
- PostgreSQLï¼ˆæ•°æ®æŒä¹…åŒ–ï¼‰
- SQLAlchemyï¼ˆORMï¼‰

**å‰ç«¯**:
- React + TypeScript
- Viteï¼ˆæ„å»ºå·¥å…·ï¼‰
- SSEï¼ˆServer-Sent Eventsï¼Œå®æ—¶é€šä¿¡ï¼‰

**å¤–éƒ¨æœåŠ¡**:
- Reddit APIï¼ˆæ•°æ®æºï¼‰

### 1.3 æ¶æ„è®¾è®¡å“²å­¦

**å››è¡¨æ¶æ„** - æç®€è€Œå¼ºå¤§ï¼š
```
Users (ç”¨æˆ·) â†’ Tasks (ä»»åŠ¡) â†’ Analyses (åˆ†æ) â†’ Reports (æŠ¥å‘Š)
                                    â†“
                          CommunityCache (ç¤¾åŒºç¼“å­˜)
```

**ç¼“å­˜ä¼˜å…ˆæ¶æ„** - 90% æ•°æ®æ¥è‡ªé¢„ç¼“å­˜ï¼š
- åå°æŒç»­çˆ¬å–çƒ­é—¨ç¤¾åŒºæ•°æ®
- ç”¨æˆ·è¯·æ±‚æ—¶ä¼˜å…ˆä½¿ç”¨ç¼“å­˜
- ä»…åœ¨å¿…è¦æ—¶è°ƒç”¨ Reddit API

---

## 2. æ•°æ®åº“è®¾è®¡

### 2.1 æ ¸å¿ƒè¡¨ç»“æ„

#### è¡¨ 1: `users` - ç”¨æˆ·è´¦æˆ·

**ç”¨é€”**: å¤šç§Ÿæˆ·éš”ç¦»ï¼Œæ¯ä¸ªç”¨æˆ·çš„æ•°æ®å®Œå…¨ç‹¬ç«‹

```sql
CREATE TABLE users (
    id UUID PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    is_active BOOLEAN DEFAULT TRUE,
    membership_level VARCHAR(20) DEFAULT 'free',  -- free/pro/enterprise
    created_at TIMESTAMP WITH TIME ZONE,
    updated_at TIMESTAMP WITH TIME ZONE
);
```

**å…³é”®å­—æ®µ**:
- `id`: UUIDï¼Œå…¨å±€å”¯ä¸€æ ‡è¯†
- `email`: ç”¨æˆ·é‚®ç®±ï¼Œå”¯ä¸€ç´¢å¼•
- `membership_level`: ä¼šå‘˜ç­‰çº§ï¼ˆæœªæ¥æ‰©å±•ï¼‰

---

#### è¡¨ 2: `tasks` - åˆ†æä»»åŠ¡

**ç”¨é€”**: å­˜å‚¨ç”¨æˆ·æäº¤çš„äº§å“æè¿°å’Œä»»åŠ¡çŠ¶æ€

```sql
CREATE TABLE tasks (
    id UUID PRIMARY KEY,
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    product_description TEXT NOT NULL,  -- 10-2000 å­—
    status VARCHAR(20) NOT NULL,        -- pending/processing/completed/failed
    error_message TEXT,
    started_at TIMESTAMP WITH TIME ZONE,
    completed_at TIMESTAMP WITH TIME ZONE,
    retry_count INTEGER DEFAULT 0,
    created_at TIMESTAMP WITH TIME ZONE,
    updated_at TIMESTAMP WITH TIME ZONE
);
```

**çŠ¶æ€æµè½¬**:
```
pending â†’ processing â†’ completed
                    â†˜ failed (å¯é‡è¯•)
```

**å…³é”®çº¦æŸ**:
- `product_description`: 10-2000 å­—
- `completed_at >= created_at`
- `status = 'failed'` æ—¶å¿…é¡»æœ‰ `error_message`

---

#### è¡¨ 3: `analyses` - åˆ†æç»“æœ

**ç”¨é€”**: å­˜å‚¨ç»“æ„åŒ–çš„åˆ†ææ•°æ®ï¼ˆJSON æ ¼å¼ï¼‰

```sql
CREATE TABLE analyses (
    id UUID PRIMARY KEY,
    task_id UUID UNIQUE REFERENCES tasks(id) ON DELETE CASCADE,
    insights JSONB NOT NULL,           -- ç—›ç‚¹ã€ç«å“ã€æœºä¼š
    sources JSONB NOT NULL,            -- æ•°æ®æ¥æºç»Ÿè®¡
    confidence_score NUMERIC(3,2),     -- 0.00-1.00
    analysis_version INTEGER DEFAULT 1,
    created_at TIMESTAMP WITH TIME ZONE
);
```

**insights ç»“æ„**:
```json
{
  "pain_points": [
    {
      "title": "ç”¨æˆ·ç—›ç‚¹æ ‡é¢˜",
      "severity": "high",
      "mention_count": 15,
      "example_quote": "ç”¨æˆ·åŸè¯å¼•ç”¨"
    }
  ],
  "competitors": [...],
  "opportunities": [...]
}
```

**sources ç»“æ„**:
```json
{
  "communities_found": 10,
  "posts_collected": 317,
  "cache_hit_rate": 0.90,
  "api_calls_made": 32
}
```

---

#### è¡¨ 4: `reports` - æ¸²æŸ“æŠ¥å‘Š

**ç”¨é€”**: å­˜å‚¨é¢„æ¸²æŸ“çš„ HTML æŠ¥å‘Š

```sql
CREATE TABLE reports (
    id UUID PRIMARY KEY,
    analysis_id UUID UNIQUE REFERENCES analyses(id) ON DELETE CASCADE,
    html_content TEXT NOT NULL,        -- å®Œæ•´ HTML
    metadata JSONB,                    -- æŠ¥å‘Šå…ƒæ•°æ®
    created_at TIMESTAMP WITH TIME ZONE
);
```

**ä¸ºä»€ä¹ˆé¢„æ¸²æŸ“ HTML?**
- åŠ å¿«æŠ¥å‘ŠåŠ è½½é€Ÿåº¦
- æ”¯æŒç¦»çº¿æŸ¥çœ‹
- ä¾¿äºå¯¼å‡º PDF

---

### 2.2 è¾…åŠ©è¡¨ç»“æ„

#### è¡¨ 5: `community_pool` - ç¤¾åŒºæ± 

**ç”¨é€”**: å­˜å‚¨é¢„å…ˆç­›é€‰çš„é«˜è´¨é‡ Reddit ç¤¾åŒº

```sql
CREATE TABLE community_pool (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) UNIQUE NOT NULL,  -- å¦‚ 'r/startups'
    tier VARCHAR(20) NOT NULL,          -- high/medium/low
    categories JSON NOT NULL,           -- ['business', 'tech']
    description_keywords JSON NOT NULL, -- ['startup', 'founder']
    daily_posts INTEGER DEFAULT 0,
    avg_comment_length INTEGER DEFAULT 0,
    quality_score NUMERIC(3,2) DEFAULT 0.50,
    priority VARCHAR(20) DEFAULT 'medium',
    is_active BOOLEAN DEFAULT TRUE,
    is_blacklisted BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP WITH TIME ZONE,
    updated_at TIMESTAMP WITH TIME ZONE
);
```

**å½“å‰çŠ¶æ€**: 200 ä¸ªæ´»è·ƒç¤¾åŒº

**åˆ†å±‚ç­–ç•¥**:
- **High tier** (é«˜ä¼˜å…ˆçº§): æ¯å°æ—¶çˆ¬å–ä¸€æ¬¡
- **Medium tier** (ä¸­ä¼˜å…ˆçº§): æ¯ 6 å°æ—¶çˆ¬å–ä¸€æ¬¡
- **Low tier** (ä½ä¼˜å…ˆçº§): æ¯ 24 å°æ—¶çˆ¬å–ä¸€æ¬¡

---

#### è¡¨ 6: `posts_raw` - åŸå§‹å¸–å­å­˜å‚¨ï¼ˆå†·å­˜å‚¨ï¼‰

**ç”¨é€”**: å­˜å‚¨æ‰€æœ‰çˆ¬å–çš„åŸå§‹å¸–å­æ•°æ®

```sql
CREATE TABLE posts_raw (
    id SERIAL PRIMARY KEY,
    source_post_id VARCHAR(50) UNIQUE NOT NULL,  -- Reddit å¸–å­ ID
    subreddit VARCHAR(100) NOT NULL,
    title TEXT,
    selftext TEXT,
    author VARCHAR(100),
    score INTEGER,
    num_comments INTEGER,
    created_utc TIMESTAMP WITH TIME ZONE,
    url TEXT,
    permalink TEXT,
    raw_data JSONB,                    -- å®Œæ•´åŸå§‹æ•°æ®
    created_at TIMESTAMP WITH TIME ZONE
);
```

**å½“å‰æ•°æ®é‡**: 18,260 æ¡

---

#### è¡¨ 7: `posts_hot` - çƒ­é—¨å¸–å­ç¼“å­˜ï¼ˆçƒ­å­˜å‚¨ï¼‰

**ç”¨é€”**: å­˜å‚¨æœ€è¿‘ 30 å¤©çš„çƒ­é—¨å¸–å­ï¼Œç”¨äºå¿«é€Ÿåˆ†æ

```sql
CREATE TABLE posts_hot (
    id SERIAL PRIMARY KEY,
    source_post_id VARCHAR(50) REFERENCES posts_raw(source_post_id),
    subreddit VARCHAR(100) NOT NULL,
    title TEXT,
    selftext TEXT,
    score INTEGER,
    num_comments INTEGER,
    created_utc TIMESTAMP WITH TIME ZONE,
    cached_at TIMESTAMP WITH TIME ZONE,
    expires_at TIMESTAMP WITH TIME ZONE,  -- 30 å¤©åè¿‡æœŸ
    created_at TIMESTAMP WITH TIME ZONE
);
```

**å½“å‰æ•°æ®é‡**: 17,977 æ¡

**è‡ªåŠ¨æ¸…ç†**: æ¯å¤©å‡Œæ™¨åˆ é™¤è¿‡æœŸæ•°æ®

---

#### è¡¨ 8: `community_cache` - ç¤¾åŒºç¼“å­˜çŠ¶æ€

**ç”¨é€”**: è®°å½•æ¯ä¸ªç¤¾åŒºçš„ç¼“å­˜å…ƒæ•°æ®

```sql
CREATE TABLE community_cache (
    id SERIAL PRIMARY KEY,
    community_name VARCHAR(100) UNIQUE NOT NULL,
    posts_cached INTEGER DEFAULT 0,
    last_crawled_at TIMESTAMP WITH TIME ZONE,
    cache_expires_at TIMESTAMP WITH TIME ZONE,
    quality_score NUMERIC(3,2),
    created_at TIMESTAMP WITH TIME ZONE,
    updated_at TIMESTAMP WITH TIME ZONE
);
```

**ç”¨é€”**:
- è®°å½•ä¸Šæ¬¡çˆ¬å–æ—¶é—´
- åˆ¤æ–­ç¼“å­˜æ˜¯å¦è¿‡æœŸ
- è®¡ç®—ç¤¾åŒºè´¨é‡åˆ†æ•°

---

## 3. ç”¨æˆ·æäº¤éœ€æ±‚åçš„å®Œæ•´æµç¨‹

### 3.1 æµç¨‹æ¦‚è§ˆ

```
ç”¨æˆ·è¾“å…¥äº§å“æè¿°
    â†“
å‰ç«¯æäº¤ POST /api/analyze
    â†“
åç«¯åˆ›å»º Task è®°å½•ï¼ˆstatus: pendingï¼‰
    â†“
Celery å¼‚æ­¥ä»»åŠ¡å¯åŠ¨ï¼ˆstatus: processingï¼‰
    â†“
ã€æ­¥éª¤ 1ã€‘æ™ºèƒ½ç¤¾åŒºå‘ç°
    â†“
ã€æ­¥éª¤ 2ã€‘å¹¶è¡Œæ•°æ®é‡‡é›†
    â†“
ã€æ­¥éª¤ 3ã€‘ä¿¡å·æå–ä¸åˆ†æ
    â†“
ã€æ­¥éª¤ 4ã€‘æŠ¥å‘Šç”Ÿæˆ
    â†“
æ›´æ–° Task çŠ¶æ€ï¼ˆstatus: completedï¼‰
    â†“
å‰ç«¯é€šè¿‡ SSE å®æ—¶æ¥æ”¶è¿›åº¦
    â†“
ç”¨æˆ·æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š
```

### 3.2 è¯¦ç»†æ­¥éª¤æ‹†è§£

#### æ­¥éª¤ 0: ç”¨æˆ·æäº¤ï¼ˆå‰ç«¯ï¼‰

**ç”¨æˆ·æ“ä½œ**:
1. åœ¨è¾“å…¥æ¡†å¡«å†™äº§å“æè¿°ï¼ˆ83 å­—ï¼‰
2. ç‚¹å‡»"å¼€å§‹ 5 åˆ†é’Ÿåˆ†æ"æŒ‰é’®

**å‰ç«¯ä»£ç **:
```typescript
// frontend/src/pages/InputPage.tsx
const response = await api.post('/api/analyze', {
  product_description: description
});
const taskId = response.data.task_id;
navigate(`/progress/${taskId}`);
```

**API è¯·æ±‚**:
```http
POST /api/analyze HTTP/1.1
Authorization: Bearer <JWT_TOKEN>
Content-Type: application/json

{
  "product_description": "ä¸€æ¬¾å¸®åŠ©å¿™ç¢Œä¸“ä¸šäººå£«è¿›è¡Œé¤é£Ÿå‡†å¤‡çš„ç§»åŠ¨åº”ç”¨..."
}
```

---

#### æ­¥éª¤ 1: åˆ›å»ºä»»åŠ¡ï¼ˆåç«¯ APIï¼‰

**åç«¯ä»£ç **:
```python
# backend/app/api/v1/analyze.py
@router.post("/analyze")
async def create_analysis_task(
    request: TaskCreate,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    # 1. åˆ›å»º Task è®°å½•
    task = Task(
        id=uuid.uuid4(),
        user_id=current_user.id,
        product_description=request.product_description,
        status=TaskStatus.PENDING
    )
    db.add(task)
    await db.commit()
    
    # 2. å‘é€åˆ° Celery é˜Ÿåˆ—
    run_analysis_task.apply_async(
        args=[str(task.id)],
        queue='analysis_queue'
    )
    
    return {"task_id": str(task.id)}
```

**æ•°æ®åº“å˜åŒ–**:
```sql
INSERT INTO tasks (id, user_id, product_description, status, created_at)
VALUES ('626e668e-...', 'user-uuid', 'äº§å“æè¿°...', 'pending', NOW());
```

---

#### æ­¥éª¤ 2: Celery ä»»åŠ¡å¯åŠ¨

**Celery Worker æ¥æ”¶ä»»åŠ¡**:
```python
# backend/app/tasks/analysis_task.py
@celery_app.task(name="run_analysis_task")
def run_analysis_task(task_id: str):
    asyncio.run(_run_analysis_async(task_id))

async def _run_analysis_async(task_id: str):
    # 1. æ›´æ–°çŠ¶æ€ä¸º processing
    await update_task_status(task_id, TaskStatus.PROCESSING)
    
    # 2. è°ƒç”¨åˆ†æå¼•æ“
    result = await AnalysisEngine.run(task_id)
    
    # 3. ä¿å­˜ç»“æœ
    await save_analysis_result(task_id, result)
    
    # 4. æ›´æ–°çŠ¶æ€ä¸º completed
    await update_task_status(task_id, TaskStatus.COMPLETED)
```

---

#### æ­¥éª¤ 3: åˆ†æå¼•æ“æ‰§è¡Œï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰

**3.1 æ™ºèƒ½ç¤¾åŒºå‘ç°**

**ç›®æ ‡**: ä» 200 ä¸ªç¤¾åŒºæ± ä¸­æ‰¾å‡ºæœ€ç›¸å…³çš„ 10-20 ä¸ªç¤¾åŒº

**ç®—æ³•**:
```python
# backend/app/services/analysis_engine.py
async def discover_communities(product_description: str) -> List[CommunityProfile]:
    # 1. æå–äº§å“å…³é”®è¯
    keywords = extract_keywords(product_description)
    # ä¾‹å¦‚: ['é¤é£Ÿ', 'å‡†å¤‡', 'ç§»åŠ¨åº”ç”¨', 'é¥®é£Ÿåå¥½', 'è´­ç‰©æ¸…å•']
    
    # 2. ä»ç¤¾åŒºæ± åŠ è½½æ‰€æœ‰æ´»è·ƒç¤¾åŒº
    communities = await load_community_pool()
    # 200 ä¸ªç¤¾åŒº
    
    # 3. è®¡ç®—æ¯ä¸ªç¤¾åŒºçš„ç›¸å…³æ€§åˆ†æ•°
    scored_communities = []
    for community in communities:
        score = calculate_relevance_score(
            keywords=keywords,
            community_categories=community.categories,
            community_keywords=community.description_keywords
        )
        scored_communities.append((community, score))
    
    # 4. æŒ‰åˆ†æ•°æ’åºï¼Œå–å‰ 10-20 ä¸ª
    top_communities = sorted(scored_communities, key=lambda x: x[1], reverse=True)[:15]
    
    return [c[0] for c in top_communities]
```

**è¾“å‡ºç¤ºä¾‹**:
```
å‘ç° 12 ä¸ªç›¸å…³ç¤¾åŒº:
- r/mealprep (åˆ†æ•°: 0.95)
- r/EatCheapAndHealthy (åˆ†æ•°: 0.88)
- r/cookingforbeginners (åˆ†æ•°: 0.82)
...
```

---

**3.2 å¹¶è¡Œæ•°æ®é‡‡é›†**

**ç›®æ ‡**: ä»å‘ç°çš„ç¤¾åŒºä¸­é‡‡é›†å¸–å­æ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼‰

**æµç¨‹**:
```python
async def collect_data(communities: List[CommunityProfile]) -> CollectionResult:
    results = []
    
    for community in communities:
        # 1. æ£€æŸ¥ç¼“å­˜
        cached_posts = await cache_manager.get_cached_posts(community.name)
        
        if cached_posts and not is_expired(cached_posts):
            # ç¼“å­˜å‘½ä¸­
            results.append({
                'community': community.name,
                'posts': cached_posts,
                'cache_hit': True
            })
        else:
            # ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨ Reddit API
            posts = await reddit_client.fetch_subreddit_posts(
                community.name,
                limit=100,
                time_filter='week',
                sort='top'
            )
            
            # æ›´æ–°ç¼“å­˜
            await cache_manager.set_cached_posts(community.name, posts)
            
            results.append({
                'community': community.name,
                'posts': posts,
                'cache_hit': False
            })
    
    return CollectionResult(
        communities_found=len(communities),
        posts_collected=sum(len(r['posts']) for r in results),
        cache_hit_rate=calculate_cache_hit_rate(results)
    )
```

**è¾“å‡ºç¤ºä¾‹**:
```
æ•°æ®é‡‡é›†å®Œæˆ:
- ç¤¾åŒºæ•°é‡: 12
- å¸–å­æ€»æ•°: 234
- ç¼“å­˜å‘½ä¸­ç‡: 90% (10/12 ä¸ªç¤¾åŒºä½¿ç”¨ç¼“å­˜)
- API è°ƒç”¨æ¬¡æ•°: 2
```

---

**3.3 ä¿¡å·æå–ä¸åˆ†æ**

**ç›®æ ‡**: ä»å¸–å­ä¸­æå–ç—›ç‚¹ã€ç«å“ã€æœºä¼š

**ç®—æ³•**:
```python
async def extract_signals(posts: List[Dict]) -> Dict[str, List]:
    pain_points = []
    competitors = []
    opportunities = []
    
    for post in posts:
        text = post['title'] + ' ' + post['selftext']
        
        # 1. ç—›ç‚¹æ£€æµ‹ï¼ˆå…³é”®è¯åŒ¹é… + æƒ…æ„Ÿåˆ†æï¼‰
        if contains_pain_keywords(text):
            pain_points.append({
                'title': extract_pain_title(text),
                'severity': calculate_severity(text),
                'mention_count': 1,
                'example_quote': extract_quote(text),
                'subreddit': post['subreddit']
            })
        
        # 2. ç«å“æ£€æµ‹ï¼ˆå“ç‰Œåç§°è¯†åˆ«ï¼‰
        competitors_found = extract_competitor_mentions(text)
        competitors.extend(competitors_found)
        
        # 3. æœºä¼šæ£€æµ‹ï¼ˆéœ€æ±‚è¡¨è¾¾è¯†åˆ«ï¼‰
        opportunities_found = extract_opportunities(text)
        opportunities.extend(opportunities_found)
    
    # 4. å»é‡å’Œèšåˆ
    pain_points = deduplicate_and_aggregate(pain_points)
    competitors = deduplicate_and_aggregate(competitors)
    opportunities = deduplicate_and_aggregate(opportunities)
    
    return {
        'pain_points': pain_points,
        'competitors': competitors,
        'opportunities': opportunities
    }
```

**è¾“å‡ºç¤ºä¾‹**:
```
ä¿¡å·æå–å®Œæˆ:
- ç—›ç‚¹: 15 æ¡
- ç«å“: 8 ä¸ª
- æœºä¼š: 10 ä¸ª
```

---

**3.4 æŠ¥å‘Šç”Ÿæˆ**

**ç›®æ ‡**: ç”Ÿæˆ HTML æ ¼å¼çš„å®Œæ•´æŠ¥å‘Š

```python
async def generate_report(insights: Dict, sources: Dict) -> str:
    html = f"""
    <html>
    <head><title>å¸‚åœºæ´å¯ŸæŠ¥å‘Š</title></head>
    <body>
        <h1>å¸‚åœºæ´å¯ŸæŠ¥å‘Š</h1>
        <section>
            <h2>æ•°æ®æ¦‚è§ˆ</h2>
            <p>åˆ†æäº† {sources['communities_found']} ä¸ªç¤¾åŒº</p>
            <p>æ”¶é›†äº† {sources['posts_collected']} æ¡å¸–å­</p>
        </section>
        
        <section>
            <h2>ç”¨æˆ·ç—›ç‚¹</h2>
            {render_pain_points(insights['pain_points'])}
        </section>
        
        <section>
            <h2>ç«å“åˆ†æ</h2>
            {render_competitors(insights['competitors'])}
        </section>
        
        <section>
            <h2>å•†ä¸šæœºä¼š</h2>
            {render_opportunities(insights['opportunities'])}
        </section>
    </body>
    </html>
    """
    return html
```

---

#### æ­¥éª¤ 4: ä¿å­˜ç»“æœåˆ°æ•°æ®åº“

```python
async def save_analysis_result(task_id: str, result: AnalysisResult):
    async with SessionFactory() as db:
        # 1. åˆ›å»º Analysis è®°å½•
        analysis = Analysis(
            id=uuid.uuid4(),
            task_id=task_id,
            insights=result.insights,
            sources=result.sources,
            confidence_score=0.85
        )
        db.add(analysis)
        
        # 2. åˆ›å»º Report è®°å½•
        report = Report(
            id=uuid.uuid4(),
            analysis_id=analysis.id,
            html_content=result.report_html
        )
        db.add(report)
        
        # 3. æ›´æ–° Task çŠ¶æ€
        task = await db.get(Task, task_id)
        task.status = TaskStatus.COMPLETED
        task.completed_at = datetime.now(timezone.utc)
        
        await db.commit()
```

---

#### æ­¥éª¤ 5: SSE å®æ—¶æ¨é€è¿›åº¦

**åç«¯ SSE æœåŠ¡**:
```python
# backend/app/core/sse.py
async def send_progress_update(task_id: str, stage: int, total_stages: int):
    event = {
        'event': 'progress',
        'task_id': task_id,
        'stage': stage,
        'total_stages': total_stages,
        'percentage': (stage / total_stages) * 100
    }
    await sse_manager.broadcast(task_id, event)
```

**å‰ç«¯ SSE å®¢æˆ·ç«¯**:
```typescript
// frontend/src/api/sse.client.ts
const eventSource = new EventSource(`/api/stream/${taskId}`);

eventSource.onmessage = (event) => {
  const data = JSON.parse(event.data);
  
  if (data.event === 'progress') {
    setProgress(data.percentage);
    setStage(data.stage);
  }
  
  if (data.event === 'completed') {
    navigate(`/report/${taskId}`);
  }
};
```

---

## 4. è‡ªåŠ¨æŠ“å–æ•°æ®ç³»ç»Ÿ

### 4.1 ç³»ç»Ÿæ¦‚è¿°

**ç›®æ ‡**: 24/7 æŒç»­çˆ¬å–ç¤¾åŒºæ•°æ®ï¼Œä¿æŒç¼“å­˜æ–°é²œåº¦

**æ¶æ„**:
```
Celery Beat (å®šæ—¶è°ƒåº¦å™¨)
    â†“
Celery Worker (çˆ¬è™«ä»»åŠ¡)
    â†“
Reddit API (æ•°æ®æº)
    â†“
PostgreSQL (posts_raw, posts_hot)
    â†“
Redis (ç¼“å­˜)
```

### 4.2 å®šæ—¶ä»»åŠ¡é…ç½®

```python
# backend/app/core/celery_app.py
celery_app.conf.beat_schedule = {
    'crawl-high-priority-communities': {
        'task': 'crawl_seed_communities',
        'schedule': crontab(minute='*/60'),  # æ¯å°æ—¶
        'args': ('high',)
    },
    'crawl-medium-priority-communities': {
        'task': 'crawl_seed_communities',
        'schedule': crontab(minute='*/360'),  # æ¯ 6 å°æ—¶
        'args': ('medium',)
    },
    'crawl-low-priority-communities': {
        'task': 'crawl_seed_communities',
        'schedule': crontab(hour='*/24'),  # æ¯ 24 å°æ—¶
        'args': ('low',)
    }
}
```

### 4.3 å¢é‡çˆ¬è™«é€»è¾‘

```python
# backend/app/tasks/crawler_task.py
@celery_app.task(name="crawl_seed_communities")
def crawl_seed_communities(tier: str = 'all'):
    asyncio.run(_crawl_async(tier))

async def _crawl_async(tier: str):
    # 1. ä»ç¤¾åŒºæ± åŠ è½½å¾…çˆ¬å–ç¤¾åŒº
    communities = await load_communities_by_tier(tier)
    # ä¾‹å¦‚: tier='high' è¿”å› 50 ä¸ªé«˜ä¼˜å…ˆçº§ç¤¾åŒº
    
    # 2. æ‰¹é‡çˆ¬å–ï¼ˆå¹¶å‘æ§åˆ¶ï¼š2ï¼‰
    for batch in chunked(communities, batch_size=12):
        tasks = [
            crawl_single_community(community)
            for community in batch
        ]
        await asyncio.gather(*tasks, return_exceptions=True)
    
    # 3. è®°å½•çˆ¬å–æŒ‡æ ‡
    await record_crawl_metrics(tier, len(communities))
```

### 4.4 å•ä¸ªç¤¾åŒºçˆ¬å–æµç¨‹

```python
async def crawl_single_community(community: CommunityProfile):
    # 1. è°ƒç”¨ Reddit API
    posts = await reddit_client.fetch_subreddit_posts(
        community.name,
        limit=100,
        time_filter='week',
        sort='top'
    )
    
    # 2. ä¿å­˜åˆ° posts_rawï¼ˆå†·å­˜å‚¨ï¼‰
    await save_to_posts_raw(posts)
    
    # 3. ä¿å­˜åˆ° posts_hotï¼ˆçƒ­å­˜å‚¨ï¼‰
    await save_to_posts_hot(posts, ttl_days=30)
    
    # 4. æ›´æ–° Redis ç¼“å­˜
    await cache_manager.set_cached_posts(community.name, posts)
    
    # 5. æ›´æ–° community_cache å…ƒæ•°æ®
    await update_community_cache(
        community.name,
        posts_cached=len(posts),
        last_crawled_at=datetime.now(timezone.utc)
    )
```

---

## 5. æ•°æ®å­˜å‚¨è§„åˆ™

### 5.1 å†·çƒ­åˆ†ç¦»æ¶æ„

**è®¾è®¡ç†å¿µ**: åˆ†ç¦»"å…¨é‡å†å²æ•°æ®"å’Œ"çƒ­é—¨è¿‘æœŸæ•°æ®"

```
posts_raw (å†·å­˜å‚¨)          posts_hot (çƒ­å­˜å‚¨)
    â†“                           â†“
æ‰€æœ‰çˆ¬å–çš„å¸–å­              æœ€è¿‘ 30 å¤©çš„çƒ­é—¨å¸–å­
æ°¸ä¹…ä¿å­˜                    è‡ªåŠ¨è¿‡æœŸåˆ é™¤
18,260 æ¡                   17,977 æ¡
```

**ä¸ºä»€ä¹ˆéœ€è¦å†·çƒ­åˆ†ç¦»?**
- **æ€§èƒ½**: åˆ†ææ—¶åªæŸ¥è¯¢ posts_hotï¼Œé€Ÿåº¦å¿« 10 å€
- **æˆæœ¬**: å†·æ•°æ®å¯ä»¥è¿ç§»åˆ°å»‰ä»·å­˜å‚¨
- **ç»´æŠ¤**: çƒ­æ•°æ®è‡ªåŠ¨æ¸…ç†ï¼Œæ— éœ€æ‰‹åŠ¨ç®¡ç†

### 5.2 æ•°æ®å†™å…¥è§„åˆ™

**è§„åˆ™ 1: åŒå†™ç­–ç•¥**
```python
async def save_posts(posts: List[RedditPost]):
    # 1. å†™å…¥ posts_rawï¼ˆå†·å­˜å‚¨ï¼‰
    await insert_posts_raw(posts)
    
    # 2. å†™å…¥ posts_hotï¼ˆçƒ­å­˜å‚¨ï¼‰
    await insert_posts_hot(posts, expires_at=now() + timedelta(days=30))
```

**è§„åˆ™ 2: å»é‡ç­–ç•¥**
```python
# ä½¿ç”¨ source_post_id ä½œä¸ºå”¯ä¸€é”®
INSERT INTO posts_raw (source_post_id, ...)
VALUES ('abc123', ...)
ON CONFLICT (source_post_id) DO NOTHING;
```

**è§„åˆ™ 3: è¿‡æœŸæ¸…ç†**
```python
# æ¯å¤©å‡Œæ™¨ 2 ç‚¹æ‰§è¡Œ
DELETE FROM posts_hot
WHERE expires_at < NOW();
```

### 5.3 ç¼“å­˜ç­–ç•¥

**ä¸‰çº§ç¼“å­˜æ¶æ„**:
```
Level 1: Redis (å†…å­˜ç¼“å­˜)
    â†“ æœªå‘½ä¸­
Level 2: posts_hot (æ•°æ®åº“çƒ­å­˜å‚¨)
    â†“ æœªå‘½ä¸­
Level 3: Reddit API (å®æ—¶æŠ“å–)
```

**ç¼“å­˜ TTL**:
- Redis: 24 å°æ—¶
- posts_hot: 30 å¤©
- community_cache: è®°å½•ä¸Šæ¬¡çˆ¬å–æ—¶é—´

---

## 6. å…³é”®æŠ€æœ¯ç»„ä»¶

### 6.1 Celery ä»»åŠ¡é˜Ÿåˆ—

**é˜Ÿåˆ—åˆ†ç±»**:
```python
CELERY_TASK_ROUTES = {
    'run_analysis_task': {'queue': 'analysis_queue'},
    'crawl_community': {'queue': 'crawler_queue'},
    'monitor_cache_health': {'queue': 'monitoring_queue'},
    'cleanup_expired_data': {'queue': 'maintenance_queue'}
}
```

**å¹¶å‘æ§åˆ¶**:
- åˆ†æä»»åŠ¡: 4 ä¸ª worker
- çˆ¬è™«ä»»åŠ¡: 2 ä¸ª workerï¼ˆé¿å… API é™æµï¼‰
- ç›‘æ§ä»»åŠ¡: 1 ä¸ª worker

### 6.2 SSE å®æ—¶é€šä¿¡

**ä¸ºä»€ä¹ˆé€‰æ‹© SSE è€Œä¸æ˜¯ WebSocket?**
- å•å‘é€šä¿¡ï¼ˆæœåŠ¡å™¨ â†’ å®¢æˆ·ç«¯ï¼‰
- è‡ªåŠ¨é‡è¿
- æ›´ç®€å•çš„å®ç°

**SSE äº‹ä»¶ç±»å‹**:
```typescript
type SSEEvent = 
  | { event: 'connected', task_id: string }
  | { event: 'progress', stage: number, total_stages: number }
  | { event: 'completed', task_id: string }
  | { event: 'error', message: string }
  | { event: 'close' };
```

### 6.3 JWT è®¤è¯

**Token ç»“æ„**:
```json
{
  "sub": "user-uuid",
  "email": "user@example.com",
  "exp": 1234567890
}
```

**è®¤è¯æµç¨‹**:
```
1. ç”¨æˆ·ç™»å½• â†’ åç«¯éªŒè¯å¯†ç  â†’ è¿”å› JWT token
2. å‰ç«¯å­˜å‚¨ token åˆ° localStorage
3. æ¯æ¬¡è¯·æ±‚æºå¸¦ token: Authorization: Bearer <token>
4. åç«¯éªŒè¯ token â†’ æå– user_id â†’ æŸ¥è¯¢æ•°æ®
```

---

## 7. å®Œæ•´æ•°æ®æµå›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ç”¨æˆ·æ“ä½œå±‚                               â”‚
â”‚  ç”¨æˆ·è¾“å…¥äº§å“æè¿° â†’ ç‚¹å‡»"å¼€å§‹åˆ†æ" â†’ æŸ¥çœ‹å®æ—¶è¿›åº¦ â†’ æŸ¥çœ‹æŠ¥å‘Š    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         å‰ç«¯å±‚ (React)                           â”‚
â”‚  InputPage â†’ POST /api/analyze â†’ ProgressPage (SSE) â†’ ReportPageâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      åç«¯ API å±‚ (FastAPI)                       â”‚
â”‚  åˆ›å»º Task â†’ å‘é€åˆ° Celery â†’ SSE æ¨é€è¿›åº¦ â†’ è¿”å›æŠ¥å‘Š            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Celery ä»»åŠ¡å±‚ (å¼‚æ­¥å¤„ç†)                      â”‚
â”‚  run_analysis_task â†’ è°ƒç”¨åˆ†æå¼•æ“ â†’ ä¿å­˜ç»“æœ â†’ æ›´æ–°çŠ¶æ€         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      åˆ†æå¼•æ“ (æ ¸å¿ƒé€»è¾‘)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ ç¤¾åŒºå‘ç°     â”‚â†’ â”‚ æ•°æ®é‡‡é›†     â”‚â†’ â”‚ ä¿¡å·æå–     â”‚          â”‚
â”‚  â”‚ (200â†’12ç¤¾åŒº) â”‚  â”‚ (ç¼“å­˜ä¼˜å…ˆ)   â”‚  â”‚ (ç—›ç‚¹/ç«å“)  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                           â†“                      â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚                                    â”‚ æŠ¥å‘Šç”Ÿæˆ     â”‚             â”‚
â”‚                                    â”‚ (HTML)       â”‚             â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      æ•°æ®å±‚ (PostgreSQL + Redis)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ users    â”‚  â”‚ tasks    â”‚  â”‚ analyses â”‚  â”‚ reports  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚posts_raw â”‚  â”‚posts_hot â”‚  â”‚community â”‚                      â”‚
â”‚  â”‚(18,260)  â”‚  â”‚(17,977)  â”‚  â”‚_pool(200)â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                                  â”‚
â”‚  Redis: ç¼“å­˜ + æ¶ˆæ¯é˜Ÿåˆ—                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åå°çˆ¬è™«ç³»ç»Ÿ (24/7 è¿è¡Œ)                      â”‚
â”‚  Celery Beat â†’ å®šæ—¶è§¦å‘ â†’ çˆ¬å–ç¤¾åŒº â†’ ä¿å­˜æ•°æ® â†’ æ›´æ–°ç¼“å­˜        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ High (1h)    â”‚  â”‚ Medium (6h)  â”‚  â”‚ Low (24h)    â”‚          â”‚
â”‚  â”‚ 50 ç¤¾åŒº      â”‚  â”‚ 100 ç¤¾åŒº     â”‚  â”‚ 50 ç¤¾åŒº      â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      å¤–éƒ¨æœåŠ¡ (Reddit API)                       â”‚
â”‚  GET /r/{subreddit}/top â†’ è¿”å›å¸–å­åˆ—è¡¨                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ€»ç»“

### æ ¸å¿ƒè®¾è®¡åŸåˆ™

1. **æç®€æ¶æ„**: å››è¡¨æ ¸å¿ƒ + è¾…åŠ©è¡¨
2. **ç¼“å­˜ä¼˜å…ˆ**: 90% æ•°æ®æ¥è‡ªé¢„ç¼“å­˜
3. **å¼‚æ­¥å¤„ç†**: Celery è§£è€¦ HTTP å’Œåˆ†æ
4. **å®æ—¶åé¦ˆ**: SSE æ¨é€è¿›åº¦
5. **å¤šç§Ÿæˆ·éš”ç¦»**: æ¯ä¸ªç”¨æˆ·æ•°æ®å®Œå…¨ç‹¬ç«‹

### å…³é”®æ•°æ®æŒ‡æ ‡

- **ç¤¾åŒºæ± **: 200 ä¸ªæ´»è·ƒç¤¾åŒº
- **å†·å­˜å‚¨**: 18,260 æ¡å¸–å­
- **çƒ­å­˜å‚¨**: 17,977 æ¡å¸–å­
- **ç¼“å­˜å‘½ä¸­ç‡**: 90%
- **åˆ†ææ—¶é—´**: 5 åˆ†é’Ÿå†…å®Œæˆ

### æŠ€æœ¯äº®ç‚¹

- **å†·çƒ­åˆ†ç¦»**: æ€§èƒ½æå‡ 10 å€
- **å¢é‡çˆ¬è™«**: 24/7 æŒç»­æ›´æ–°
- **æ™ºèƒ½è°ƒåº¦**: åˆ†å±‚ä¼˜å…ˆçº§ç®¡ç†
- **å»é‡æœºåˆ¶**: é¿å…é‡å¤æ•°æ®
- **è‡ªåŠ¨æ¸…ç†**: 30 å¤©è¿‡æœŸåˆ é™¤

---

**æ–‡æ¡£ç»“æŸ**

