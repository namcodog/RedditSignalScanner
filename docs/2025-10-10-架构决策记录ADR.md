# 架构决策记录 (ADR)

> **项目**: Reddit Signal Scanner 0-1重写
> **创建日期**: 2025-10-10
> **维护者**: 项目架构组

---

## ADR格式说明

每个决策记录包含：
- **状态**: 提议 / 已接受 / 已废弃 / 已替代
- **背景**: 为什么需要做这个决策
- **决策**: 我们选择了什么方案
- **后果**: 这个决策带来的影响（正面和负面）
- **替代方案**: 我们考虑过但没选择的方案

---

## ADR-001: 使用4表架构而非多表设计

**状态**: ✅ 已接受

**日期**: 2025-10-10

**背景**:
现有项目使用10+个数据表，导致：
- JOIN查询复杂
- 数据关系难以理解
- 维护成本高

**决策**:
采用Linus"数据结构优先"原则，设计4表架构：
```
Users → Tasks → Analyses → Reports
                ↓
         CommunityCache (独立)
```

**理由**:
1. 简单的1:N:1:1关系，无特殊情况
2. 社区、帖子等不作为持久化实体（仅是中间数据）
3. JSONB字段存储灵活数据
4. 符合PRD-01设计

**后果**:

正面：
- ✅ 查询简单（最多2层JOIN）
- ✅ Schema清晰易懂
- ✅ 迁移脚本简洁
- ✅ 测试覆盖容易

负面：
- ⚠️ JSONB字段需要应用层验证
- ⚠️ 复杂查询可能需要GIN索引

**替代方案**:

方案A: 分离表（posts, comments, subreddits）
- 拒绝理由: 增加JOIN复杂度，违反简单原则

方案B: NoSQL（MongoDB）
- 拒绝理由: 失去ACID保证，不适合任务状态管理

---

## ADR-002: SSE优先，轮询作为Fallback

**状态**: ✅ 已接受

**日期**: 2025-10-10

**背景**:
Linus严厉批评"300次无用HTTP请求"的轮询设计。

**决策**:
- 主要方式: Server-Sent Events (SSE)
- Fallback: 轮询（仅在SSE不可用时）

**理由**:
1. SSE简单（单向推送足够）
- 比WebSocket简单
- 自动断线重连
- 标准HTTP协议

2. 性能优势
- 1个长连接 vs 300次短连接
- 实时推送 vs 2秒轮询

3. 符合PRD-02要求

**后果**:

正面：
- ✅ 显著降低服务器负载
- ✅ 用户体验更好（实时更新）
- ✅ 代码更简洁

负面：
- ⚠️ 需要处理SSE连接管理
- ⚠️ 老旧浏览器可能不支持（需要Fallback）

**实现细节**:
```python
@router.get("/analyze/stream/{task_id}")
async def stream_progress(task_id: str):
    async def event_generator():
        yield "data: {\"event\": \"connected\"}\n\n"
        # ... 推送进度
    return StreamingResponse(event_generator(), media_type="text/event-stream")
```

**替代方案**:

方案A: WebSocket
- 拒绝理由: 过度复杂（我们不需要双向通信）

方案B: 纯轮询
- 拒绝理由: 资源浪费，用户体验差

---

## ADR-003: 缓存优先架构（90%缓存 + 10%实时）

**状态**: ✅ 已接受

**日期**: 2025-10-10

**背景**:
"5分钟分析"承诺与Reddit API限制的物理矛盾：
- 实时爬取: 20社区 × 100帖 = 2000 API调用
- Reddit限制: 60请求/分钟 → 需要33分钟

**决策**:
采用缓存优先架构：
- 后台爬虫持续爬取热门社区（24×7）
- 分析引擎优先使用缓存（90%数据）
- 仅精准补充10%实时数据

**理由**:
1. 诚实的架构（承认缓存而非魔法）
2. 实际可行（符合API限制）
3. 数据新鲜度可接受（主体24小时内）

**后果**:

正面：
- ✅ "5分钟承诺"可实现
- ✅ API调用<20次/分钟
- ✅ 系统稳定可靠

负面：
- ⚠️ 需要维护后台爬虫系统
- ⚠️ 缓存miss时性能下降
- ⚠️ 数据可能不是最新（需标注）

**配置**:
```yaml
# backend/config/cache.yaml
cache_strategy:
  target_hit_rate: 0.9  # 90%目标
  max_api_calls_per_minute: 50  # 预留10个给实时
  cache_ttl_hours: 1
```

**替代方案**:

方案A: 纯实时爬取
- 拒绝理由: 物理不可能（违反API限制）

方案B: 用户等待33分钟
- 拒绝理由: 用户体验极差

---

## ADR-004: 类型安全零容忍（100% mypy --strict）

**状态**: ✅ 已接受

**日期**: 2025-10-10

**背景**:
现有项目质量问题：
- 1个`# type: ignore`
- 多处`Dict[str, Any]`
- 部分函数缺少类型注解

**决策**:
从第一行代码开始，强制100% mypy --strict：
```python
# ❌ 绝对禁止
# type: ignore
Any
Dict[str, Any]
def func(data):  # 无类型注解

# ✅ 必须遵守
from typing import Dict, List
from pydantic import BaseModel

class Request(BaseModel):
    description: str

def process(req: Request) -> Dict[str, str]:
    return {"result": "success"}
```

**理由**:
1. 早期发现错误（编译期 vs 运行期）
2. IDE自动补全和重构支持
3. 文档作用（类型即文档）
4. 符合CLAUDE.md规范

**后果**:

正面：
- ✅ Bug在开发阶段被发现
- ✅ 重构更安全
- ✅ 新人上手更快
- ✅ 代码可读性提高

负面：
- ⚠️ 初期编码速度稍慢
- ⚠️ 学习曲线（泛型、协议等）

**强制执行**:
```bash
# pre-commit hook
mypy --strict backend/app backend/tests
if [ $? -ne 0 ]; then
    echo "❌ 类型检查失败，提交被拒绝"
    exit 1
fi
```

---

## ADR-005: Pydantic用于Schema验证

**状态**: ✅ 已接受

**日期**: 2025-10-10

**背景**:
JSONB字段灵活但缺少验证，现有项目曾因字段不匹配导致bug。

**决策**:
使用Pydantic模型验证所有JSONB数据：

```python
class PainPoint(BaseModel):
    description: str = Field(min_length=10, max_length=500)
    frequency: int = Field(ge=1)
    sentiment_score: Decimal = Field(ge=-1.0, le=1.0)

class Insights(BaseModel):
    pain_points: List[PainPoint]
    competitors: List[Competitor]
    opportunities: List[Opportunity]

    @validator('pain_points')
    def validate_pain_points(cls, v):
        if len(v) == 0:
            raise ValueError("至少需要1个痛点")
        return v

# 使用
insights = Insights(**data)  # 自动验证
db.add(Analysis(insights=insights.dict()))
```

**理由**:
1. 防止数据格式错误
2. 统一前后端schema
3. 自动生成OpenAPI文档
4. 类型安全

**后果**:

正面：
- ✅ 数据格式错误在写入前被发现
- ✅ API文档自动生成
- ✅ 前后端类型一致

负面：
- ⚠️ 序列化/反序列化开销（通常可忽略）

---

## ADR-006: Celery解耦HTTP和分析引擎

**状态**: ✅ 已接受

**日期**: 2025-10-10

**背景**:
分析任务耗时5分钟，不能阻塞HTTP请求。

**决策**:
使用Celery任务队列：
```
FastAPI (HTTP) → 创建任务 → 返回task_id (< 200ms)
                     ↓
                 Celery队列
                     ↓
              Analysis Workers → 执行5分钟分析
                     ↓
                 更新Redis状态
                     ↓
                 SSE推送给前端
```

**理由**:
1. 遵循PRD-04设计
2. 成熟稳定的解决方案
3. 支持重试、优先级、监控

**后果**:

正面：
- ✅ HTTP响应快速
- ✅ 任务可靠执行
- ✅ 易于水平扩展

负面：
- ⚠️ 需要维护Celery Worker
- ⚠️ 需要Redis依赖

**配置**:
```python
# backend/app/core/celery_config.py
app = Celery('reddit_scanner')
app.config_from_object({
    'broker_url': 'redis://localhost:6379/0',
    'result_backend': 'redis://localhost:6379/0',
    'task_acks_late': True,
    'task_reject_on_worker_lost': True
})
```

---

## ADR-007: React + TypeScript用于前端

**状态**: ✅ 已接受

**日期**: 2025-10-10

**背景**:
需要构建交互式SPA（3个页面）。

**决策**:
- React 18 + TypeScript 5
- Vite构建工具
- React Router
- 原生EventSource (SSE客户端)

**理由**:
1. 符合PRD-05设计
2. TypeScript类型安全
3. Vite快速构建
4. 社区成熟

**后果**:

正面：
- ✅ 开发体验好
- ✅ 类型安全（前后端一致）
- ✅ 构建快速

负面：
- ⚠️ 需要Node.js环境
- ⚠️ Bundle大小需要优化

**目录结构**:
```
frontend/
├── src/
│   ├── pages/      # 3个页面
│   ├── components/ # UI组件
│   ├── services/   # API客户端
│   └── types/      # TypeScript类型
```

---

## ADR-008: JWT无状态认证

**状态**: ✅ 已接受

**日期**: 2025-10-10

**背景**:
需要用户认证和多租户隔离。

**决策**:
使用JWT (JSON Web Tokens):
```python
# 生成token
token = jwt.encode({
    'user_id': str(user.id),
    'exp': datetime.utcnow() + timedelta(hours=24)
}, SECRET_KEY, algorithm='HS256')

# 验证token
@router.get("/protected")
async def protected(current_user: User = Depends(get_current_user)):
    # current_user自动从JWT解析
    pass
```

**理由**:
1. 无状态（不需要session存储）
2. 易于水平扩展
3. 支持多租户（user_id在token中）
4. 符合PRD-06设计

**后果**:

正面：
- ✅ 服务器无状态
- ✅ 易于扩展
- ✅ 标准化方案

负面：
- ⚠️ Token无法主动撤销（需要过期时间）
- ⚠️ Secret key泄露风险

**安全措施**:
- Token过期时间: 24小时
- HTTPS传输
- Secret key环境变量
- Refresh token机制

---

## ADR-009: PostgreSQL作为主数据库

**状态**: ✅ 已接受

**日期**: 2025-10-10

**背景**:
需要ACID保证和复杂查询能力。

**决策**:
PostgreSQL 15+ with:
- JSONB字段（灵活数据）
- GIN索引（JSONB查询优化）
- UUID主键
- 事务支持

**理由**:
1. 符合PRD-01设计
2. JSONB强大且高效
3. 成熟稳定
4. ACID保证

**后果**:

正面：
- ✅ 数据一致性保证
- ✅ JSONB查询灵活
- ✅ 丰富的工具生态

负面：
- ⚠️ 需要运维PostgreSQL
- ⚠️ 水平扩展相对复杂（但当前不需要）

**配置**:
```yaml
# docker-compose.yml
postgres:
  image: postgres:15
  environment:
    POSTGRES_DB: reddit_scanner
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: postgres
  ports:
    - "5432:5432"
```

---

## ADR-010: 测试金字塔策略

**状态**: ✅ 已接受

**日期**: 2025-10-10

**背景**:
需要高质量但高效的测试策略。

**决策**:
测试金字塔：
```
        /\
       /E2E\      10%  (端到端测试)
      /------\
     /集成测试\    30%  (API、数据库集成)
    /----------\
   / 单元测试   \  60%  (纯函数、业务逻辑)
  /--------------\
```

**理由**:
1. 符合PRD-08设计
2. 快速反馈（单元测试秒级）
3. 高覆盖率（目标80%+）

**后果**:

正面：
- ✅ 快速反馈循环
- ✅ 高覆盖率
- ✅ 易于定位bug

负面：
- ⚠️ 需要维护测试代码

**目标覆盖率**:
- 单元测试: 60%代码覆盖
- 集成测试: 30%代码覆盖
- E2E测试: 10%代码覆盖（关键路径）
- **总计**: 80%+

---

## ADR-011: Git工作流（特性分支 + PR）

**状态**: ✅ 已接受

**日期**: 2025-10-10

**决策**:
```
main (受保护)
  ├── feature/day1-models
  ├── feature/day2-migrations
  └── feature/day3-api
```

流程：
1. 从main创建feature分支
2. 开发 + 本地测试
3. 提交PR
4. CI检查（mypy + pytest）
5. Review通过后合并

**强制要求**:
- main分支保护（禁止直接push）
- PR必须通过CI
- PR必须通过代码review

---

## 📝 决策提案模板

```markdown
## ADR-XXX: [决策标题]

**状态**: 提议中

**日期**: YYYY-MM-DD

**背景**:
[为什么需要这个决策？]

**决策**:
[我们选择什么方案？]

**理由**:
1. [原因1]
2. [原因2]

**后果**:

正面：
- ✅ [好处1]

负面：
- ⚠️ [代价1]

**替代方案**:

方案A: [描述]
- 拒绝理由: [原因]
```

---

**维护说明**:
1. 每个重大技术决策都应该记录ADR
2. ADR不可修改（保持历史）
3. 废弃的ADR标记状态为"已废弃"
4. 新决策替代旧决策时，标记"已替代"并引用新ADR编号
