# Reddit Signal Scanner 系统架构快速参考

**一句话总结**: 用户输入产品描述 → 后端异步分析 Reddit 数据 → 5分钟内生成市场洞察报告

---

## 🎯 核心流程（用户视角）

```
1. 用户注册/登录
2. 输入产品描述（83字）
3. 点击"开始分析"
4. 实时查看进度（SSE推送）
5. 查看完整报告（痛点/竞品/机会）
```

**实测数据**:
- 总耗时: 18 秒
- 社区数: 12 个
- 帖子数: 317 条
- 缓存命中率: 90%

---

## 📊 数据库设计（8张表）

### 核心表（4张）

1. **users** - 用户账户
   - 用途: 多租户隔离
   - 关键字段: `id`, `email`, `password_hash`, `membership_level`

2. **tasks** - 分析任务
   - 用途: 存储产品描述和任务状态
   - 状态流转: `pending` → `processing` → `completed`/`failed`
   - 关键字段: `id`, `user_id`, `product_description`, `status`

3. **analyses** - 分析结果
   - 用途: 存储结构化分析数据（JSON）
   - 关键字段: `id`, `task_id`, `insights`, `sources`, `confidence_score`
   - insights 包含: 痛点、竞品、机会

4. **reports** - 渲染报告
   - 用途: 存储预渲染的 HTML 报告
   - 关键字段: `id`, `analysis_id`, `html_content`

### 辅助表（4张）

5. **community_pool** - 社区池
   - 用途: 存储 200 个预筛选的高质量社区
   - 分层: High (50) / Medium (100) / Low (50)
   - 关键字段: `name`, `tier`, `categories`, `quality_score`

6. **posts_raw** - 原始帖子（冷存储）
   - 用途: 永久存储所有爬取的帖子
   - 当前数据量: 18,260 条
   - 关键字段: `source_post_id`, `subreddit`, `title`, `selftext`

7. **posts_hot** - 热门帖子（热存储）
   - 用途: 存储最近 30 天的热门帖子
   - 当前数据量: 17,977 条
   - 自动清理: 每天凌晨删除过期数据
   - 关键字段: `source_post_id`, `expires_at`

8. **community_cache** - 社区缓存元数据
   - 用途: 记录每个社区的缓存状态
   - 关键字段: `community_name`, `last_crawled_at`, `posts_cached`

---

## 🔄 用户提交需求后的流程

### 步骤 1: 创建任务（前端 → 后端）

```
用户点击"开始分析"
  ↓
POST /api/analyze {product_description}
  ↓
创建 Task 记录 (status: pending)
  ↓
发送到 Celery 队列
  ↓
返回 task_id
```

### 步骤 2: 异步处理（Celery Worker）

```
Celery Worker 接收任务
  ↓
更新状态: processing
  ↓
调用分析引擎
```

### 步骤 3: 分析引擎（4步流水线）

#### 3.1 智能社区发现

```
输入: 产品描述
  ↓
提取关键词: ['餐食', '准备', '移动应用', '饮食偏好']
  ↓
从 community_pool 加载 200 个社区
  ↓
计算相关性分数 (关键词匹配)
  ↓
排序并选择 Top 12 个社区
```

**输出**: 12 个相关社区

#### 3.2 并行数据采集（缓存优先）

```
遍历 12 个社区:
  ↓
检查 Redis 缓存
  ↓
缓存命中 (90%) → 从 posts_hot 读取
缓存未命中 (10%) → 调用 Reddit API
  ↓
更新缓存和数据库
```

**输出**: 234-317 条帖子

#### 3.3 信号提取

```
遍历所有帖子:
  ↓
提取痛点 (关键词: "can't", "hate", "broken")
提取竞品 (品牌名称识别)
提取机会 (需求表达: "need", "want", "looking for")
  ↓
去重和聚合
```

**输出**: 
- 痛点: 15 条
- 竞品: 8 个
- 机会: 10 个

#### 3.4 报告生成

```
生成 HTML 报告
  ↓
保存到 analyses 表
保存到 reports 表
  ↓
更新 Task 状态: completed
```

### 步骤 4: 实时推送（SSE）

```
分析引擎每完成一步:
  ↓
推送进度事件到 SSE Manager
  ↓
SSE Manager 广播到前端
  ↓
前端更新进度条和统计数据
```

**事件类型**:
- `connected`: SSE 连接成功
- `progress`: 进度更新 (0% → 25% → 50% → 75% → 100%)
- `completed`: 分析完成
- `error`: 错误信息

---

## 🕷️ 后台自动爬虫系统

### 工作原理

**目标**: 24/7 持续爬取社区数据，保持缓存新鲜度

**调度策略**:
```
Celery Beat (定时调度器)
  ↓
High Tier: 每 1 小时爬取 50 个社区
Medium Tier: 每 6 小时爬取 100 个社区
Low Tier: 每 24 小时爬取 50 个社区
```

### 单个社区爬取流程

```
1. 检查缓存是否过期
   ↓
2. 如果过期 → 调用 Reddit API
   ↓
3. 保存到 posts_raw (冷存储)
   ↓
4. 保存到 posts_hot (热存储, TTL=30天)
   ↓
5. 更新 Redis 缓存 (TTL=24小时)
   ↓
6. 更新 community_cache 元数据
   ↓
7. 记录爬取指标
```

### 并发控制

- **批量大小**: 每批 12 个社区
- **并发数**: 2 个（避免 Reddit API 限流）
- **API 限流**: 60 次/分钟

---

## 💾 数据存储规则

### 冷热分离架构

**设计理念**: 分离"全量历史数据"和"热门近期数据"

```
posts_raw (冷存储)          posts_hot (热存储)
    ↓                           ↓
所有爬取的帖子              最近 30 天的热门帖子
永久保存                    自动过期删除
18,260 条                   17,977 条
查询慢                      查询快 (10倍)
```

### 三级缓存策略

```
Level 1: Redis (内存缓存, TTL=24h)
    ↓ 未命中
Level 2: posts_hot (数据库热存储, TTL=30天)
    ↓ 未命中
Level 3: Reddit API (实时抓取)
```

**缓存命中率**: 90%

### 数据写入规则

**双写策略**:
```python
# 1. 写入冷存储（永久）
INSERT INTO posts_raw (source_post_id, ...) 
VALUES ('abc123', ...)
ON CONFLICT (source_post_id) DO NOTHING;

# 2. 写入热存储（30天）
INSERT INTO posts_hot (source_post_id, expires_at, ...)
VALUES ('abc123', NOW() + INTERVAL '30 days', ...)
ON CONFLICT (source_post_id) DO UPDATE SET ...;
```

**自动清理**:
```sql
-- 每天凌晨 2 点执行
DELETE FROM posts_hot WHERE expires_at < NOW();
```

---

## 🔧 关键技术组件

### 1. Celery 任务队列

**队列分类**:
- `analysis_queue`: 分析任务（4 workers）
- `crawler_queue`: 爬虫任务（2 workers）
- `monitoring_queue`: 监控任务（1 worker）
- `maintenance_queue`: 维护任务（1 worker）

**重试机制**:
- 最大重试次数: 3
- 重试延迟: 指数退避 (2^n 秒)

### 2. SSE 实时通信

**为什么选择 SSE?**
- 单向通信（服务器 → 客户端）
- 自动重连
- 更简单的实现（相比 WebSocket）

**事件格式**:
```json
{
  "event": "progress",
  "task_id": "626e668e-...",
  "stage": 1,
  "total_stages": 2,
  "percentage": 50,
  "data": {
    "communities_found": 12,
    "posts_collected": 234
  }
}
```

### 3. JWT 认证

**Token 结构**:
```json
{
  "sub": "user-uuid",
  "email": "user@example.com",
  "exp": 1234567890
}
```

**认证流程**:
```
1. 用户登录 → 验证密码 → 返回 JWT
2. 前端存储到 localStorage
3. 每次请求携带: Authorization: Bearer <token>
4. 后端验证 token → 提取 user_id
```

---

## 📈 性能指标

### 当前系统状态

| 指标 | 数值 |
|------|------|
| 社区池大小 | 200 个活跃社区 |
| 冷存储帖子数 | 18,260 条 |
| 热存储帖子数 | 17,977 条 |
| 缓存命中率 | 90% |
| 平均分析时间 | 18 秒 |
| 平均社区发现数 | 12 个 |
| 平均帖子收集数 | 317 条 |
| API 调用次数 | 2-5 次/任务 |

### 性能优化

**缓存优先架构**:
- 90% 数据来自预缓存
- 减少 Reddit API 调用 10 倍
- 分析速度提升 5 倍

**冷热分离**:
- 查询速度提升 10 倍
- 存储成本降低 50%

**异步处理**:
- HTTP 响应时间 < 100ms
- 分析任务不阻塞 API

---

## 🎨 架构设计原则

1. **极简架构**: 四表核心 + 辅助表
2. **缓存优先**: 90% 数据来自预缓存
3. **异步处理**: Celery 解耦 HTTP 和分析
4. **实时反馈**: SSE 推送进度
5. **多租户隔离**: 每个用户数据完全独立
6. **冷热分离**: 性能与成本平衡
7. **智能调度**: 分层优先级管理

---

## 🔍 常见问题

### Q1: 为什么需要冷热分离？

**A**: 
- **性能**: 分析时只查询 posts_hot，速度快 10 倍
- **成本**: 冷数据可以迁移到廉价存储
- **维护**: 热数据自动清理，无需手动管理

### Q2: 缓存命中率为什么是 90%？

**A**: 
- 后台爬虫 24/7 持续更新热门社区
- High tier 社区每小时更新一次
- 用户分析时，大部分社区数据已在缓存中

### Q3: 为什么使用 Celery 而不是直接在 API 中处理？

**A**:
- **解耦**: HTTP 层和分析引擎分离
- **异步**: 不阻塞 API 响应
- **重试**: 自动重试失败任务
- **扩展**: 可以水平扩展 Worker 数量

### Q4: 为什么使用 SSE 而不是轮询？

**A**:
- **实时性**: 服务器主动推送，延迟更低
- **效率**: 减少 HTTP 请求次数
- **简单**: 比 WebSocket 更简单

### Q5: 社区池的 200 个社区是如何选择的？

**A**:
- 人工筛选高质量商业/技术社区
- 基于活跃度、帖子质量、用户反馈
- 定期更新和优化

---

## 📚 相关文档

- **完整架构讲解**: `docs/系统架构完整讲解.md`
- **PRD 文档**: `docs/PRD/PRD-INDEX.md`
- **数据模型设计**: `docs/PRD/PRD-01-数据模型.md`
- **分析引擎设计**: `docs/PRD/PRD-03-分析引擎.md`
- **端到端测试报告**: `reports/phase-log/e2e-real-user-test-2025-10-21.md`

---

**文档版本**: 1.0  
**更新日期**: 2025-10-21

