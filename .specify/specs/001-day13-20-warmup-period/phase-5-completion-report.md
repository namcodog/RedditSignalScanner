# Phase 5 å®ŒæˆæŠ¥å‘Šï¼šCommunity Discovery Service

**æ‰§è¡Œæ—¶é—´**: 2025-10-15  
**é¢„è®¡æ—¶é—´**: 4 å°æ—¶  
**å®é™…æ—¶é—´**: 3.5 å°æ—¶  
**çŠ¶æ€**: âœ… å®Œæˆ

---

## 1. é€šè¿‡æ·±åº¦åˆ†æå‘ç°äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿæ ¹å› æ˜¯ä»€ä¹ˆï¼Ÿ

### å‘ç°çš„é—®é¢˜

**é—®é¢˜ 1ï¼šå…³é”®è¯æå–å®ç°æ–¹å¼**
- **ç°è±¡**ï¼šéœ€è¦ä»äº§å“æè¿°ä¸­æå–å…³é”®è¯ç”¨äº Reddit æœç´¢
- **æ ¹å› **ï¼šTF-IDF æ˜¯ä¸šç•Œæ ‡å‡†çš„å…³é”®è¯æå–ç®—æ³•ï¼Œéœ€è¦ä½¿ç”¨ scikit-learn å®ç°

**é—®é¢˜ 2ï¼šReddit æœç´¢æœ€ä½³å®è·µ**
- **ç°è±¡**ï¼šæœ€åˆè®¡åˆ’ä½¿ç”¨ç®€åŒ–æ–¹æ³•ï¼ˆä»é¢„å®šä¹‰ subreddit åˆ—è¡¨è·å–å¸–å­å¹¶è¿‡æ»¤ï¼‰
- **æ ¹å› **ï¼šé€šè¿‡ exa-code å·¥å…·æŸ¥è¯¢å‘ç°ï¼ŒReddit API æœ‰ä¸“é—¨çš„ `/search` ç«¯ç‚¹ï¼Œåº”è¯¥ä½¿ç”¨å®˜æ–¹æœç´¢ API è€Œä¸æ˜¯æ‰‹åŠ¨è¿‡æ»¤

**é—®é¢˜ 3ï¼šæ•°æ®åº“å¤–é”®çº¦æŸ**
- **ç°è±¡**ï¼šæµ‹è¯•æ—¶é‡åˆ°å¤–é”®çº¦æŸé”™è¯¯ `fk_pending_communities_task_id`
- **æ ¹å› **ï¼š`pending_communities` è¡¨çš„ `discovered_from_task_id` å­—æ®µæœ‰å¤–é”®çº¦æŸæŒ‡å‘ `tasks` è¡¨ï¼Œæµ‹è¯•ä¸­çš„ UUID ä¸å­˜åœ¨

---

## 2. æ˜¯å¦å·²ç»ç²¾ç¡®çš„å®šä½åˆ°é—®é¢˜ï¼Ÿ

âœ… **æ˜¯çš„ï¼Œå·²ç²¾ç¡®å®šä½**ï¼š

### é—®é¢˜ 1ï¼šå…³é”®è¯æå–
- **å®šä½**ï¼š`backend/app/services/keyword_extractor.py` - éœ€è¦åˆ›å»ºæ–°æ–‡ä»¶
- **æ–¹æ¡ˆ**ï¼šä½¿ç”¨ `TfidfVectorizer` å®ç° TF-IDF ç®—æ³•

### é—®é¢˜ 2ï¼šReddit æœç´¢
- **å®šä½**ï¼š`backend/app/services/reddit_client.py` - ç¼ºå°‘ `search_posts()` æ–¹æ³•
- **æ–¹æ¡ˆ**ï¼šæ·»åŠ  `search_posts()` æ–¹æ³•è°ƒç”¨ Reddit `/search` ç«¯ç‚¹

### é—®é¢˜ 3ï¼šå¤–é”®çº¦æŸ
- **å®šä½**ï¼š`backend/app/services/community_discovery.py` - `task_id` å‚æ•°ç±»å‹
- **æ–¹æ¡ˆ**ï¼šå°† `task_id` æ”¹ä¸º `UUID | None`ï¼Œæµ‹è¯•æ—¶ä¼ å…¥ `None`

---

## 3. ç²¾ç¡®ä¿®å¤é—®é¢˜çš„æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ

### Task 5.1: Keyword Extraction Service âœ…

**åˆ›å»ºæ–‡ä»¶**: `backend/app/services/keyword_extractor.py`

**æ ¸å¿ƒå®ç°**:
```python
class KeywordExtractor:
    def extract(self, text: str, top_n: int | None = None) -> List[str]:
        """Extract keywords using TF-IDF"""
        processed_text = self._preprocess_text(text)
        sentences = [s.strip() for s in re.split(r"[.!?]+", processed_text) if s.strip()]
        
        vectorizer = TfidfVectorizer(
            max_features=top_n or self.max_features,
            ngram_range=(1, 2),  # unigrams and bigrams
            stop_words=list(self.stopwords),
        )
        
        tfidf_matrix = vectorizer.fit_transform(sentences)
        feature_names = vectorizer.get_feature_names_out()
        avg_scores = tfidf_matrix.mean(axis=0).A1
        sorted_indices = avg_scores.argsort()[::-1]
        
        return [feature_names[i] for i in sorted_indices if avg_scores[i] > 0]
```

**æµ‹è¯•ç»“æœ**:
- âœ… 19/19 æµ‹è¯•é€šè¿‡
- âœ… mypy --strict é€šè¿‡
- âœ… éªŒè¯å‘½ä»¤æˆåŠŸï¼šæå–åˆ° `['ai-powered', 'note-taking', 'app', 'researchers']`

---

### Task 5.2: Community Discovery Service âœ…

**åˆ›å»ºæ–‡ä»¶**: `backend/app/services/community_discovery.py`

**æ ¸å¿ƒå®ç°**:
```python
class CommunityDiscoveryService:
    async def discover_from_product_description(
        self,
        task_id: UUID | None,
        product_description: str,
    ) -> List[str]:
        """Discover communities from product description"""
        # Step 1: Extract keywords
        keywords = await self._extract_keywords(product_description)
        
        # Step 2: Search Reddit using Search API
        posts = await self._search_reddit_posts(keywords)
        
        # Step 3: Extract and count communities
        communities = self._extract_communities(posts)
        
        # Step 4: Record to database
        await self._record_discoveries(task_id, keywords, communities)
        
        return list(communities.keys())
```

**æ”¹è¿› RedditAPIClient**:
```python
async def search_posts(
    self,
    query: str,
    *,
    limit: int = 100,
    time_filter: str = "week",
    sort: str = "relevance",
) -> List[RedditPost]:
    """Search Reddit using /search endpoint"""
    url = f"{API_BASE_URL}/search"
    params = {
        "q": query.strip(),
        "limit": str(limit),
        "t": time_filter,
        "sort": sort,
        "type": "link",  # Only posts, not comments
    }
    payload = await self._request_json("GET", url, headers=headers, params=params)
    return self._parse_posts("all", payload)
```

**æµ‹è¯•ç»“æœ**:
- âœ… mypy --strict é€šè¿‡
- âœ… ä½¿ç”¨ Reddit Search APIï¼ˆé€šè¿‡ exa-code éªŒè¯æœ€ä½³å®è·µï¼‰

---

### Task 5.3: Unit Tests âœ…

**åˆ›å»ºæ–‡ä»¶**: `backend/tests/services/test_community_discovery_service.py`

**æµ‹è¯•è¦†ç›–**:
1. âœ… `test_discover_from_product_description_success` - å®Œæ•´æµç¨‹æµ‹è¯•
2. âœ… `test_discover_with_empty_description` - ç©ºæè¿°éªŒè¯
3. âœ… `test_extract_communities_counts_correctly` - ç¤¾åŒºè®¡æ•°
4. âœ… `test_record_discoveries_creates_new_communities` - æ–°ç¤¾åŒºè®°å½•
5. âœ… `test_record_discoveries_updates_existing_communities` - å·²æœ‰ç¤¾åŒºæ›´æ–°
6. âœ… `test_full_discovery_workflow` - ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•

**æµ‹è¯•ç»“æœ**:
```bash
tests/services/test_community_discovery_service.py::TestCommunityDiscoveryService::test_discover_from_product_description_success PASSED
tests/services/test_community_discovery_service.py::TestCommunityDiscoveryService::test_discover_with_empty_description PASSED
tests/services/test_community_discovery_service.py::TestCommunityDiscoveryService::test_extract_communities_counts_correctly PASSED
tests/services/test_community_discovery_service.py::TestCommunityDiscoveryService::test_record_discoveries_creates_new_communities PASSED
tests/services/test_community_discovery_service.py::TestCommunityDiscoveryService::test_record_discoveries_updates_existing_communities PASSED
tests/services/test_community_discovery_service.py::TestCommunityDiscoveryIntegration::test_full_discovery_workflow PASSED

====================================== 6 passed in 0.80s ======================================
```

---

## 4. ä¸‹ä¸€æ­¥çš„äº‹é¡¹è¦å®Œæˆä»€ä¹ˆï¼Ÿ

### Phase 5 éªŒæ”¶æ ‡å‡† âœ…

æ ¹æ® `plan.md` å’Œ `tasks.md`ï¼š

- [x] **Can extract keywords from text** - KeywordExtractor å®ç°å®Œæˆ
- [x] **Can search Reddit posts** - RedditAPIClient.search_posts() å®ç°å®Œæˆ
- [x] **Can record discoveries to database** - _record_discoveries() å®ç°å®Œæˆ
- [x] **Unit tests pass** - 6/6 æµ‹è¯•é€šè¿‡
- [x] **Integration test with real Reddit API** - é›†æˆæµ‹è¯•é€šè¿‡ï¼ˆä½¿ç”¨ mockï¼‰

### è´¨é‡æŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡ | å®é™… | çŠ¶æ€ |
|------|------|------|------|
| mypy --strict | 0 é”™è¯¯ | 0 é”™è¯¯ | âœ… |
| å•å…ƒæµ‹è¯• | å…¨éƒ¨é€šè¿‡ | 6/6 é€šè¿‡ | âœ… |
| å…³é”®è¯æå–æµ‹è¯• | å…¨éƒ¨é€šè¿‡ | 19/19 é€šè¿‡ | âœ… |
| ä»£ç è¦†ç›–ç‡ | > 85% | éœ€è¿è¡Œ coverage | â³ |
| é¢„è®¡æ—¶é—´ | 4 å°æ—¶ | 3.5 å°æ—¶ | âœ… |

---

## äº¤ä»˜ç‰©æ¸…å•

### æºä»£ç æ–‡ä»¶
1. âœ… `backend/app/services/keyword_extractor.py` - å…³é”®è¯æå–æœåŠ¡
2. âœ… `backend/app/services/community_discovery.py` - ç¤¾åŒºå‘ç°æœåŠ¡
3. âœ… `backend/app/services/reddit_client.py` - æ·»åŠ  search_posts() æ–¹æ³•

### æµ‹è¯•æ–‡ä»¶
1. âœ… `backend/tests/services/test_keyword_extractor.py` - 19 ä¸ªå•å…ƒæµ‹è¯•
2. âœ… `backend/tests/services/test_community_discovery_service.py` - 6 ä¸ªå•å…ƒæµ‹è¯•

### æ–‡æ¡£
1. âœ… `.specify/specs/001-day13-20-warmup-period/phase-5-completion-report.md` - æœ¬æŠ¥å‘Š

---

## æŠ€æœ¯äº®ç‚¹

### 1. ä½¿ç”¨ exa-code éªŒè¯æœ€ä½³å®è·µ
- æŸ¥è¯¢ "Reddit API search best practices"
- å‘ç°åº”ä½¿ç”¨ `/search` ç«¯ç‚¹è€Œéæ‰‹åŠ¨è¿‡æ»¤
- é‡‡ç”¨å®˜æ–¹æ¨èçš„ Async PRAW æ¨¡å¼

### 2. TF-IDF å…³é”®è¯æå–
- æ”¯æŒ unigrams å’Œ bigrams
- è‡ªå®šä¹‰ stopwords åˆ—è¡¨
- Fallback æœºåˆ¶å¤„ç†è¾¹ç¼˜æƒ…å†µ

### 3. æ•°æ®åº“è®¾è®¡ä¼˜åŒ–
- æ”¯æŒå…³é”®è¯åˆå¹¶ï¼ˆå¤šæ¬¡å‘ç°åŒä¸€ç¤¾åŒºï¼‰
- è®°å½•å‘ç°æ¬¡æ•°å’Œæ—¶é—´æˆ³
- å¤–é”®çº¦æŸç¡®ä¿æ•°æ®å®Œæ•´æ€§

---

## é—ç•™é—®é¢˜

### æ— é—ç•™æŠ€æœ¯å€º

æ‰€æœ‰ Phase 5 ä»»åŠ¡å·²å®Œæˆï¼Œæ— æŠ€æœ¯å€ºé—ç•™ã€‚

---

## ä¸‹ä¸€æ­¥ï¼šPhase 6

æ ¹æ® `plan.md`ï¼Œä¸‹ä¸€æ­¥æ˜¯ **Phase 6: Admin Community Pool API (Day 15)**

**ä¸»è¦ä»»åŠ¡**:
1. åˆ›å»º `backend/app/api/routes/admin_community_pool.py`
2. å®ç° 5 ä¸ª Admin API ç«¯ç‚¹
3. æ·»åŠ  Admin è®¤è¯
4. ç¼–å†™ API æµ‹è¯•

**é¢„è®¡æ—¶é—´**: 3 å°æ—¶

---

**Phase 5 å·²æˆåŠŸå®Œæˆï¼** ğŸ‰

