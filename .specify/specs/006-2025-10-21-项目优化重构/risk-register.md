# 风险台账 - Reddit Signal Scanner 项目优化重构

**创建日期**: 2025-10-21  
**负责人**: Tech Lead + PM  
**更新频率**: 每周一更新

---

## 📊 风险等级定义

| 等级 | 符号 | 影响 | 概率 | 应对策略 |
|------|------|------|------|----------|
| **高** | 🔴 | 严重影响交付或质量 | 很可能发生 | 立即缓解，持续监控 |
| **中** | 🟡 | 影响进度或体验 | 可能发生 | 制定缓解计划 |
| **低** | 🟢 | 轻微影响 | 不太可能发生 | 记录备案 |

---

## 🔴 高优先级风险

### R001: 依赖目录入库导致仓库膨胀

**风险描述**:
- `node_modules/` 和 `venv/` 目录被提交到 Git 仓库
- 导致仓库体积膨胀（可能超过 500MB）
- CI/CD 流程缓慢（安装依赖超过 5 分钟）

**影响**:
- 🔴 **严重**: 阻塞所有开发流程
- 开发者 `git clone` 时间过长
- CI/CD 流程效率低下
- GitHub 仓库存储成本增加

**概率**:
- ✅ **已发生**: 当前仓库已包含这些目录

**缓解措施**:
1. **立即执行**（Day 1-2）:
   - 创建 `backend/scripts/cleanup_repo.sh` 脚本
   - 移除 `node_modules/` 和 `venv/` 目录
   - 更新 `.gitignore`
   - 配置 GitHub Actions 依赖缓存

2. **验收标准**:
   - [x] 仓库体积下降 ≥ 50%（实际：99.05%，从 295MB 降至 2.8MB）
   - [x] CI 安装时长下降 ≥ 40%（已配置缓存，待验证）
   - [x] `git log --stat` 不再出现这些目录

**执行结果**（2025-10-22）:
- ✅ **阶段 1**：停止追踪依赖目录（Commit: 640a549）
  - 更新 `.gitignore` 添加明确忽略规则
  - 执行 `git rm -r --cached` 移除 17,698 个文件
  - CI 全部通过（Run #66, #67）

- ✅ **阶段 2**：彻底清理 Git 历史（Commit: 640a549 强制推送）
  - 使用 `git-filter-repo` 重写历史
  - 仓库体积从 295MB 减少到 2.8MB（**99.05% 减少**）
  - 创建备份（~/repo-backup/reddit-signal-scanner.git）
  - 强制推送到 GitHub（main, fix/ci-failures 分支）

- ✅ **阶段 3**：配置 GitHub Actions 依赖缓存（Commit: 2d93237）
  - 升级到 actions/cache@v4
  - 配置 Python 依赖缓存（~/.cache/pip + backend/.venv）
  - 配置 Node.js 依赖缓存（~/.npm + frontend/node_modules）
  - CI 全部通过（Run #68）

**负责人**: Backend Lead
**状态**: ✅ 已解决
**完成日期**: 2025-10-22（提前 1 天完成）

---

### R002: NER F1 分数低于目标（< 0.75）

**风险描述**: 
- NER v1 使用规则/词典方法，可能无法达到 F1 ≥ 0.75 的目标
- 标注集准备不足（需要 200 条高质量标注数据）
- 实体类型复杂（品牌、功能、痛点、价格、平台、场景）

**影响**: 
- 🔴 **严重**: 影响 M1 交付
- 实体抽取质量差，影响后续竞品雷达和趋势分析
- 用户体验下降（实体高亮不准确）

**概率**: 
- 🟡 **中等**: 规则方法通常 F1 在 0.6-0.7 之间

**缓解措施**:
1. **Plan A**（优先）:
   - 使用规则/词典方法 + 精心设计的正则表达式
   - 准备高质量标注集（200 条）
   - 迭代优化规则，目标 F1 ≥ 0.75

2. **Plan B**（降级方案）:
   - 如果 F1 < 0.75，降低目标到 0.65
   - 标记为"实验性功能"
   - 在 M2 引入小模型（spaCy/Flair）提升到 0.75

3. **Plan C**（最坏情况）:
   - 砍掉 NER v1，放到 M2
   - 优先完成其他 M1 任务

**负责人**: Data/ML Lead  
**状态**: 🟡 监控中  
**截止日期**: 2025-11-18（Week 5）

---

### R003: M0 超期（1 周内无法完成）

**风险描述**: 
- M0 包含 5 个用户故事（US1-US5）
- 任务量可能被低估（23 个任务）
- 团队资源不足或遇到技术难题

**影响**: 
- 🔴 **严重**: 影响整体进度
- M1 和 M2 延期
- 团队士气下降

**概率**: 
- 🟡 **中等**: 第一周通常会遇到意外问题

**缓解措施**:
1. **优先级调整**:
   - 如果 Day 5 发现进度落后，砍掉 US4（CSV 导出）
   - 将 CSV 导出放到 M1 Week 2
   - 确保 US1-US3 完成（技术债务清理、质量看板、洞察卡片、E2E 收敛）

2. **每日站会**:
   - 每天 10:00 AM 同步进度
   - 及时发现阻塞问题
   - 调整任务优先级

3. **技术支持**:
   - Tech Lead 随时待命
   - 遇到技术难题立即升级

**负责人**: PM + Tech Lead  
**状态**: 🟡 监控中  
**截止日期**: 2025-10-28（Week 1 结束）

---

## 🟡 中优先级风险

### R004: 去重算法性能差

**风险描述**: 
- MinHash/SimHash 去重算法在大数据量下性能差
- 10,000 条帖子去重耗时超过 1 分钟
- 影响用户体验（分析任务耗时过长）

**影响**: 
- 🟡 **中等**: 影响用户体验
- P95 端到端耗时超过 5 分钟目标

**概率**: 
- 🟢 **低**: `datasketch` 库已优化，性能通常较好

**缓解措施**:
1. **性能基准测试**:
   - 在 Week 4 开始前，先做性能基准测试
   - 测试 10,000 条帖子去重耗时
   - 如果超过 1 分钟，考虑优化方案

2. **优化方案**:
   - 限制样本量（只对最近 30 天的帖子去重）
   - 使用并行处理（multiprocessing）
   - 使用增量去重（只对新帖子去重）

3. **降级方案**:
   - 如果性能仍然差，只使用 MinHash（放弃 SimHash）
   - 降低相似度阈值（从 0.8 降至 0.7）

**负责人**: Data/ML Lead  
**状态**: 🟢 待评估  
**截止日期**: 2025-11-11（Week 4 开始前）

---

### R005: PPT 导出失败

**风险描述**: 
- `python-pptx` 库功能有限
- PPT 模板设计复杂
- 生成的 PPT 格式不符合评审会要求

**影响**: 
- 🟡 **中等**: 影响产品闭环
- 用户无法直接使用 PPT 进行评审会

**概率**: 
- 🟡 **中等**: PPT 生成通常有格式问题

**缓解措施**:
1. **提前设计模板**:
   - 在 Week 3 开始前，先设计 PPT 模板
   - 与 PM 确认模板符合评审会要求
   - 使用简单的布局（标题页、要点页、证据页）

2. **降级方案**:
   - 如果 PPT 生成失败，提供 CSV 导出
   - 用户可以手动将 CSV 数据复制到 PPT

3. **Plan B**:
   - 使用第三方服务（如 Google Slides API）
   - 或者提供 Markdown 导出，用户自行转换

**负责人**: Backend Lead  
**状态**: 🟢 待评估  
**截止日期**: 2025-11-04（Week 3 开始前）

---

### R006: Notion API 限流

**风险描述**: 
- Notion API 有速率限制（每秒 3 个请求）
- 批量导出时可能触发限流
- 导出失败或耗时过长

**影响**: 
- 🟡 **中等**: 影响用户体验
- 用户无法批量导出到 Notion

**概率**: 
- 🟢 **低**: 单次导出通常不会触发限流

**缓解措施**:
1. **速率限制**:
   - 添加重试机制（exponential backoff）
   - 限制导出频率（每分钟最多 10 次）

2. **批量导出优化**:
   - 使用异步任务（Celery）
   - 分批导出（每批 10 条洞察）

3. **用户提示**:
   - 导出时显示进度条
   - 提示用户"导出中，请稍候"

**负责人**: Backend Lead  
**状态**: 🟢 待评估  
**截止日期**: 2025-11-11（Week 3）

---

### R007: 标注集准备慢

**风险描述**: 
- NER v1 需要 200 条高质量标注数据
- 人工标注耗时（每条 5 分钟，总计 16 小时）
- Ops 团队资源不足

**影响**: 
- 🟡 **中等**: 影响 M1 交付
- NER v1 延期

**概率**: 
- 🟡 **中等**: 标注工作通常比预期慢

**缓解措施**:
1. **合成数据**:
   - 使用 GPT-4 生成合成数据（100 条）
   - 人工标注真实数据（100 条）
   - 混合使用，降低标注成本

2. **标注工具**:
   - 使用 Label Studio 或 Prodigy
   - 提升标注效率（每条 2 分钟）

3. **分阶段标注**:
   - Week 5 Day 1-2: 标注 100 条
   - Week 5 Day 3-4: 标注 100 条
   - Week 5 Day 5: 评估 F1

**负责人**: Ops Lead + Data/ML Lead  
**状态**: 🟡 监控中  
**截止日期**: 2025-11-18（Week 5）

---

### R008: 趋势分析算法复杂

**风险描述**: 
- 时序聚类和突发检测算法复杂
- 需要调研 EARS、阈值+滑窗等方法
- 实现和调优耗时

**影响**: 
- 🟡 **中等**: 影响 M2 交付
- 趋势分析 v1 延期

**概率**: 
- 🟡 **中等**: 算法实现通常比预期复杂

**缓解措施**:
1. **简化算法**:
   - 优先使用基于阈值的突发检测
   - 放弃复杂的时序聚类
   - 降低算法复杂度

2. **使用现成库**:
   - 调研现成的突发检测库（如 `pybursts`）
   - 避免从零实现

3. **降级方案**:
   - 如果算法太复杂，砍掉趋势分析 v1
   - 放到下一个季度

**负责人**: Data/ML Lead  
**状态**: 🟢 待评估  
**截止日期**: 2025-12-21（Month 2）

---

## 🟢 低优先级风险

### R009: .env.local 入库

**风险描述**: 
- `.env.local` 文件被提交到 Git 仓库
- 可能包含敏感信息（API Key、密码）

**影响**: 
- 🟢 **低**: 当前自用研究，无敏感信息
- 如果后续包含敏感信息，需要立即更换

**概率**: 
- 🟢 **低**: 当前无敏感信息

**缓解措施**:
1. **记录备案**:
   - 已记录在风险台账
   - 按产品方要求暂不处理

2. **监控**:
   - 定期检查 `.env.local` 内容
   - 如果出现敏感值，立即更换并从 Git 历史中删除

3. **长期方案**:
   - 在 M2 或后续版本中，将 `.env.local` 移除
   - 使用环境变量或密钥管理服务

**负责人**: Tech Lead  
**状态**: 🟢 暂缓  
**截止日期**: N/A

---

### R010: Reddit TOS 合规

**风险描述**: 
- 当前使用 Reddit API 进行数据采集
- 需要遵守 Reddit TOS（服务条款）
- 可能需要速率限制、缓存时长、退订机制

**影响**: 
- 🟢 **低**: 当前自用研究，风险较低
- 如果后续商业化，需要启动合规清单

**概率**: 
- 🟢 **低**: 当前自用研究

**缓解措施**:
1. **记录备案**:
   - 已记录在风险台账
   - 按产品方要求暂不处理

2. **合规清单**（后续版本）:
   - 速率限制（每分钟最多 60 个请求）
   - 缓存时长（最多 30 天）
   - 退订机制（用户可以删除数据）
   - 数据使用声明（明确告知用户数据来源）

3. **长期方案**:
   - 在 M2 或后续版本中，启动合规专项
   - 咨询法律顾问

**负责人**: PM + Tech Lead  
**状态**: 🟢 暂缓  
**截止日期**: N/A

---

### R011: 模型成本漂移

**风险描述**: 
- OpenAI API 价格可能上涨
- 使用量增加导致成本上升
- 单条洞察成本超过预算

**影响**: 
- 🟢 **低**: 当前使用量较小
- 如果后续用户量增加，成本可能成为问题

**概率**: 
- 🟢 **低**: 当前使用量较小

**缓解措施**:
1. **成本跟踪**:
   - 在质量看板中添加 `cost_per_insight` 指标
   - 每周监控成本趋势

2. **缓存策略**:
   - 引入 Embedding 和 LLM 调用缓存
   - 目标缓存命中率 ≥ 60%

3. **成本优化**:
   - 使用更便宜的模型（如 GPT-3.5 替代 GPT-4）
   - 减少不必要的 API 调用

**负责人**: Tech Lead  
**状态**: 🟢 持续监控  
**截止日期**: N/A

---

### R012: 证据失真/误解

**风险描述**: 
- 分析引擎可能误解帖子内容
- 提取的痛点、竞品、机会不准确
- 用户基于错误洞察做决策

**影响**: 
- 🔴 **严重**: 影响产品价值
- 用户信任度下降

**概率**: 
- 🟡 **中等**: 算法不完美，误解难以避免

**缓解措施**:
1. **强制证据链展示**:
   - 每个洞察都必须展示证据段落
   - 用户可以点击查看原帖
   - 用户可以自行验证洞察真实性

2. **人工抽检**:
   - Ops 团队每周抽检 50 条洞察
   - 计算审阅通过率（目标 ≥ 70%）
   - 发现问题及时优化算法

3. **用户反馈**:
   - 添加"报告错误"按钮
   - 用户可以标记不准确的洞察
   - 收集反馈用于算法优化

**负责人**: Data/ML Lead + Ops Lead  
**状态**: 🟡 持续监控  
**截止日期**: N/A

---

## 📊 风险矩阵

| 风险 ID | 风险名称 | 等级 | 影响 | 概率 | 状态 | 负责人 |
|---------|----------|------|------|------|------|--------|
| R001 | 依赖目录入库 | 🔴 高 | 严重 | 已发生 | ✅ 已解决 | Backend Lead |
| R002 | NER F1 < 0.75 | 🔴 高 | 严重 | 中等 | 监控中 | Data/ML Lead |
| R003 | M0 超期 | 🔴 高 | 严重 | 中等 | 监控中 | PM + Tech Lead |
| R004 | 去重算法性能差 | 🟡 中 | 中等 | 低 | 待评估 | Data/ML Lead |
| R005 | PPT 导出失败 | 🟡 中 | 中等 | 中等 | 待评估 | Backend Lead |
| R006 | Notion API 限流 | 🟡 中 | 中等 | 低 | 待评估 | Backend Lead |
| R007 | 标注集准备慢 | 🟡 中 | 中等 | 中等 | 监控中 | Ops + Data/ML |
| R008 | 趋势分析算法复杂 | 🟡 中 | 中等 | 中等 | 待评估 | Data/ML Lead |
| R009 | .env.local 入库 | 🟢 低 | 低 | 低 | 暂缓 | Tech Lead |
| R010 | Reddit TOS 合规 | 🟢 低 | 低 | 低 | 暂缓 | PM + Tech Lead |
| R011 | 模型成本漂移 | 🟢 低 | 低 | 低 | 持续监控 | Tech Lead |
| R012 | 证据失真/误解 | 🔴 高 | 严重 | 中等 | 持续监控 | Data/ML + Ops |

---

## 📅 更新日志

### 2025-10-22
- ✅ **R001 已解决**：依赖目录入库问题彻底解决
  - 仓库体积减少 99.05%（295MB → 2.8MB）
  - 完成三阶段清理（停止追踪 → 清理历史 → 配置缓存）
  - 所有 CI 检查通过
  - 提前 1 天完成（截止日期：2025-10-23）

### 2025-10-21
- ✅ 创建风险台账
- ✅ 识别 12 个风险（3 个高优先级，5 个中优先级，4 个低优先级）
- ✅ 为每个风险制定缓解措施
- ⏳ 待执行：R001（依赖目录入库）缓解措施

---

**下一步行动**: 每周一更新风险状态，及时调整缓解措施

