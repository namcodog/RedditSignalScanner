# 数据存储设计深度分析报告

**生成时间**: 2025-10-24  
**分析范围**: 数据存储结构、冷热分离、SCD2实现、数据流向、设计问题识别  
**数据库版本**: `d18c3d80c75e` (head)

---

## 📊 执行摘要

### 🎯 分析结论

**存储架构**: ✅ **冷热分离 + SCD2版本控制 + 物化视图优化**  
**设计完整性**: ⚠️ **70%完整** (架构设计优秀,但实施不完整)  
**发现问题**: 🔴 **7个严重问题** + 🟡 **5个优化建议**

---

## 1️⃣ 数据存储结构全景

### 1.1 存储分层架构

```
┌─────────────────────────────────────────────────────────────┐
│                     数据存储三层架构                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Layer 1: Redis 缓存 (内存)                                 │
│  ├─ TTL: 24小时                                             │
│  ├─ 用途: 实时分析、快速响应                                 │
│  └─ 管理: CacheManager                                      │
│                                                             │
│  Layer 2: posts_hot (热存储)                                │
│  ├─ TTL: 24-72小时                                          │
│  ├─ 用途: 近期数据分析、看板                                 │
│  ├─ 策略: 覆盖式刷新                                         │
│  └─ 表: posts_hot (11字段,简化版)                           │
│                                                             │
│  Layer 3: posts_raw (冷存储)                                │
│  ├─ 保留: 90天滚动窗口                                       │
│  ├─ 用途: 算法训练、趋势分析、回测                           │
│  ├─ 策略: 增量累积 + SCD2版本控制                            │
│  └─ 表: posts_raw (23字段,完整版)                           │
│                                                             │
│  Layer 3.5: posts_latest (物化视图)                         │
│  ├─ 来源: posts_raw WHERE is_current = TRUE                │
│  ├─ 用途: 快速查询最新版本                                   │
│  └─ 刷新: 定期刷新 (设计中,未实施)                           │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 1.2 核心表结构

#### posts_raw (冷库)

**主键策略**: 
- ✅ 当前: `id BIGSERIAL PRIMARY KEY`
- ✅ 唯一约束: `(source, source_post_id, version)`
- ✅ 索引: 8个索引 (时间、社区、哈希、GIN)

**SCD2字段**:
- `version`: 版本号 (每次编辑+1)
- `is_current`: 是否当前版本
- `valid_from`: 版本生效时间
- `valid_to`: 版本失效时间 (默认 9999-12-31)

**去重机制**:
- `text_norm_hash`: 文本归一化哈希 (MD5)
- 触发器: `trg_fill_normalized_fields` 自动填充

**字段统计**: 23个字段
- 主键: 4个 (id, source, source_post_id, version)
- 时间戳: 4个 (created_at, fetched_at, valid_from, valid_to)
- 内容: 6个 (title, body, body_norm, text_norm_hash, url, lang)
- 元数据: 5个 (subreddit, score, num_comments, is_deleted, edit_count)
- 作者: 2个 (author_id, author_name)
- JSONB: 1个 (metadata)
- SCD2: 1个 (is_current)

#### posts_hot (热缓存)

**主键策略**:
- ✅ 当前: `id BIGSERIAL PRIMARY KEY`
- ✅ 唯一约束: `(source, source_post_id)`
- ✅ 索引: 5个索引 (时间、社区、过期、GIN)

**TTL机制**:
- `expires_at`: 过期时间 (默认 cached_at + 24小时)
- 定期清理: `cleanup_expired_hot_cache()` (设计中,未实施)

**字段统计**: 12个字段 (简化版)
- 主键: 3个 (id, source, source_post_id)
- 时间戳: 3个 (created_at, cached_at, expires_at)
- 内容: 2个 (title, body)
- 元数据: 3个 (subreddit, score, num_comments)
- JSONB: 1个 (metadata)

#### posts_latest (物化视图)

**定义**: `SELECT * FROM posts_raw WHERE is_current = TRUE`

**索引**: 4个索引
- `idx_posts_latest_created_at`: 时间查询
- `idx_posts_latest_subreddit`: 社区查询
- `idx_posts_latest_text_hash`: 去重查询
- `idx_posts_latest_unique`: 唯一性保证

**刷新策略**: ⚠️ **未实施** (设计中有 `refresh_posts_latest()` 函数,但未调用)

---

## 2️⃣ 数据流向完整梳理

### 2.1 数据写入流程

```
┌──────────────┐
│ Reddit API   │
└──────┬───────┘
       │
       ▼
┌──────────────────────────────────────────────────────────┐
│ IncrementalCrawler.crawl_community_incremental()         │
│ ├─ 1. 获取水位线 (community_cache.last_seen_post_id)     │
│ ├─ 2. 抓取新帖子 (Reddit API)                            │
│ ├─ 3. 过滤 (只保留新于水位线的)                          │
│ └─ 4. 双写 (_dual_write)                                │
└──────┬───────────────────────────────────────────────────┘
       │
       ▼
┌──────────────────────────────────────────────────────────┐
│ _dual_write() - 冷热双写策略                             │
│                                                          │
│  ┌─────────────────────┐    ┌─────────────────────┐    │
│  │ 1. 写冷库 (先)       │    │ 2. 写热缓存 (后)     │    │
│  │ _upsert_to_cold_    │    │ _upsert_to_hot_     │    │
│  │ storage()           │    │ cache()             │    │
│  │                     │    │                     │    │
│  │ ├─ 检查是否存在      │    │ ├─ 覆盖式更新        │    │
│  │ ├─ 新增: version=1  │    │ ├─ 更新 expires_at  │    │
│  │ ├─ 更新: version+1  │    │ └─ 更新所有字段      │    │
│  │ └─ 重复: 跳过        │    │                     │    │
│  │                     │    │                     │    │
│  │ ▼                   │    │ ▼                   │    │
│  │ posts_raw           │    │ posts_hot           │    │
│  │ (增量累积)           │    │ (覆盖刷新)           │    │
│  └─────────────────────┘    └─────────────────────┘    │
│                                                          │
└──────────────────────────────────────────────────────────┘
       │
       ▼
┌──────────────────────────────────────────────────────────┐
│ 3. 更新水位线 (community_cache)                          │
│ ├─ last_seen_post_id                                    │
│ ├─ last_seen_created_at                                 │
│ ├─ total_posts_fetched                                  │
│ └─ dedup_rate                                           │
└──────────────────────────────────────────────────────────┘
```

### 2.2 数据读取流程

```
┌──────────────────────────────────────────────────────────┐
│ AnalysisEngine.run_analysis()                            │
└──────┬───────────────────────────────────────────────────┘
       │
       ▼
┌──────────────────────────────────────────────────────────┐
│ DataCollectionService.collect_posts()                    │
│ (Cache-First 策略)                                       │
│                                                          │
│  ┌─────────────────────┐                                │
│  │ 1. Redis 缓存 (优先) │                                │
│  │ CacheManager.get_   │                                │
│  │ cached_posts()      │                                │
│  └─────────┬───────────┘                                │
│            │ ❌ Miss                                     │
│            ▼                                             │
│  ┌─────────────────────┐                                │
│  │ 2. Reddit API (实时) │                                │
│  │ RedditAPIClient.    │                                │
│  │ fetch_subreddit_    │                                │
│  │ posts()             │                                │
│  └─────────┬───────────┘                                │
│            │                                             │
│            ▼                                             │
│  ┌─────────────────────┐                                │
│  │ 3. 写入 Redis 缓存   │                                │
│  │ CacheManager.set_   │                                │
│  │ cached_posts()      │                                │
│  └─────────────────────┘                                │
│                                                          │
└──────────────────────────────────────────────────────────┘
       │
       ▼
┌──────────────────────────────────────────────────────────┐
│ 分析流程                                                  │
│ ├─ 1. 关键词过滤 (_filter_posts_by_keywords)             │
│ ├─ 2. 去重 (deduplicate_posts)                          │
│ ├─ 3. 信号提取 (SignalExtractor.extract)                │
│ └─ 4. 机会评分 (OpportunityScorer.score)                │
└──────────────────────────────────────────────────────────┘
```

**⚠️ 关键发现**: 
- ❌ **分析引擎未使用 posts_hot/posts_raw**
- ❌ **分析引擎只使用 Redis + Reddit API**
- ❌ **posts_latest 物化视图从未被查询**

---

## 3️⃣ 存储设计问题识别

### 🔴 P0 严重问题 (7个)

#### P0-1: 物化视图 posts_latest 从未刷新 ⚠️

**问题**: 
- 设计中有 `refresh_posts_latest()` 函数
- 但从未被调用,物化视图永远是空的
- 当前数据: `SELECT COUNT(*) FROM posts_latest` = **0 行**

**影响**: 
- 物化视图完全无用
- 浪费存储空间和索引维护成本

**证据**:
```bash
$ psql -c "SELECT COUNT(*) FROM posts_latest"
 total_posts_latest 
--------------------
                  0
```

**修复建议**:
1. 添加 Celery Beat 定时任务,每小时刷新一次
2. 或者在 `_dual_write()` 后触发增量刷新
3. 或者删除物化视图,改用普通视图

---

#### P0-2: 热缓存过期数据从未清理 ⚠️

**问题**:
- 设计中有 `cleanup_expired_hot_cache()` 函数 (在 SQL 迁移中)
- 但在 Python 代码中未实现
- `posts_hot` 表会无限增长

**影响**:
- 存储空间浪费
- 查询性能下降
- TTL机制失效

**证据**:
```python
# backend/app/tasks/maintenance_task.py 中有清理逻辑
# 但只在 cleanup_expired_hot_cache_task() 中调用
# 该任务未在 Celery Beat 中配置
```

**修复建议**:
1. 在 `backend/app/core/celery_beat_config.py` 添加定时任务
2. 每小时执行一次 `cleanup_expired_hot_cache_task`

---

#### P0-3: 冷库90天滚动窗口从未执行 ⚠️

**问题**:
- 设计中有 `cleanup_old_posts()` 函数 (在 SQL 迁移中)
- 但在 Python 代码中未实现
- `posts_raw` 表会无限增长

**影响**:
- 存储空间无限增长
- 查询性能持续下降
- 违背"90天滚动窗口"设计原则

**修复建议**:
1. 实现 `cleanup_old_posts_task()` Celery 任务
2. 每天执行一次,删除 90 天前的数据

---

#### P0-4: 分析引擎未使用冷热存储 🔴

**问题**:
- `AnalysisEngine` 只使用 Redis + Reddit API
- 完全忽略 `posts_hot` 和 `posts_raw`
- 冷热分离架构形同虚设

**影响**:
- 浪费存储资源
- 无法利用历史数据做趋势分析
- 无法实现"回测"功能

**证据**:
```python
# backend/app/services/analysis_engine.py
# _fetch_hot_samples() 和 _fetch_cold_samples() 存在
# 但只用于 sample_guard 检查,不用于主分析流程
```

**修复建议**:
1. 修改 `DataCollectionService.collect_posts()`:
   - 优先从 `posts_hot` 读取 (最近 24-72 小时)
   - 补读 `posts_raw` (最近 30 天)
   - 最后才调用 Reddit API
2. 实现三层缓存策略: Redis → posts_hot → posts_raw → Reddit API

---

#### P0-5: SCD2版本控制未正确实施 ⚠️

**问题**:
- `_upsert_to_cold_storage()` 中的 SCD2 逻辑不完整
- 更新时只增加 `version`,未设置旧版本的 `valid_to` 和 `is_current=FALSE`

**影响**:
- 多个版本的 `is_current` 都是 `TRUE`
- `posts_latest` 物化视图会包含重复数据
- 无法正确追踪版本历史

**证据**:
```python
# backend/app/services/incremental_crawler.py:341-370
stmt = stmt.on_conflict_do_update(
    index_elements=["source", "source_post_id", "version"],
    set_={
        "score": excluded.score,
        "num_comments": excluded.num_comments,
        "fetched_at": excluded.fetched_at,
        "version": PostRaw.version + 1,  # ❌ 只增加版本号
    },
)
# ❌ 缺少: 设置旧版本 is_current=FALSE, valid_to=NOW()
```

**修复建议**:
1. 在 `on_conflict_do_update` 前,先更新旧版本:
   ```python
   UPDATE posts_raw 
   SET is_current = FALSE, valid_to = NOW()
   WHERE source = ? AND source_post_id = ? AND is_current = TRUE
   ```
2. 然后插入新版本 (version+1, is_current=TRUE)

---

#### P0-6: 去重哈希可能冲突 ⚠️

**问题**:
- `text_norm_hash` 使用 MD5 哈希
- MD5 已知存在碰撞风险
- 对于大规模数据,可能导致误判

**影响**:
- 不同内容被误判为重复
- 丢失有效数据

**修复建议**:
1. 改用 SHA-256 或 BLAKE2
2. 或者使用 `(text_norm_hash, title, body)` 组合去重

---

#### P0-7: 数据库迁移与 Alembic 不一致 🔴

**问题**:
- `backend/migrations/001_cold_hot_storage.sql` 是手动 SQL 迁移
- 但 Alembic 版本历史中没有对应的迁移文件
- 导致 `posts_raw`, `posts_hot`, `posts_latest` 不在 Alembic 管理下

**影响**:
- `alembic check` 会报错
- 无法回滚迁移
- 团队协作时可能出现数据库不一致

**证据**:
```bash
$ find backend/alembic/versions -name "*cold_hot*"
# 无结果

$ ls backend/migrations/
001_cold_hot_storage.sql  # ❌ 手动 SQL,未纳入 Alembic
```

**修复建议**:
1. 将 `001_cold_hot_storage.sql` 转换为 Alembic 迁移
2. 或者删除 SQL 文件,用 Alembic 重新生成迁移

---

### 🟡 P1 优化建议 (5个)

#### P1-1: posts_hot 缺少 author 字段

**问题**: 热缓存没有作者信息,分析时可能需要

**建议**: 添加 `author_id`, `author_name` 字段

---

#### P1-2: 缺少数据质量监控

**问题**: 无法监控去重率、版本分布、TTL 命中率

**建议**: 
1. 添加 `storage_metrics` 表
2. 记录每日去重率、版本数、过期清理数

---

#### P1-3: 缺少数据归档机制

**问题**: 90天外的数据直接删除,无法恢复

**建议**:
1. 添加 `posts_archive` 表 (S3/Glacier)
2. 归档后再删除

---

#### P1-4: 物化视图刷新策略不明确

**问题**: 不知道何时刷新,刷新频率多少

**建议**:
1. 增量刷新: 每次 `_dual_write()` 后触发
2. 全量刷新: 每天凌晨 3 点

---

#### P1-5: 缺少存储容量预警

**问题**: 无法提前预警存储空间不足

**建议**:
1. 添加 `get_storage_stats()` 定时任务
2. 当存储超过 80% 时发送告警

---

## 4️⃣ 总结与建议

### 4.1 设计评价

**优点** ✅:
1. 冷热分离架构设计优秀
2. SCD2 版本控制思路正确
3. 物化视图优化方向正确
4. 索引设计完整

**缺点** ❌:
1. 设计与实施脱节 (7个P0问题)
2. 维护任务缺失 (清理、刷新、归档)
3. 分析引擎未集成存储层
4. 迁移管理混乱 (SQL + Alembic)

### 4.2 修复优先级

**第一批 (本周)** 🔴:
1. P0-4: 分析引擎集成冷热存储
2. P0-7: 统一迁移管理 (Alembic)
3. P0-5: 修复 SCD2 版本控制

**第二批 (下周)** 🟡:
4. P0-1: 实施物化视图刷新
5. P0-2: 实施热缓存清理
6. P0-3: 实施冷库滚动窗口

**第三批 (长期)** 🟢:
7. P0-6: 升级哈希算法
8. P1-1 ~ P1-5: 优化建议

---

**报告生成时间**: 2025-10-24  
**下一步**: 根据优先级逐一修复问题

