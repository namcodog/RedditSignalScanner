# Day 7 ä»»åŠ¡åˆ†é…ä¸éªŒæ”¶æ–‡æ¡£

> **æ—¥æœŸ**: 2025-10-13 (Day 7)  
> **æ–‡æ¡£ç”¨é€”**: ä»»åŠ¡åˆ†é…ã€è¿›åº¦è·Ÿè¸ªã€éªŒæ”¶æ ‡å‡†  
> **åˆ›å»ºæ—¶é—´**: 2025-10-12 16:00  
> **è´£ä»»äºº**: Lead  
> **å…³é”®é‡Œç¨‹ç¢‘**: ğŸš€ **æ•°æ®é‡‡é›†æ¨¡å—å®Œæˆ + ProgressPageå®Œå–„ + ReportPageå¼€å§‹!**

---

## ğŸ“… Day 7 æ€»ä½“ç›®æ ‡

### Day 6 éªŒæ”¶ç»“æœå›é¡¾
- âœ… **Backend A**: TF-IDF + ç¤¾åŒºå‘ç°ç®—æ³•å®Œæˆ, MyPy 0 errors, 15ä¸ªæµ‹è¯•é€šè¿‡
- âœ… **Backend B**: è®¤è¯ç³»ç»Ÿé›†æˆå®Œæˆ, ä»»åŠ¡ç›‘æ§æ¥å£å¯ç”¨, 7ä¸ªæµ‹è¯•é€šè¿‡
- âœ… **Frontend**: è‡ªåŠ¨è®¤è¯å®ç°, APIé›†æˆæµ‹è¯•11/12é€šè¿‡, ProgressPageç»„ä»¶å®Œæˆ
- âœ… **ç«¯åˆ°ç«¯**: å®Œæ•´æµç¨‹æ‰“é€š, Celeryä»»åŠ¡0.058ç§’æ‰§è¡Œ
- âœ… **æŠ€æœ¯å€º**: 1ä¸ªéé˜»å¡æ€§æµ‹è¯•é—®é¢˜

### Day 7 å…³é”®äº§å‡º
æ ¹æ®`docs/2025-10-10-3äººå¹¶è¡Œå¼€å‘æ–¹æ¡ˆ.md` (ç¬¬191-203è¡Œ):
- ğŸ¯ **æ•°æ®é‡‡é›†æ¨¡å—**: Reddit APIé›†æˆ + ç¼“å­˜ä¼˜å…ˆé€»è¾‘
- ğŸ¯ **è®¤è¯ç³»ç»Ÿæµ‹è¯•**: å®Œæ•´é›†æˆæµ‹è¯• + é›†æˆåˆ°ä¸»API
- ğŸ¯ **å‰ç«¯å¼€å‘**: ProgressPageå®Œå–„ + ReportPageå¼€å§‹å¼€å‘

### Day 7 é‡Œç¨‹ç¢‘
- ğŸ¯ **æ•°æ®é‡‡é›†æ¨¡å—å®Œæˆ** - Reddit API + ç¼“å­˜ä¼˜å…ˆ
- ğŸ¯ **å‰ç«¯2ä¸ªé¡µé¢å®Œæˆ** - ProgressPage + ReportPageåŸºç¡€
- ğŸ¯ **Adminåå°å¯åŠ¨** - Dashboardæ¥å£å¼€å§‹

---

## ğŸ‘¨â€ğŸ’» Backend Aï¼ˆèµ„æ·±åç«¯ï¼‰ä»»åŠ¡æ¸…å•

### æ ¸å¿ƒèŒè´£
1. **å®ç°æ•°æ®é‡‡é›†æ¨¡å—** (ä¼˜å…ˆçº§P0)
2. **Reddit APIå®¢æˆ·ç«¯é›†æˆ** (ä¼˜å…ˆçº§P0)
3. **ç¼“å­˜ä¼˜å…ˆé€»è¾‘å®ç°** (ä¼˜å…ˆçº§P0)

### ä¸Šåˆä»»åŠ¡ (9:00-12:00) - Reddit APIå®¢æˆ·ç«¯

#### 1ï¸âƒ£ å®ç°Reddit APIå®¢æˆ·ç«¯ (2.5å°æ—¶) - ä¼˜å…ˆçº§P0

**ä»»åŠ¡æè¿°**:
åŸºäºPRD-03è®¾è®¡,å®ç°Reddit APIå®¢æˆ·ç«¯,æ”¯æŒå¼‚æ­¥å¹¶å‘é‡‡é›†

**å‚è€ƒæ–‡æ¡£**:
- `docs/PRD/PRD-03-åˆ†æå¼•æ“.md` (ç¬¬138-237è¡Œ)
- `backend/docs/ANALYSIS_ENGINE_DESIGN.md`

**å®ç°æ–‡ä»¶**: `backend/app/services/reddit_client.py`

**æ ¸å¿ƒåŠŸèƒ½**:
```python
"""
Reddit APIå®¢æˆ·ç«¯
åŸºäºPRD-03 Step 2è®¾è®¡
"""
from __future__ import annotations

import asyncio
import aiohttp
from typing import List, Dict, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta

@dataclass
class RedditPost:
    """Redditå¸–å­æ•°æ®ç»“æ„"""
    id: str
    title: str
    selftext: str
    score: int
    num_comments: int
    created_utc: float
    subreddit: str
    author: str
    url: str
    permalink: str

class RedditAPIClient:
    """Reddit APIå®¢æˆ·ç«¯ - æ”¯æŒå¼‚æ­¥å¹¶å‘"""
    
    def __init__(
        self,
        client_id: str,
        client_secret: str,
        user_agent: str,
        rate_limit: int = 60  # æ¯åˆ†é’Ÿè¯·æ±‚æ•°
    ):
        self.client_id = client_id
        self.client_secret = client_secret
        self.user_agent = user_agent
        self.rate_limit = rate_limit
        self.access_token: Optional[str] = None
        self.token_expires_at: Optional[datetime] = None
    
    async def authenticate(self) -> None:
        """OAuth2è®¤è¯è·å–access_token"""
        # å®ç°OAuth2æµç¨‹
        pass
    
    async def fetch_subreddit_posts(
        self,
        subreddit: str,
        limit: int = 100,
        time_filter: str = "week"
    ) -> List[RedditPost]:
        """
        è·å–subredditçš„çƒ­é—¨å¸–å­
        
        Args:
            subreddit: ç¤¾åŒºåç§°
            limit: è·å–æ•°é‡(æœ€å¤š100)
            time_filter: æ—¶é—´èŒƒå›´(hour/day/week/month/year/all)
        
        Returns:
            å¸–å­åˆ—è¡¨
        """
        # å®ç°APIè°ƒç”¨
        pass
    
    async def fetch_multiple_subreddits(
        self,
        subreddits: List[str],
        limit_per_subreddit: int = 100
    ) -> Dict[str, List[RedditPost]]:
        """
        å¹¶å‘è·å–å¤šä¸ªsubredditçš„å¸–å­
        
        Args:
            subreddits: ç¤¾åŒºåˆ—è¡¨
            limit_per_subreddit: æ¯ä¸ªç¤¾åŒºè·å–æ•°é‡
        
        Returns:
            {subreddit: [posts]}
        """
        # å®ç°å¹¶å‘é‡‡é›†
        tasks = [
            self.fetch_subreddit_posts(sub, limit_per_subreddit)
            for sub in subreddits
        ]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        return {
            sub: posts if not isinstance(posts, Exception) else []
            for sub, posts in zip(subreddits, results)
        }
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] RedditAPIClientç±»å®ç°å®Œæˆ
- [ ] OAuth2è®¤è¯æµç¨‹å·¥ä½œæ­£å¸¸
- [ ] å•ä¸ªsubredditè·å–åŠŸèƒ½å¯ç”¨
- [ ] å¹¶å‘è·å–å¤šä¸ªsubredditåŠŸèƒ½å¯ç”¨
- [ ] é€Ÿç‡é™åˆ¶æ§åˆ¶å®ç°(60è¯·æ±‚/åˆ†é’Ÿ)
- [ ] é”™è¯¯å¤„ç†å®Œå–„(ç½‘ç»œé”™è¯¯ã€APIé”™è¯¯ã€è¶…æ—¶)
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡>80%
- [ ] MyPy --strict 0 errors

**æµ‹è¯•æ–‡ä»¶**: `backend/tests/services/test_reddit_client.py`

**æµ‹è¯•ç”¨ä¾‹**:
```python
import pytest
from app.services.reddit_client import RedditAPIClient

@pytest.mark.asyncio
async def test_authenticate():
    """æµ‹è¯•OAuth2è®¤è¯"""
    client = RedditAPIClient(
        client_id="test_id",
        client_secret="test_secret",
        user_agent="test_agent"
    )
    await client.authenticate()
    assert client.access_token is not None

@pytest.mark.asyncio
async def test_fetch_subreddit_posts():
    """æµ‹è¯•è·å–å•ä¸ªsubredditå¸–å­"""
    client = RedditAPIClient(...)
    posts = await client.fetch_subreddit_posts("python", limit=10)
    assert len(posts) <= 10
    assert all(isinstance(p.score, int) for p in posts)

@pytest.mark.asyncio
async def test_fetch_multiple_subreddits():
    """æµ‹è¯•å¹¶å‘è·å–å¤šä¸ªsubreddit"""
    client = RedditAPIClient(...)
    results = await client.fetch_multiple_subreddits(
        ["python", "javascript", "golang"],
        limit_per_subreddit=50
    )
    assert len(results) == 3
    assert all(len(posts) <= 50 for posts in results.values())

@pytest.mark.asyncio
async def test_rate_limiting():
    """æµ‹è¯•é€Ÿç‡é™åˆ¶"""
    client = RedditAPIClient(..., rate_limit=10)
    # å‘é€20ä¸ªè¯·æ±‚,åº”è¯¥è¢«é™é€Ÿ
    start = time.time()
    await client.fetch_multiple_subreddits(["test"] * 20)
    duration = time.time() - start
    assert duration >= 60  # è‡³å°‘éœ€è¦1åˆ†é’Ÿ
```

---

#### 2ï¸âƒ£ å®ç°ç¼“å­˜ä¼˜å…ˆé€»è¾‘ (30åˆ†é’Ÿ) - ä¼˜å…ˆçº§P0

**ä»»åŠ¡æè¿°**:
å®ç°ç¼“å­˜ä¼˜å…ˆçš„æ•°æ®é‡‡é›†ç­–ç•¥,æœ€å¤§åŒ–åˆ©ç”¨Redisç¼“å­˜

**å‚è€ƒæ–‡æ¡£**:
- `docs/PRD/PRD-03-åˆ†æå¼•æ“.md` (ç¬¬8-26è¡Œ)

**å®ç°æ–‡ä»¶**: `backend/app/services/cache_manager.py`

**æ ¸å¿ƒåŠŸèƒ½**:
```python
"""
ç¼“å­˜ç®¡ç†å™¨ - ç¼“å­˜ä¼˜å…ˆç­–ç•¥
åŸºäºPRD-03ç¼“å­˜ä¼˜å…ˆæ¶æ„
"""
from __future__ import annotations

import redis
import json
from typing import List, Dict, Optional
from datetime import datetime, timedelta

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨ - Redisç¼“å­˜å±‚"""
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
        self.cache_ttl = 86400  # 24å°æ—¶
    
    def get_cached_posts(
        self,
        subreddit: str,
        max_age_hours: int = 24
    ) -> Optional[List[Dict]]:
        """
        ä»ç¼“å­˜è·å–å¸–å­æ•°æ®
        
        Args:
            subreddit: ç¤¾åŒºåç§°
            max_age_hours: æœ€å¤§ç¼“å­˜å¹´é¾„(å°æ—¶)
        
        Returns:
            ç¼“å­˜çš„å¸–å­åˆ—è¡¨,å¦‚æœä¸å­˜åœ¨æˆ–è¿‡æœŸè¿”å›None
        """
        key = f"reddit:posts:{subreddit}"
        data = self.redis.get(key)
        
        if data is None:
            return None
        
        cached = json.loads(data)
        cached_at = datetime.fromisoformat(cached["cached_at"])
        
        if datetime.now() - cached_at > timedelta(hours=max_age_hours):
            return None  # ç¼“å­˜è¿‡æœŸ
        
        return cached["posts"]
    
    def set_cached_posts(
        self,
        subreddit: str,
        posts: List[Dict]
    ) -> None:
        """ç¼“å­˜å¸–å­æ•°æ®"""
        key = f"reddit:posts:{subreddit}"
        data = {
            "cached_at": datetime.now().isoformat(),
            "posts": posts
        }
        self.redis.setex(key, self.cache_ttl, json.dumps(data))
    
    def calculate_cache_hit_rate(
        self,
        subreddits: List[str]
    ) -> float:
        """
        è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡
        
        Returns:
            å‘½ä¸­ç‡ (0.0-1.0)
        """
        hits = sum(
            1 for sub in subreddits
            if self.get_cached_posts(sub) is not None
        )
        return hits / len(subreddits) if subreddits else 0.0
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] CacheManagerç±»å®ç°å®Œæˆ
- [ ] ç¼“å­˜è¯»å–åŠŸèƒ½å¯ç”¨
- [ ] ç¼“å­˜å†™å…¥åŠŸèƒ½å¯ç”¨
- [ ] ç¼“å­˜è¿‡æœŸæ£€æŸ¥æ­£ç¡®
- [ ] ç¼“å­˜å‘½ä¸­ç‡è®¡ç®—å‡†ç¡®
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡>80%
- [ ] MyPy --strict 0 errors

---

### ä¸‹åˆä»»åŠ¡ (14:00-18:00) - æ•°æ®é‡‡é›†æ¨¡å—é›†æˆ

#### 3ï¸âƒ£ å®ç°æ•°æ®é‡‡é›†æœåŠ¡ (3å°æ—¶) - ä¼˜å…ˆçº§P0

**ä»»åŠ¡æè¿°**:
é›†æˆReddit APIå®¢æˆ·ç«¯å’Œç¼“å­˜ç®¡ç†å™¨,å®ç°å®Œæ•´çš„æ•°æ®é‡‡é›†æµç¨‹

**å®ç°æ–‡ä»¶**: `backend/app/services/data_collection.py`

**æ ¸å¿ƒåŠŸèƒ½**:
```python
"""
æ•°æ®é‡‡é›†æœåŠ¡ - ç¼“å­˜ä¼˜å…ˆ + APIè¡¥å……
åŸºäºPRD-03 Step 2è®¾è®¡
"""
from __future__ import annotations

from typing import List, Dict
from dataclasses import dataclass

from app.services.reddit_client import RedditAPIClient, RedditPost
from app.services.cache_manager import CacheManager

@dataclass
class CollectionResult:
    """æ•°æ®é‡‡é›†ç»“æœ"""
    total_posts: int
    cache_hits: int
    api_calls: int
    cache_hit_rate: float
    posts_by_subreddit: Dict[str, List[RedditPost]]

class DataCollectionService:
    """æ•°æ®é‡‡é›†æœåŠ¡ - ç¼“å­˜ä¼˜å…ˆç­–ç•¥"""
    
    def __init__(
        self,
        reddit_client: RedditAPIClient,
        cache_manager: CacheManager
    ):
        self.reddit = reddit_client
        self.cache = cache_manager
    
    async def collect_posts(
        self,
        subreddits: List[str],
        limit_per_subreddit: int = 100
    ) -> CollectionResult:
        """
        é‡‡é›†å¸–å­æ•°æ® - ç¼“å­˜ä¼˜å…ˆç­–ç•¥
        
        æµç¨‹:
        1. æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
        2. ä»ç¼“å­˜è·å–å·²æœ‰æ•°æ®
        3. APIè¡¥å……ç¼ºå¤±æ•°æ®
        4. æ›´æ–°ç¼“å­˜
        
        Args:
            subreddits: ç¤¾åŒºåˆ—è¡¨
            limit_per_subreddit: æ¯ä¸ªç¤¾åŒºè·å–æ•°é‡
        
        Returns:
            é‡‡é›†ç»“æœ
        """
        # 1. æ£€æŸ¥ç¼“å­˜
        cache_hit_rate = self.cache.calculate_cache_hit_rate(subreddits)
        
        posts_by_subreddit = {}
        cache_hits = 0
        api_calls = 0
        
        # 2. ä»ç¼“å­˜è·å–
        for subreddit in subreddits:
            cached_posts = self.cache.get_cached_posts(subreddit)
            if cached_posts:
                posts_by_subreddit[subreddit] = cached_posts
                cache_hits += 1
            else:
                # 3. APIè¡¥å……
                posts = await self.reddit.fetch_subreddit_posts(
                    subreddit,
                    limit=limit_per_subreddit
                )
                posts_by_subreddit[subreddit] = posts
                api_calls += 1
                
                # 4. æ›´æ–°ç¼“å­˜
                self.cache.set_cached_posts(subreddit, posts)
        
        total_posts = sum(len(posts) for posts in posts_by_subreddit.values())
        
        return CollectionResult(
            total_posts=total_posts,
            cache_hits=cache_hits,
            api_calls=api_calls,
            cache_hit_rate=cache_hit_rate,
            posts_by_subreddit=posts_by_subreddit
        )
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] DataCollectionServiceç±»å®ç°å®Œæˆ
- [ ] ç¼“å­˜ä¼˜å…ˆé€»è¾‘æ­£ç¡®å®ç°
- [ ] APIè¡¥å……é€»è¾‘æ­£ç¡®å®ç°
- [ ] ç¼“å­˜æ›´æ–°é€»è¾‘æ­£ç¡®å®ç°
- [ ] é‡‡é›†ç»“æœç»Ÿè®¡å‡†ç¡®
- [ ] é›†æˆæµ‹è¯•é€šè¿‡
- [ ] MyPy --strict 0 errors

**é›†æˆæµ‹è¯•**: `backend/tests/services/test_data_collection.py`

```python
@pytest.mark.asyncio
async def test_data_collection_cache_first():
    """æµ‹è¯•ç¼“å­˜ä¼˜å…ˆç­–ç•¥"""
    # æ¨¡æ‹Ÿç¼“å­˜å‘½ä¸­ç‡80%
    result = await service.collect_posts(
        subreddits=["python", "javascript", "golang", "rust", "java"],
        limit_per_subreddit=100
    )
    
    assert result.cache_hit_rate >= 0.6  # è‡³å°‘60%å‘½ä¸­
    assert result.api_calls <= 2  # æœ€å¤š2ä¸ªAPIè°ƒç”¨
    assert result.total_posts >= 300  # è‡³å°‘300ä¸ªå¸–å­
```

---

#### 4ï¸âƒ£ é›†æˆåˆ°åˆ†æä»»åŠ¡ (1å°æ—¶) - ä¼˜å…ˆçº§P0

**ä»»åŠ¡æè¿°**:
å°†æ•°æ®é‡‡é›†æ¨¡å—é›†æˆåˆ°Celeryåˆ†æä»»åŠ¡ä¸­

**ä¿®æ”¹æ–‡ä»¶**: `backend/app/tasks/analysis_task.py`

**é›†æˆä»£ç **:
```python
from app.services.data_collection import DataCollectionService
from app.services.analysis.community_discovery import discover_communities

@celery_app.task(name="tasks.analysis.run", bind=True)
def run_analysis_task(
    self,
    task_id: str,
    product_description: str,
    user_id: str
) -> Dict[str, Any]:
    """
    æ‰§è¡Œåˆ†æä»»åŠ¡
    
    æµç¨‹:
    1. ç¤¾åŒºå‘ç° (Day 6å·²å®Œæˆ)
    2. æ•°æ®é‡‡é›† (Day 7æ–°å¢)
    3. ä¿¡å·æå– (Day 8)
    4. æ’åºè¾“å‡º (Day 8)
    """
    # Step 1: ç¤¾åŒºå‘ç°
    communities = discover_communities(product_description, limit=20)
    subreddits = [c.name for c in communities]
    
    # Step 2: æ•°æ®é‡‡é›† (æ–°å¢)
    collection_service = DataCollectionService(reddit_client, cache_manager)
    collection_result = await collection_service.collect_posts(
        subreddits=subreddits,
        limit_per_subreddit=100
    )
    
    # æ›´æ–°ä»»åŠ¡è¿›åº¦
    update_task_progress(task_id, progress=50, message="æ•°æ®é‡‡é›†å®Œæˆ")
    
    # TODO: Step 3 & 4 (Day 8)
    
    return {
        "task_id": task_id,
        "status": "completed",
        "communities_found": len(communities),
        "posts_collected": collection_result.total_posts,
        "cache_hit_rate": collection_result.cache_hit_rate
    }
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] æ•°æ®é‡‡é›†é›†æˆåˆ°ä»»åŠ¡æµç¨‹
- [ ] ä»»åŠ¡è¿›åº¦æ›´æ–°æ­£ç¡®
- [ ] ç«¯åˆ°ç«¯æµ‹è¯•é€šè¿‡
- [ ] Celeryä»»åŠ¡æ‰§è¡ŒæˆåŠŸ

---

## ğŸ‘¨â€ğŸ’» Backend Bï¼ˆæ”¯æ’‘åç«¯ï¼‰ä»»åŠ¡æ¸…å•

### æ ¸å¿ƒèŒè´£
1. **è®¤è¯ç³»ç»Ÿå®Œæ•´æµ‹è¯•** (ä¼˜å…ˆçº§P0)
2. **é›†æˆè®¤è¯åˆ°ä¸»API** (ä¼˜å…ˆçº§P0)
3. **å¼€å§‹Adminåå°å¼€å‘** (ä¼˜å…ˆçº§P1)

### ä¸Šåˆä»»åŠ¡ (9:00-12:00) - è®¤è¯ç³»ç»Ÿæµ‹è¯•

#### 1ï¸âƒ£ å®Œå–„è®¤è¯é›†æˆæµ‹è¯• (2å°æ—¶) - ä¼˜å…ˆçº§P0

**ä»»åŠ¡æè¿°**:
è¡¥å……å®Œæ•´çš„è®¤è¯ç³»ç»Ÿé›†æˆæµ‹è¯•,è¦†ç›–æ‰€æœ‰è¾¹ç•Œæƒ…å†µ

**æµ‹è¯•æ–‡ä»¶**: `backend/tests/api/test_auth_complete.py`

**æµ‹è¯•ç”¨ä¾‹**:
```python
"""
è®¤è¯ç³»ç»Ÿå®Œæ•´æµ‹è¯•
åŸºäºPRD-06ç”¨æˆ·è®¤è¯ç³»ç»Ÿ
"""
import pytest
from fastapi.testclient import TestClient

def test_register_success(client: TestClient):
    """æµ‹è¯•æ³¨å†ŒæˆåŠŸ"""
    response = client.post("/api/auth/register", json={
        "email": "newuser@example.com",
        "password": "SecurePass123!"
    })
    assert response.status_code == 200
    data = response.json()
    assert "access_token" in data
    assert data["user"]["email"] == "newuser@example.com"

def test_register_duplicate_email(client: TestClient):
    """æµ‹è¯•é‡å¤é‚®ç®±æ³¨å†Œ"""
    # ç¬¬ä¸€æ¬¡æ³¨å†Œ
    client.post("/api/auth/register", json={
        "email": "duplicate@example.com",
        "password": "Pass123!"
    })
    # ç¬¬äºŒæ¬¡æ³¨å†Œç›¸åŒé‚®ç®±
    response = client.post("/api/auth/register", json={
        "email": "duplicate@example.com",
        "password": "Pass123!"
    })
    assert response.status_code == 409  # Conflict

def test_login_success(client: TestClient):
    """æµ‹è¯•ç™»å½•æˆåŠŸ"""
    # å…ˆæ³¨å†Œ
    client.post("/api/auth/register", json={
        "email": "login@example.com",
        "password": "Pass123!"
    })
    # ç™»å½•
    response = client.post("/api/auth/login", json={
        "email": "login@example.com",
        "password": "Pass123!"
    })
    assert response.status_code == 200
    assert "access_token" in response.json()

def test_login_wrong_password(client: TestClient):
    """æµ‹è¯•é”™è¯¯å¯†ç """
    client.post("/api/auth/register", json={
        "email": "user@example.com",
        "password": "CorrectPass123!"
    })
    response = client.post("/api/auth/login", json={
        "email": "user@example.com",
        "password": "WrongPass123!"
    })
    assert response.status_code == 401

def test_token_expiration(client: TestClient):
    """æµ‹è¯•Tokenè¿‡æœŸ"""
    # ä½¿ç”¨è¿‡æœŸTokenè®¿é—®å—ä¿æŠ¤ç«¯ç‚¹
    expired_token = "eyJ..."  # è¿‡æœŸçš„Token
    response = client.get(
        "/api/status/some-task-id",
        headers={"Authorization": f"Bearer {expired_token}"}
    )
    assert response.status_code == 401

def test_multi_tenant_isolation(client: TestClient):
    """æµ‹è¯•å¤šç§Ÿæˆ·éš”ç¦»"""
    # ç”¨æˆ·Aåˆ›å»ºä»»åŠ¡
    token_a = register_and_login("usera@example.com")
    task_response = client.post(
        "/api/analyze",
        headers={"Authorization": f"Bearer {token_a}"},
        json={"product_description": "Test product"}
    )
    task_id = task_response.json()["task_id"]
    
    # ç”¨æˆ·Bå°è¯•è®¿é—®ç”¨æˆ·Açš„ä»»åŠ¡
    token_b = register_and_login("userb@example.com")
    response = client.get(
        f"/api/status/{task_id}",
        headers={"Authorization": f"Bearer {token_b}"}
    )
    assert response.status_code == 403  # Forbidden
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] æ³¨å†ŒåŠŸèƒ½æµ‹è¯•å®Œæ•´
- [ ] ç™»å½•åŠŸèƒ½æµ‹è¯•å®Œæ•´
- [ ] TokenéªŒè¯æµ‹è¯•å®Œæ•´
- [ ] å¤šç§Ÿæˆ·éš”ç¦»æµ‹è¯•é€šè¿‡
- [ ] è¾¹ç•Œæƒ…å†µè¦†ç›–å®Œæ•´
- [ ] æµ‹è¯•è¦†ç›–ç‡>90%
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡

---

### ä¸‹åˆä»»åŠ¡ (14:00-18:00) - Adminåå°å¼€å‘

#### 2ï¸âƒ£ è®¾è®¡Adminåå°API (2å°æ—¶) - ä¼˜å…ˆçº§P1

**ä»»åŠ¡æè¿°**:
è®¾è®¡Adminåå°Dashboard API,æä¾›ç³»ç»Ÿç›‘æ§æ•°æ®

**å‚è€ƒæ–‡æ¡£**:
- `docs/PRD/PRD-07-Adminåå°.md`

**å®ç°æ–‡ä»¶**: `backend/app/api/routes/admin.py`

**APIè®¾è®¡**:
```python
"""
Adminåå°API
åŸºäºPRD-07è®¾è®¡
"""
from fastapi import APIRouter, Depends
from app.core.auth import require_admin

router = APIRouter(prefix="/api/admin", tags=["admin"])

@router.get("/dashboard/stats")
async def get_dashboard_stats(
    current_user = Depends(require_admin)
):
    """
    è·å–Dashboardç»Ÿè®¡æ•°æ®
    
    Returns:
        {
            "total_users": 1234,
            "total_tasks": 5678,
            "tasks_today": 123,
            "avg_processing_time": 45.6,
            "cache_hit_rate": 0.85,
            "active_workers": 4
        }
    """
    pass

@router.get("/tasks/recent")
async def get_recent_tasks(
    limit: int = 50,
    current_user = Depends(require_admin)
):
    """è·å–æœ€è¿‘çš„ä»»åŠ¡åˆ—è¡¨"""
    pass

@router.get("/users/active")
async def get_active_users(
    limit: int = 50,
    current_user = Depends(require_admin)
):
    """è·å–æ´»è·ƒç”¨æˆ·åˆ—è¡¨"""
    pass
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] Admin APIè·¯ç”±è®¾è®¡å®Œæˆ
- [ ] Dashboardç»Ÿè®¡æ¥å£å®ç°
- [ ] æƒé™æ§åˆ¶å®ç°(require_admin)
- [ ] APIæ–‡æ¡£å®Œæ•´
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡

---

## ğŸ‘©â€ğŸ’» Frontendï¼ˆå…¨æ ˆå‰ç«¯ï¼‰ä»»åŠ¡æ¸…å•

### æ ¸å¿ƒèŒè´£
1. **ProgressPageå®Œå–„** (ä¼˜å…ˆçº§P0)
2. **ReportPageå¼€å§‹å¼€å‘** (ä¼˜å…ˆçº§P0)
3. **è¿›åº¦æ¡ç»„ä»¶ä¼˜åŒ–** (ä¼˜å…ˆçº§P1)

### ä¸Šåˆä»»åŠ¡ (9:00-12:00) - ProgressPageå®Œå–„

#### 1ï¸âƒ£ å®ç°SSEè½®è¯¢é™çº§ (2å°æ—¶) - ä¼˜å…ˆçº§P0

**ä»»åŠ¡æè¿°**:
ä¸ºProgressPageæ·»åŠ SSEè¿æ¥å¤±è´¥æ—¶çš„è½®è¯¢é™çº§æœºåˆ¶

**ä¿®æ”¹æ–‡ä»¶**: `frontend/src/pages/ProgressPage.tsx`

**å®ç°ä»£ç **:
```typescript
/**
 * ProgressPage - è¿›åº¦å±•ç¤ºé¡µé¢
 * æ”¯æŒSSEå®æ—¶æ›´æ–° + è½®è¯¢é™çº§
 */
import { useState, useEffect } from 'react';
import { useParams } from 'react-router-dom';
import { getTaskStatus } from '@/api/analyze.api';
import { connectSSE } from '@/api/sse.client';

export default function ProgressPage() {
  const { taskId } = useParams<{ taskId: string }>();
  const [progress, setProgress] = useState(0);
  const [message, setMessage] = useState('ä»»åŠ¡æ’é˜Ÿä¸­...');
  const [usePolling, setUsePolling] = useState(false);
  
  useEffect(() => {
    if (!taskId) return;
    
    // å°è¯•SSEè¿æ¥
    const eventSource = connectSSE(taskId, {
      onProgress: (data) => {
        setProgress(data.progress);
        setMessage(data.message);
      },
      onComplete: () => {
        navigate(`/report/${taskId}`);
      },
      onError: (error) => {
        console.error('[SSE Error]', error);
        // SSEå¤±è´¥,åˆ‡æ¢åˆ°è½®è¯¢
        setUsePolling(true);
      }
    });
    
    return () => {
      eventSource?.close();
    };
  }, [taskId]);
  
  // è½®è¯¢é™çº§
  useEffect(() => {
    if (!usePolling || !taskId) return;
    
    const pollInterval = setInterval(async () => {
      try {
        const status = await getTaskStatus(taskId);
        setProgress(status.progress);
        setMessage(status.message);
        
        if (status.status === 'completed') {
          clearInterval(pollInterval);
          navigate(`/report/${taskId}`);
        }
      } catch (error) {
        console.error('[Polling Error]', error);
      }
    }, 2000);  // æ¯2ç§’è½®è¯¢ä¸€æ¬¡
    
    return () => clearInterval(pollInterval);
  }, [usePolling, taskId]);
  
  return (
    <div className="progress-page">
      <h1>åˆ†æè¿›è¡Œä¸­...</h1>
      <ProgressBar value={progress} />
      <p>{message}</p>
      {usePolling && (
        <p className="text-sm text-muted">
          å®æ—¶è¿æ¥å¤±è´¥,å·²åˆ‡æ¢åˆ°è½®è¯¢æ¨¡å¼
        </p>
      )}
    </div>
  );
}
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] SSEè¿æ¥æ­£å¸¸å·¥ä½œ
- [ ] SSEå¤±è´¥è‡ªåŠ¨åˆ‡æ¢è½®è¯¢
- [ ] è½®è¯¢é—´éš”åˆç†(2ç§’)
- [ ] è¿›åº¦æ›´æ–°æµç•…
- [ ] å®Œæˆåè‡ªåŠ¨è·³è½¬
- [ ] TypeScript 0 errors
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡

---

### ä¸‹åˆä»»åŠ¡ (14:00-18:00) - ReportPageå¼€å‘

#### 2ï¸âƒ£ å®ç°ReportPageåŸºç¡€ç»“æ„ (3å°æ—¶) - ä¼˜å…ˆçº§P0

**ä»»åŠ¡æè¿°**:
åˆ›å»ºReportPageç»„ä»¶,å±•ç¤ºåˆ†ææŠ¥å‘ŠåŸºç¡€ç»“æ„

**æ–°å»ºæ–‡ä»¶**: `frontend/src/pages/ReportPage.tsx`

**å®ç°ä»£ç **:
```typescript
/**
 * ReportPage - åˆ†ææŠ¥å‘Šé¡µé¢
 * åŸºäºPRD-05å‰ç«¯äº¤äº’è®¾è®¡
 */
import { useState, useEffect } from 'react';
import { useParams } from 'react-router-dom';
import { getAnalysisReport } from '@/api/analyze.api';
import type { AnalysisReport } from '@/types';

export default function ReportPage() {
  const { taskId } = useParams<{ taskId: string }>();
  const [report, setReport] = useState<AnalysisReport | null>(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  
  useEffect(() => {
    if (!taskId) return;
    
    const fetchReport = async () => {
      try {
        setLoading(true);
        const data = await getAnalysisReport(taskId);
        setReport(data);
      } catch (err) {
        setError('è·å–æŠ¥å‘Šå¤±è´¥,è¯·ç¨åé‡è¯•');
        console.error('[Report Error]', err);
      } finally {
        setLoading(false);
      }
    };
    
    fetchReport();
  }, [taskId]);
  
  if (loading) {
    return <div>åŠ è½½æŠ¥å‘Šä¸­...</div>;
  }
  
  if (error) {
    return <div className="error">{error}</div>;
  }
  
  if (!report) {
    return <div>æŠ¥å‘Šä¸å­˜åœ¨</div>;
  }
  
  return (
    <div className="report-page">
      <header>
        <h1>åˆ†ææŠ¥å‘Š</h1>
        <p>ä»»åŠ¡ID: {taskId}</p>
      </header>
      
      <section className="report-summary">
        <h2>æ¦‚è§ˆ</h2>
        <div className="stats">
          <div>ç¤¾åŒºæ•°: {report.communities_analyzed}</div>
          <div>å¸–å­æ•°: {report.posts_analyzed}</div>
          <div>ä¿¡å·æ•°: {report.signals_found}</div>
        </div>
      </section>
      
      <section className="report-signals">
        <h2>å‘ç°çš„ä¿¡å·</h2>
        {/* TODO: Day 8å®ç°ä¿¡å·åˆ—è¡¨ */}
        <p>ä¿¡å·åˆ—è¡¨å°†åœ¨Day 8å®ç°</p>
      </section>
      
      <section className="report-communities">
        <h2>ç›¸å…³ç¤¾åŒº</h2>
        {/* TODO: Day 8å®ç°ç¤¾åŒºåˆ—è¡¨ */}
        <p>ç¤¾åŒºåˆ—è¡¨å°†åœ¨Day 8å®ç°</p>
      </section>
    </div>
  );
}
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] ReportPageç»„ä»¶åˆ›å»ºå®Œæˆ
- [ ] æŠ¥å‘Šè·å–é€»è¾‘å®ç°
- [ ] åŠ è½½çŠ¶æ€å±•ç¤º
- [ ] é”™è¯¯å¤„ç†å®Œå–„
- [ ] åŸºç¡€å¸ƒå±€å®Œæˆ
- [ ] TypeScript 0 errors
- [ ] è·¯ç”±é…ç½®æ­£ç¡®

---

## ğŸ§ª ç«¯åˆ°ç«¯éªŒæ”¶æ ‡å‡†

### éªŒæ”¶æµç¨‹ï¼ˆå¿…é¡»å…¨éƒ¨é€šè¿‡ï¼‰

#### é˜¶æ®µ1: ä»£ç è´¨é‡éªŒæ”¶ âœ…

**Backend AéªŒæ”¶**:
```bash
# 1. MyPyç±»å‹æ£€æŸ¥
cd backend
python -m mypy --strict app/services/reddit_client.py
python -m mypy --strict app/services/cache_manager.py
python -m mypy --strict app/services/data_collection.py
# æœŸæœ›: Success: no issues found

# 2. å•å…ƒæµ‹è¯•
python -m pytest tests/services/test_reddit_client.py -v
python -m pytest tests/services/test_cache_manager.py -v
python -m pytest tests/services/test_data_collection.py -v
# æœŸæœ›: æ‰€æœ‰æµ‹è¯•é€šè¿‡,è¦†ç›–ç‡>80%
```

**Backend BéªŒæ”¶**:
```bash
# 1. è®¤è¯æµ‹è¯•
python -m pytest tests/api/test_auth_complete.py -v
# æœŸæœ›: æ‰€æœ‰æµ‹è¯•é€šè¿‡,è¦†ç›–ç‡>90%

# 2. Admin APIæµ‹è¯•
python -m pytest tests/api/test_admin.py -v
# æœŸæœ›: æ‰€æœ‰æµ‹è¯•é€šè¿‡
```

**FrontendéªŒæ”¶**:
```bash
# 1. TypeScriptæ£€æŸ¥
cd frontend
npx tsc --noEmit
# æœŸæœ›: 0 errors

# 2. å•å…ƒæµ‹è¯•
npm test -- --run
# æœŸæœ›: æ‰€æœ‰æµ‹è¯•é€šè¿‡
```

---

#### é˜¶æ®µ2: æœåŠ¡å¯åŠ¨éªŒæ”¶ âœ…

**éªŒè¯æ‰€æœ‰æœåŠ¡æ­£å¸¸è¿è¡Œ**:
```bash
# 1. PostgreSQL
psql -h localhost -p 5432 -U postgres -d reddit_scanner -c "SELECT 1;"
# æœŸæœ›: è¿”å›1

# 2. Redis
redis-cli ping
# æœŸæœ›: PONG

# 3. Backend
curl http://localhost:8006/docs
# æœŸæœ›: è¿”å›Swagger UI

# 4. Celery Worker
# æ£€æŸ¥Workeræ—¥å¿—æ˜¾ç¤ºready

# 5. Frontend
curl http://localhost:3006
# æœŸæœ›: è¿”å›HTML
```

---

#### é˜¶æ®µ3: APIåŠŸèƒ½éªŒæ”¶ âœ…

**æµ‹è¯•æ•°æ®é‡‡é›†API**:
```bash
# 1. æ³¨å†Œç”¨æˆ·
TOKEN=$(curl -s -X POST http://localhost:8006/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{"email":"test-day7@example.com","password":"TestPass123"}' \
  | jq -r '.access_token')

# 2. åˆ›å»ºåˆ†æä»»åŠ¡
TASK_ID=$(curl -s -X POST http://localhost:8006/api/analyze \
  -H "Authorization: Bearer $TOKEN" \
  -d '{"product_description":"AIç¬”è®°åº”ç”¨"}' \
  | jq -r '.task_id')

# 3. ç­‰å¾…ä»»åŠ¡å®Œæˆ(åº”è¯¥åŒ…å«æ•°æ®é‡‡é›†)
sleep 5

# 4. æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
curl -s http://localhost:8006/api/status/$TASK_ID \
  -H "Authorization: Bearer $TOKEN" \
  | jq '.'

# æœŸæœ›è¾“å‡ºåŒ…å«:
# {
#   "status": "completed",
#   "progress": 100,
#   "communities_found": 20,
#   "posts_collected": 1500+,
#   "cache_hit_rate": 0.6+
# }
```

---

#### é˜¶æ®µ4: å‰ç«¯åŠŸèƒ½éªŒæ”¶ âœ…

**æµè§ˆå™¨æµ‹è¯•æµç¨‹**:
1. âœ… æ‰“å¼€ `http://localhost:3006`
2. âœ… è¾“å…¥äº§å“æè¿°
3. âœ… ç‚¹å‡»"å¼€å§‹ 5 åˆ†é’Ÿåˆ†æ"
4. âœ… è‡ªåŠ¨è·³è½¬åˆ°ProgressPage
5. âœ… çœ‹åˆ°å®æ—¶è¿›åº¦æ›´æ–°
6. âœ… è¿›åº¦è¾¾åˆ°100%åè‡ªåŠ¨è·³è½¬åˆ°ReportPage
7. âœ… çœ‹åˆ°æŠ¥å‘ŠåŸºç¡€ç»“æ„

**éªŒæ”¶æ ‡å‡†**:
- [ ] è‡ªåŠ¨è®¤è¯æˆåŠŸ
- [ ] ä»»åŠ¡åˆ›å»ºæˆåŠŸ
- [ ] ProgressPageæ˜¾ç¤ºæ­£å¸¸
- [ ] SSEæˆ–è½®è¯¢å·¥ä½œæ­£å¸¸
- [ ] è‡ªåŠ¨è·³è½¬åˆ°ReportPage
- [ ] ReportPageæ˜¾ç¤ºåŸºç¡€ä¿¡æ¯

---

#### é˜¶æ®µ5: ç«¯åˆ°ç«¯éªŒæ”¶ âœ…

**å®Œæ•´æµç¨‹éªŒè¯**:
```bash
# è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬
cd backend
python scripts/test_end_to_end_day7.py

# æœŸæœ›è¾“å‡º:
# âœ… ç”¨æˆ·æ³¨å†ŒæˆåŠŸ
# âœ… ä»»åŠ¡åˆ›å»ºæˆåŠŸ
# âœ… ç¤¾åŒºå‘ç°å®Œæˆ(20ä¸ªç¤¾åŒº)
# âœ… æ•°æ®é‡‡é›†å®Œæˆ(1500+å¸–å­)
# âœ… ç¼“å­˜å‘½ä¸­ç‡>60%
# âœ… ä»»åŠ¡æ‰§è¡Œæ—¶é—´<180ç§’
# âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸ
```

---

## ğŸ“Š Day 7 éªŒæ”¶æ¸…å•

### Backend AéªŒæ”¶ âœ…
- [ ] Reddit APIå®¢æˆ·ç«¯å®ç°å®Œæˆ
- [ ] OAuth2è®¤è¯å·¥ä½œæ­£å¸¸
- [ ] å¹¶å‘é‡‡é›†åŠŸèƒ½å¯ç”¨
- [ ] é€Ÿç‡é™åˆ¶æ§åˆ¶æ­£ç¡®
- [ ] ç¼“å­˜ç®¡ç†å™¨å®ç°å®Œæˆ
- [ ] ç¼“å­˜ä¼˜å…ˆé€»è¾‘æ­£ç¡®
- [ ] æ•°æ®é‡‡é›†æœåŠ¡é›†æˆå®Œæˆ
- [ ] é›†æˆåˆ°Celeryä»»åŠ¡
- [ ] MyPy --strict 0 errors
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡>80%
- [ ] é›†æˆæµ‹è¯•é€šè¿‡

### Backend BéªŒæ”¶ âœ…
- [ ] è®¤è¯ç³»ç»Ÿå®Œæ•´æµ‹è¯•é€šè¿‡
- [ ] å¤šç§Ÿæˆ·éš”ç¦»éªŒè¯é€šè¿‡
- [ ] Admin APIè®¾è®¡å®Œæˆ
- [ ] Dashboardç»Ÿè®¡æ¥å£å®ç°
- [ ] æƒé™æ§åˆ¶å®ç°
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡

### FrontendéªŒæ”¶ âœ…
- [ ] ProgressPage SSEå®ç°
- [ ] è½®è¯¢é™çº§æœºåˆ¶å®ç°
- [ ] ReportPageåŸºç¡€ç»“æ„å®Œæˆ
- [ ] æŠ¥å‘Šè·å–é€»è¾‘å®ç°
- [ ] è·¯ç”±é…ç½®æ­£ç¡®
- [ ] TypeScript 0 errors
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡

### ç«¯åˆ°ç«¯éªŒæ”¶ âœ…
- [ ] æ‰€æœ‰æœåŠ¡æ­£å¸¸è¿è¡Œ
- [ ] APIåŠŸèƒ½å®Œæ•´å¯ç”¨
- [ ] å‰ç«¯å®Œæ•´æµç¨‹å¯ç”¨
- [ ] æ•°æ®é‡‡é›†åŠŸèƒ½éªŒè¯
- [ ] ç¼“å­˜å‘½ä¸­ç‡>60%
- [ ] ä»»åŠ¡æ‰§è¡Œæ—¶é—´<180ç§’

---

## ğŸ“ Day 7 æˆåŠŸæ ‡å¿—

- âœ… **æ•°æ®é‡‡é›†æ¨¡å—å®Œæˆ** - Reddit API + ç¼“å­˜ä¼˜å…ˆ
- âœ… **ProgressPageå®Œå–„** - SSE + è½®è¯¢é™çº§
- âœ… **ReportPageå¯åŠ¨** - åŸºç¡€ç»“æ„å®Œæˆ
- âœ… **ç«¯åˆ°ç«¯æµç¨‹éªŒè¯** - å®Œæ•´æµç¨‹å¯ç”¨
- âœ… **ä¸ºDay 8é“ºå¹³é“è·¯** - ä¿¡å·æå–å‡†å¤‡å°±ç»ª

---

**Day 7 åŠ æ²¹ï¼ğŸš€**

