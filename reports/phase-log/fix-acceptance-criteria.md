# ä¿®å¤éªŒæ”¶æ ‡å‡†ï¼ˆç»“æœå¯¼å‘ï¼‰

## ä¿®å¤æ—¶é—´
2025-10-18

## é—®é¢˜æ¸…å•

### é—®é¢˜1: Celery Beat æœªæ˜¾ç¤º cleanup ä»»åŠ¡ âŒ

**ç°è±¡**:
```bash
# Celery Beat Schedule è¾“å‡ºä¸­æ²¡æœ‰ cleanup-expired-posts-hot
```

**æ ¹å› **: Celery Worker/Beat æœªé‡å¯ï¼Œé…ç½®æœªç”Ÿæ•ˆ

**éªŒæ”¶æ ‡å‡†**:

| éªŒæ”¶é¡¹ | éªŒè¯æ–¹æ³• | æœŸæœ›ç»“æœ |
|--------|---------|---------|
| **1. cleanup ä»»åŠ¡å­˜åœ¨** | `celery -A app.core.celery_app inspect scheduled` | åŒ…å« `cleanup-expired-posts-hot` |
| **2. Beat Schedule æ˜¾ç¤º** | Python è„šæœ¬æ‰“å° beat_schedule | åŒ…å« `cleanup-expired-posts-hot` |
| **3. ä»»åŠ¡è°ƒåº¦é¢‘ç‡** | æ£€æŸ¥ schedule é…ç½® | `crontab(hour="*/6")` |
| **4. ä»»åŠ¡é˜Ÿåˆ—** | æ£€æŸ¥ options.queue | `cleanup_queue` |

**éªŒæ”¶SQL**:
```bash
# éªŒæ”¶1: æ£€æŸ¥ Beat Schedule
cd backend && python3 << 'EOF'
from app.core.celery_app import celery_app
schedule = celery_app.conf.beat_schedule
assert "cleanup-expired-posts-hot" in schedule, "cleanup ä»»åŠ¡ä¸å­˜åœ¨"
task = schedule["cleanup-expired-posts-hot"]
assert task["task"] == "tasks.maintenance.cleanup_expired_posts_hot"
print("âœ… cleanup ä»»åŠ¡å­˜åœ¨äº Beat Schedule")
EOF

# éªŒæ”¶2: æ£€æŸ¥ Celery Inspect
celery -A app.core.celery_app inspect scheduled | grep cleanup
# æœŸæœ›: çœ‹åˆ° cleanup-expired-posts-hot

# éªŒæ”¶3: æ£€æŸ¥ posts_hot è¿‡æœŸæ•°æ®
psql -U postgres -d reddit_scanner -c "SELECT COUNT(*) FROM posts_hot WHERE expires_at < NOW();"
# æœŸæœ›: 0
```

---

### é—®é¢˜2: å•å…ƒæµ‹è¯•Mocké—®é¢˜ âŒ

**ç°è±¡**:
```
FAILED test_duplicate_detection - assert 0 == 10
FAILED test_watermark_filtering - assert 0 == 5
```

**æ ¹å› **: 
1. ä½¿ç”¨ `AsyncMock` æ¨¡æ‹Ÿ Reddit API
2. Mock æ•°æ®æœªæ­£ç¡®æ’å…¥æ•°æ®åº“
3. å»é‡é€»è¾‘ä¾èµ–æ•°æ®åº“çŠ¶æ€ï¼ŒMock æ— æ³•éªŒè¯

**ä¿®å¤æ–¹æ¡ˆ**: ä½¿ç”¨çœŸå®æ•°æ®åº“ + çœŸå®æ•°æ®ï¼ˆä¸ä½¿ç”¨Mockï¼‰

**éªŒæ”¶æ ‡å‡†**:

| éªŒæ”¶é¡¹ | éªŒè¯æ–¹æ³• | æœŸæœ›ç»“æœ |
|--------|---------|---------|
| **1. æµ‹è¯•ä½¿ç”¨çœŸå®DB** | æ£€æŸ¥æµ‹è¯•ä»£ç  | æ—  `AsyncMock(return_value=...)` |
| **2. test_duplicate_detection** | `pytest tests/services/test_incremental_crawler_dedup.py::TestIncrementalCrawlerDedup::test_duplicate_detection -v` | PASSED |
| **3. test_watermark_filtering** | `pytest tests/services/test_incremental_crawler_dedup.py::TestIncrementalCrawlerDedup::test_watermark_filtering -v` | PASSED |
| **4. æ‰€æœ‰å»é‡æµ‹è¯•** | `pytest tests/services/test_incremental_crawler_dedup.py -v` | 5/5 PASSED |

**éªŒæ”¶ä»£ç **:
```bash
# éªŒæ”¶1: è¿è¡Œæ‰€æœ‰å»é‡æµ‹è¯•
cd backend && pytest tests/services/test_incremental_crawler_dedup.py -v
# æœŸæœ›: 5 passed

# éªŒæ”¶2: æ£€æŸ¥æµ‹è¯•ä»£ç ä¸­æ— Mock
grep -n "AsyncMock" tests/services/test_incremental_crawler_dedup.py
# æœŸæœ›: æ— è¾“å‡ºï¼ˆæˆ–åªåœ¨ fixture ä¸­ç”¨äº reddit_clientï¼‰

# éªŒæ”¶3: éªŒè¯å»é‡é€»è¾‘ï¼ˆæ‰‹åŠ¨æµ‹è¯•ï¼‰
cd backend && python3 << 'EOF'
import asyncio
from app.core.database import SessionFactory
from app.services.incremental_crawler import IncrementalCrawler
from app.clients.reddit_client import RedditClient

async def test_dedup():
    async with SessionFactory() as db:
        client = RedditClient()
        crawler = IncrementalCrawler(db, client)
        
        # ç¬¬ä¸€æ¬¡æŠ“å–
        result1 = await crawler.crawl_community_incremental("python", limit=10)
        print(f"ç¬¬ä¸€æ¬¡: new={result1['new_posts']}, updated={result1['updated_posts']}")
        
        # ç¬¬äºŒæ¬¡æŠ“å–ï¼ˆåº”è¯¥å¤§éƒ¨åˆ†æ˜¯é‡å¤ï¼‰
        result2 = await crawler.crawl_community_incremental("python", limit=10)
        print(f"ç¬¬äºŒæ¬¡: new={result2['new_posts']}, updated={result2['updated_posts']}")
        
        # éªŒè¯: ç¬¬äºŒæ¬¡çš„ new_posts åº”è¯¥ <= ç¬¬ä¸€æ¬¡
        assert result2['new_posts'] <= result1['new_posts'], "å»é‡é€»è¾‘å¤±è´¥"
        print("âœ… å»é‡é€»è¾‘éªŒè¯é€šè¿‡")

asyncio.run(test_dedup())
EOF
```

---

### é—®é¢˜3: Cron å¤‡ä»½æœªé…ç½® âŒ

**ç°è±¡**: å¤‡ä»½è„šæœ¬å­˜åœ¨ï¼Œä½†æœªé…ç½® Cron å®šæ—¶ä»»åŠ¡

**éªŒæ”¶æ ‡å‡†**:

| éªŒæ”¶é¡¹ | éªŒè¯æ–¹æ³• | æœŸæœ›ç»“æœ |
|--------|---------|---------|
| **1. Cron ä»»åŠ¡å­˜åœ¨** | `crontab -l \| grep backup_database` | åŒ…å«å¤‡ä»½ä»»åŠ¡ |
| **2. æ‰§è¡Œæ—¶é—´** | æ£€æŸ¥ Cron é…ç½® | `0 2 * * *` (æ¯æ—¥2ç‚¹) |
| **3. æ—¥å¿—è¾“å‡º** | æ£€æŸ¥ Cron é…ç½® | é‡å®šå‘åˆ° `/tmp/backup.log` |
| **4. å¤‡ä»½æ–‡ä»¶ç”Ÿæˆ** | æ‰‹åŠ¨æ‰§è¡Œåæ£€æŸ¥ | `backup/reddit_scanner_*.sql.gz` å­˜åœ¨ |

**éªŒæ”¶å‘½ä»¤**:
```bash
# éªŒæ”¶1: é…ç½® Cron ä»»åŠ¡
crontab -e
# æ·»åŠ : 0 2 * * * /Users/hujia/Desktop/RedditSignalScanner/scripts/backup_database.sh >> /tmp/backup.log 2>&1

# éªŒæ”¶2: æ£€æŸ¥ Cron é…ç½®
crontab -l | grep backup_database
# æœŸæœ›: 0 2 * * * /Users/hujia/Desktop/RedditSignalScanner/scripts/backup_database.sh >> /tmp/backup.log 2>&1

# éªŒæ”¶3: æ‰‹åŠ¨æ‰§è¡Œæµ‹è¯•
./scripts/backup_database.sh
ls -lh backup/reddit_scanner_*.sql.gz
# æœŸæœ›: å¤‡ä»½æ–‡ä»¶å­˜åœ¨ï¼Œå¤§å° >20MB

# éªŒæ”¶4: æ£€æŸ¥å¤‡ä»½æ–‡ä»¶æ•°é‡ï¼ˆ7å¤©ä¿ç•™ï¼‰
find backup -name "reddit_scanner_*.sql.gz" -type f | wc -l
# æœŸæœ›: <=7
```

---

## ç»¼åˆéªŒæ”¶è„šæœ¬

åˆ›å»º `scripts/verify_all_fixes.sh`:

```bash
#!/bin/bash
set -e

echo "=========================================="
echo "ç»¼åˆéªŒæ”¶è„šæœ¬"
echo "=========================================="
echo ""

PASS_COUNT=0
FAIL_COUNT=0

# éªŒæ”¶1: Celery Beat cleanup ä»»åŠ¡
echo "éªŒæ”¶1: Celery Beat cleanup ä»»åŠ¡..."
cd backend && python3 << 'EOF'
from app.core.celery_app import celery_app
schedule = celery_app.conf.beat_schedule
assert "cleanup-expired-posts-hot" in schedule
print("âœ… PASSED")
EOF
if [ $? -eq 0 ]; then
    ((PASS_COUNT++))
else
    ((FAIL_COUNT++))
fi
cd ..

# éªŒæ”¶2: posts_hot è¿‡æœŸæ•°æ®
echo "éªŒæ”¶2: posts_hot è¿‡æœŸæ•°æ®..."
EXPIRED=$(psql -U postgres -d reddit_scanner -t -c "SELECT COUNT(*) FROM posts_hot WHERE expires_at < NOW();")
if [ "$EXPIRED" -eq 0 ]; then
    echo "âœ… PASSED: posts_hot è¿‡æœŸæ•°æ® = 0"
    ((PASS_COUNT++))
else
    echo "âŒ FAILED: posts_hot è¿‡æœŸæ•°æ® = $EXPIRED"
    ((FAIL_COUNT++))
fi

# éªŒæ”¶3: å»é‡æµ‹è¯•
echo "éªŒæ”¶3: å»é‡æµ‹è¯•..."
cd backend && pytest tests/services/test_incremental_crawler_dedup.py -v --tb=short
if [ $? -eq 0 ]; then
    echo "âœ… PASSED"
    ((PASS_COUNT++))
else
    echo "âŒ FAILED"
    ((FAIL_COUNT++))
fi
cd ..

# éªŒæ”¶4: Cron å¤‡ä»½é…ç½®
echo "éªŒæ”¶4: Cron å¤‡ä»½é…ç½®..."
crontab -l | grep backup_database > /dev/null
if [ $? -eq 0 ]; then
    echo "âœ… PASSED: Cron ä»»åŠ¡å·²é…ç½®"
    ((PASS_COUNT++))
else
    echo "âš ï¸  WARNING: Cron ä»»åŠ¡æœªé…ç½®ï¼ˆéœ€æ‰‹åŠ¨é…ç½®ï¼‰"
    ((FAIL_COUNT++))
fi

# éªŒæ”¶5: å¤‡ä»½è„šæœ¬å¯æ‰§è¡Œ
echo "éªŒæ”¶5: å¤‡ä»½è„šæœ¬å¯æ‰§è¡Œ..."
if [ -x scripts/backup_database.sh ]; then
    echo "âœ… PASSED: å¤‡ä»½è„šæœ¬å¯æ‰§è¡Œ"
    ((PASS_COUNT++))
else
    echo "âŒ FAILED: å¤‡ä»½è„šæœ¬ä¸å¯æ‰§è¡Œ"
    ((FAIL_COUNT++))
fi

# éªŒæ”¶6: crawl_metrics å†™å…¥
echo "éªŒæ”¶6: crawl_metrics å†™å…¥..."
METRICS_COUNT=$(psql -U postgres -d reddit_scanner -t -c "SELECT COUNT(*) FROM crawl_metrics;")
if [ "$METRICS_COUNT" -gt 0 ]; then
    echo "âœ… PASSED: crawl_metrics æœ‰ $METRICS_COUNT æ¡è®°å½•"
    ((PASS_COUNT++))
else
    echo "âŒ FAILED: crawl_metrics æ— è®°å½•"
    ((FAIL_COUNT++))
fi

# éªŒæ”¶7: Redis maxmemory
echo "éªŒæ”¶7: Redis maxmemory..."
MAXMEMORY=$(redis-cli CONFIG GET maxmemory | tail -1)
if [ "$MAXMEMORY" -eq 2147483648 ]; then
    echo "âœ… PASSED: Redis maxmemory = 2GB"
    ((PASS_COUNT++))
else
    echo "âŒ FAILED: Redis maxmemory = $MAXMEMORY"
    ((FAIL_COUNT++))
fi

echo ""
echo "=========================================="
echo "éªŒæ”¶ç»“æœæ±‡æ€»"
echo "=========================================="
echo "âœ… é€šè¿‡: $PASS_COUNT"
echo "âŒ å¤±è´¥: $FAIL_COUNT"
echo "æ€»è®¡: $((PASS_COUNT + FAIL_COUNT))"
echo ""

if [ "$FAIL_COUNT" -eq 0 ]; then
    echo "ğŸ‰ æ‰€æœ‰éªŒæ”¶é€šè¿‡ï¼"
    exit 0
else
    echo "âš ï¸  æœ‰ $FAIL_COUNT é¡¹éªŒæ”¶å¤±è´¥ï¼Œè¯·æ£€æŸ¥"
    exit 1
fi
```

## éªŒæ”¶é€šè¿‡æ ‡å‡†

**P0 ä¿®å¤ï¼ˆå¿…é¡»100%é€šè¿‡ï¼‰**:
- âœ… Celery Beat cleanup ä»»åŠ¡å­˜åœ¨
- âœ… posts_hot è¿‡æœŸæ•°æ® = 0
- âœ… Redis maxmemory = 2GB

**P1 ä¿®å¤ï¼ˆå¿…é¡»100%é€šè¿‡ï¼‰**:
- âœ… å»é‡æµ‹è¯• 5/5 é€šè¿‡
- âœ… crawl_metrics å†™å…¥æˆåŠŸ
- âœ… å¤‡ä»½è„šæœ¬å¯æ‰§è¡Œ
- âš ï¸ Cron å¤‡ä»½é…ç½®ï¼ˆå¯é€‰ï¼Œæ‰‹åŠ¨é…ç½®ï¼‰

**ç»¼åˆéªŒæ”¶**:
- æ€»é€šè¿‡ç‡: >=85% (6/7)
- P0 é€šè¿‡ç‡: 100% (3/3)
- P1 é€šè¿‡ç‡: >=75% (3/4)

