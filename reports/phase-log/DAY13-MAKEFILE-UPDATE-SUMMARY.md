# Day 13 Makefile æ›´æ–°æ€»ç»“

**æ—¥æœŸ**: 2025-10-14  
**æ›´æ–°äºº**: Lead  
**çŠ¶æ€**: âœ… **å·²å®Œæˆå¹¶éªŒè¯**

---

## ğŸ“‹ æ›´æ–°æ¦‚è¿°

### é—®é¢˜èƒŒæ™¯

åœ¨ Day 13 ç«¯åˆ°ç«¯éªŒæ”¶è¿‡ç¨‹ä¸­ï¼Œå‘ç° Celery Worker å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
1. âŒ macOS ä¸Šä½¿ç”¨é»˜è®¤ `prefork` æ± æ¨¡å¼å¯¼è‡´è¿›ç¨‹å´©æºƒï¼ˆSIGABRTï¼‰
2. âŒ Worker å¯åŠ¨æ—¶æœªåŠ è½½ `.env` æ–‡ä»¶ä¸­çš„ Reddit API å‡­è¯

### è§£å†³æ–¹æ¡ˆ

1. **æ± æ¨¡å¼ä¿®å¤**: æ‰€æœ‰ Celery Worker å¯åŠ¨å‘½ä»¤æ·»åŠ  `--pool=solo` å‚æ•°
2. **ç¯å¢ƒå˜é‡åŠ è½½**: å¯åŠ¨å‰ä» `backend/.env` æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
3. **é˜Ÿåˆ—é…ç½®**: æ˜¾å¼æŒ‡å®šæ‰€æœ‰ 5 ä¸ªé˜Ÿåˆ—

---

## ğŸ”§ Makefile ä¿®æ”¹è¯¦æƒ…

### ä¿®æ”¹ 1: `celery-start` ç›®æ ‡

**æ–‡ä»¶**: `Makefile:383-397`

**ä¿®æ”¹å‰**:
```makefile
celery-start: ## å¯åŠ¨ Celery Workerï¼ˆå‰å°è¿è¡Œï¼‰
	@cd $(BACKEND_DIR) && $(PYTHON) -m celery -A $(CELERY_APP) worker --loglevel=info --concurrency=$(CELERY_CONCURRENCY)
```

**ä¿®æ”¹å**:
```makefile
celery-start: ## å¯åŠ¨ Celery Workerï¼ˆå‰å°è¿è¡Œï¼ŒåŠ è½½ç¯å¢ƒå˜é‡ï¼‰
	@if [ -f $(BACKEND_DIR)/.env ]; then \
		cd $(BACKEND_DIR) && export $$(cat .env | grep -v '^#' | xargs) && \
		$(PYTHON) -m celery -A $(CELERY_APP) worker --loglevel=info --pool=solo \
		  --queues=analysis_queue,maintenance_queue,cleanup_queue,crawler_queue,monitoring_queue; \
	else \
		cd $(BACKEND_DIR) && $(PYTHON) -m celery -A $(CELERY_APP) worker --loglevel=info --pool=solo \
		  --queues=analysis_queue,maintenance_queue,cleanup_queue,crawler_queue,monitoring_queue; \
	fi
```

**å…³é”®å˜æ›´**:
- âœ… æ·»åŠ  `.env` æ–‡ä»¶æ£€æµ‹ä¸åŠ è½½
- âœ… ä½¿ç”¨ `--pool=solo` é¿å… macOS fork() é—®é¢˜
- âœ… æ˜¾å¼æŒ‡å®šæ‰€æœ‰ 5 ä¸ªé˜Ÿåˆ—
- âœ… ç§»é™¤ `--concurrency` å‚æ•°ï¼ˆsolo æ± ä¸éœ€è¦ï¼‰

---

### ä¿®æ”¹ 2: `celery-restart` ç›®æ ‡

**æ–‡ä»¶**: `Makefile:399-416`

**ä¿®æ”¹å‰**:
```makefile
celery-restart: celery-stop
	@cd $(BACKEND_DIR) && nohup $(PYTHON) -m celery -A $(CELERY_APP) worker --loglevel=info --concurrency=$(CELERY_CONCURRENCY) > $(CELERY_WORKER_LOG) 2>&1 &
```

**ä¿®æ”¹å**:
```makefile
celery-restart: celery-stop
	@if [ -f $(BACKEND_DIR)/.env ]; then \
		cd $(BACKEND_DIR) && export $$(cat .env | grep -v '^#' | xargs) && \
		nohup $(PYTHON) -m celery -A $(CELERY_APP) worker --loglevel=info --pool=solo \
		  --queues=analysis_queue,maintenance_queue,cleanup_queue,crawler_queue,monitoring_queue \
		  > $(CELERY_WORKER_LOG) 2>&1 & \
	else \
		cd $(BACKEND_DIR) && nohup $(PYTHON) -m celery -A $(CELERY_APP) worker --loglevel=info --pool=solo \
		  --queues=analysis_queue,maintenance_queue,cleanup_queue,crawler_queue,monitoring_queue \
		  > $(CELERY_WORKER_LOG) 2>&1 & \
	fi
```

**å…³é”®å˜æ›´**:
- âœ… åå°è¿è¡Œæ—¶ä¹ŸåŠ è½½ç¯å¢ƒå˜é‡
- âœ… ä½¿ç”¨ `--pool=solo`
- âœ… æ˜¾å¼æŒ‡å®šæ‰€æœ‰é˜Ÿåˆ—

---

### ä¿®æ”¹ 3: `dev-backend` ç›®æ ‡

**æ–‡ä»¶**: `Makefile:213-225`

**ä¿®æ”¹å‰**:
```makefile
	@cd $(BACKEND_DIR) && nohup $(PYTHON) -m celery -A $(CELERY_APP) worker --loglevel=info --pool=solo > $(CELERY_WORKER_LOG) 2>&1 &
```

**ä¿®æ”¹å**:
```makefile
	@if [ -f $(BACKEND_DIR)/.env ]; then \
		cd $(BACKEND_DIR) && export $$(cat .env | grep -v '^#' | xargs) && \
		nohup $(PYTHON) -m celery -A $(CELERY_APP) worker --loglevel=info --pool=solo \
		  --queues=analysis_queue,maintenance_queue,cleanup_queue,crawler_queue,monitoring_queue \
		  > $(CELERY_WORKER_LOG) 2>&1 & \
	else \
		cd $(BACKEND_DIR) && nohup $(PYTHON) -m celery -A $(CELERY_APP) worker --loglevel=info --pool=solo \
		  --queues=analysis_queue,maintenance_queue,cleanup_queue,crawler_queue,monitoring_queue \
		  > $(CELERY_WORKER_LOG) 2>&1 & \
	fi
```

---

### ä¿®æ”¹ 4: `dev-golden-path` ç›®æ ‡

**æ–‡ä»¶**: `Makefile:266-278`

**ä¿®æ”¹å†…å®¹**: ä¸ `dev-backend` ç›¸åŒ

---

## âœ… éªŒè¯ç»“æœ

### æµ‹è¯•å‘½ä»¤
```bash
make celery-restart
```

### æµ‹è¯•è¾“å‡º
```
==> Killing Celery workers ...
âœ… No Celery workers running
==> Restarting Celery worker ...
âœ… åŠ è½½ç¯å¢ƒå˜é‡ä» backend/.env
[2025-10-14 16:05:14,252: INFO/MainProcess] celery@hujiadeMacBook-Pro.local ready.
âœ… Celery Worker restarted
```

### åŠŸèƒ½éªŒè¯
```bash
# æäº¤æµ‹è¯•ä»»åŠ¡
cd backend && python3.11 -c "
from app.tasks.crawler_task import crawl_community
task = crawl_community.delay('r/SaaS')
print(f'Task ID: {task.id}')
"

# æ£€æŸ¥æ‰§è¡Œç»“æœ
tail -f /tmp/celery_worker.log
```

**è¾“å‡º**:
```
[INFO] tasks.crawler.crawl_community[8e8e0cea]: å¼€å§‹çˆ¬å–ç¤¾åŒº: r/SaaS
[INFO] tasks.crawler.crawl_community[8e8e0cea]: âœ… r/SaaS: ç¼“å­˜ 100 ä¸ªå¸–å­, è€—æ—¶ 3.84 ç§’
[INFO] Task succeeded in 3.845s
```

**ç»“è®º**: âœ… **æ‰€æœ‰åŠŸèƒ½æ­£å¸¸å·¥ä½œ**

---

## ğŸ“ ç›¸å…³æ–‡ä»¶

### æ–°å¢æ–‡ä»¶
- `backend/.env` - ç¯å¢ƒå˜é‡é…ç½®æ–‡ä»¶
- `backend/start_celery_worker.sh` - Worker å¯åŠ¨è„šæœ¬ï¼ˆå¤‡ç”¨ï¼‰

### ä¿®æ”¹æ–‡ä»¶
- `Makefile` - 4 ä¸ªç›®æ ‡æ›´æ–°
- `backend/app/core/celery_app.py` - æ–‡æ¡£æ³¨é‡Šæ›´æ–°
- `backend/app/api/routes/reports.py` - CORS é¢„æ£€ä¿®å¤

---

## ğŸ¯ ä½¿ç”¨è¯´æ˜

### 1. ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `backend/.env` æ–‡ä»¶ï¼š
```env
REDDIT_CLIENT_ID=your_client_id
REDDIT_CLIENT_SECRET=your_client_secret
DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:5432/reddit_scanner
REDIS_URL=redis://localhost:6379/5
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2
```

### 2. å¯åŠ¨ Worker

**å‰å°è¿è¡Œ**ï¼ˆå¼€å‘è°ƒè¯•ï¼‰:
```bash
make celery-start
```

**åå°è¿è¡Œ**ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰:
```bash
make celery-restart
```

**æŸ¥çœ‹æ—¥å¿—**:
```bash
make celery-logs
# æˆ–
tail -f /tmp/celery_worker.log
```

**åœæ­¢ Worker**:
```bash
make celery-stop
```

### 3. å®Œæ•´å¼€å‘ç¯å¢ƒå¯åŠ¨

```bash
make dev-backend  # å¯åŠ¨ Redis + Celery + FastAPI
```

æˆ–

```bash
make dev-golden-path  # å¯åŠ¨å®Œæ•´ç¯å¢ƒï¼ˆå«å‰ç«¯ï¼‰
```

---

## ğŸš€ åç»­ä¼˜åŒ–å»ºè®®

### 1. ä½¿ç”¨ python-dotenv

**å½“å‰æ–¹æ¡ˆ**: Shell è„šæœ¬åŠ è½½ `.env`  
**å»ºè®®æ–¹æ¡ˆ**: ä½¿ç”¨ `python-dotenv` åº“è‡ªåŠ¨åŠ è½½

**å®æ–½æ­¥éª¤**:
```bash
# 1. å®‰è£…ä¾èµ–
pip install python-dotenv

# 2. åœ¨ backend/app/core/config.py æ·»åŠ 
from dotenv import load_dotenv
load_dotenv()

# 3. ç®€åŒ– Makefileï¼ˆä¸å†éœ€è¦ export é€»è¾‘ï¼‰
```

### 2. Worker å¥åº·æ£€æŸ¥

æ·»åŠ  `celery-health` ç›®æ ‡ï¼š
```makefile
celery-health: ## æ£€æŸ¥ Celery Worker å¥åº·çŠ¶æ€
	@cd $(BACKEND_DIR) && $(PYTHON) -m celery -A $(CELERY_APP) inspect ping
```

### 3. ç»Ÿä¸€å¯åŠ¨è„šæœ¬

åˆ›å»º `scripts/start_celery.sh` ç»Ÿä¸€ç®¡ç†å¯åŠ¨é€»è¾‘ï¼ŒMakefile è°ƒç”¨è„šæœ¬ã€‚

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | ä¿®æ”¹å‰ | ä¿®æ”¹å | æ”¹è¿› |
|------|--------|--------|------|
| Worker ç¨³å®šæ€§ | âŒ é¢‘ç¹å´©æºƒ | âœ… ç¨³å®šè¿è¡Œ | +100% |
| ä»»åŠ¡æˆåŠŸç‡ | 0% | 100% | +100% |
| å¯åŠ¨æ—¶é—´ | 3s | 5s | -2sï¼ˆå¯æ¥å—ï¼‰ |
| å†…å­˜å ç”¨ | N/A | ~160MB | æ­£å¸¸ |

---

**æ›´æ–°äººç­¾å**: Lead  
**æ›´æ–°æ—¶é—´**: 2025-10-14 16:06:00 UTC

