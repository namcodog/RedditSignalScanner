# 🔍 Reddit Signal Scanner 数据库设计深度分析报告

**分析日期**: 2025-10-23  
**分析工具**: Serena MCP + Sequential Thinking + Exa Code  
**分析范围**: 全仓库数据库架构、产品端、Admin端、自动抓取系统  
**分析深度**: 模型设计、索引策略、约束规范、性能优化、最佳实践对比

---

## 📊 执行摘要

### 核心发现

经过全面深度分析,发现当前数据库设计存在 **10个深层次问题**:
- **P0 严重问题**: 3个 (外键缺失、主键不一致、级联删除缺失)
- **P1 重要问题**: 3个 (索引缺失、JSONB索引缺失、数据库名称不统一)
- **P2 优化建议**: 4个 (审计字段、软删除、时间戳不一致、复合主键复杂)

### 影响评估

| 问题类型 | 影响范围 | 严重程度 | 修复优先级 |
|---------|---------|---------|-----------|
| 数据完整性 | 3个表 | 🔴 高 | P0 |
| 查询性能 | 6个表 | 🟡 中 | P1 |
| 代码规范性 | 全部表 | 🟢 低 | P2 |

---

## 🗂️ 数据库架构全景图

### 表结构总览 (15个表)

#### 1. 核心业务表 (7个)
```
users (UUID主键)
  ├── tasks (UUID主键, user_id外键)
  │   ├── analyses (UUID主键, task_id外键唯一)
  │   │   └── reports (UUID主键, analysis_id外键唯一)
  │   ├── insight_cards (UUID主键, task_id外键)
  │   │   └── evidences (UUID主键, insight_card_id外键)
  │   └── beta_feedback (UUID主键, task_id+user_id外键)
```

#### 2. 社区管理表 (4个)
```
community_pool (自增主键, name唯一)
pending_communities (自增主键, name唯一)
community_import_history (自增主键)
community_cache (字符串主键: community_name)
```

#### 3. 数据存储表 (3个)
```
posts_raw (复合主键: source+source_post_id+version, SCD2设计)
posts_hot (复合主键: source+source_post_id)
community_watermarks (字符串主键: community_name)
```

#### 4. 监控指标表 (2个)
```
crawl_metrics (自增主键, 按日期+小时聚合)
quality_metrics (自增主键, date唯一)
```

### 主键策略分布

| 主键类型 | 表数量 | 表名 | 适用场景 |
|---------|-------|------|---------|
| UUID | 7 | users, tasks, analyses, reports, insight_cards, evidences, beta_feedback | 分布式系统、公开ID |
| 自增整数 | 5 | community_pool, pending_communities, community_import_history, crawl_metrics, quality_metrics | 单体应用、内部ID |
| 字符串 | 2 | community_cache, community_watermarks | 自然主键 |
| 复合主键 | 2 | posts_raw, posts_hot | 多维度唯一性 |

---

## 🚨 P0 严重问题 (必须修复)

### 问题1: 外键约束缺失 (数据完整性风险)

#### 影响表
1. **community_import_history.uploaded_by_user_id**
   - 当前状态: 无外键约束
   - 应该关联: `users.id`
   - 风险: 用户删除后,导入历史记录仍然存在,产生孤儿记录

2. **pending_communities.discovered_from_task_id**
   - 当前状态: 无外键约束
   - 应该关联: `tasks.id`
   - 风险: 任务删除后,待审核社区记录仍然存在

3. **pending_communities.reviewed_by**
   - 当前状态: 无外键约束
   - 应该关联: `users.id`
   - 风险: 审核人删除后,无法追溯审核历史

#### 代码证据
```python
# backend/app/models/community_pool.py:70-71
uploaded_by_user_id: Mapped[uuid.UUID] = mapped_column(
    UUID(as_uuid=True), nullable=False
)  # ❌ 缺少 ForeignKey("users.id")

# backend/app/models/community_pool.py:58-59
discovered_from_task_id: Mapped[str | None] = mapped_column(
    UUID(as_uuid=True), nullable=True
)  # ❌ 缺少 ForeignKey("tasks.id")

# backend/app/models/community_pool.py:61
reviewed_by: Mapped[str | None] = mapped_column(UUID(as_uuid=True), nullable=True)
# ❌ 缺少 ForeignKey("users.id")
```

#### 最佳实践对比
```python
# ✅ 正确示例 (beta_feedback.py)
task_id: Mapped[uuid.UUID] = mapped_column(
    ForeignKey("tasks.id", ondelete="CASCADE"), nullable=False
)
user_id: Mapped[uuid.UUID] = mapped_column(
    ForeignKey("users.id", ondelete="CASCADE"), nullable=False
)
```

#### 修复方案
```python
# 修复 community_import_history
uploaded_by_user_id: Mapped[uuid.UUID] = mapped_column(
    ForeignKey("users.id", ondelete="SET NULL"), nullable=True  # 改为可空,删除用户时设为NULL
)

# 修复 pending_communities
discovered_from_task_id: Mapped[uuid.UUID | None] = mapped_column(
    ForeignKey("tasks.id", ondelete="SET NULL"), nullable=True
)
reviewed_by: Mapped[uuid.UUID | None] = mapped_column(
    ForeignKey("users.id", ondelete="SET NULL"), nullable=True
)
```

---

### 问题2: 主键策略不一致 (维护性问题)

#### 当前状态
- **UUID主键**: 7个表 (用户相关、任务相关)
- **自增主键**: 5个表 (社区管理、监控指标)
- **字符串主键**: 2个表 (社区缓存、水位线)
- **复合主键**: 2个表 (帖子存储)

#### 问题分析
1. **开发者困惑**: 不知道新表该用哪种主键策略
2. **代码不一致**: 外键关联方式不同,查询模式不同
3. **性能差异**: UUID有性能开销,自增ID性能更好
4. **扩展性差异**: UUID适合分布式,自增ID适合单体

#### 最佳实践建议
根据Exa Code查询结果,PostgreSQL 10+推荐策略:

```sql
-- ✅ 推荐: 使用 GENERATED BY DEFAULT AS IDENTITY
CREATE TABLE example (
    id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    ...
);

-- ✅ 可接受: 使用 SERIAL (兼容性)
CREATE TABLE example (
    id SERIAL PRIMARY KEY,
    ...
);

-- ✅ 分布式场景: 使用 UUID
CREATE TABLE example (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    ...
);
```

#### 统一建议
1. **核心业务表** (users, tasks, analyses): 保持UUID (已有数据,不建议修改)
2. **社区管理表**: 统一使用自增ID (性能优先)
3. **新表**: 优先使用 `GENERATED BY DEFAULT AS IDENTITY`

---

### 问题3: 缺少级联删除策略 (数据清理问题)

#### 影响表
1. **community_import_history**: 用户删除后,导入历史无法自动清理
2. **pending_communities**: 任务删除后,待审核社区无法自动清理

#### 当前状态
```python
# ❌ 无级联删除
uploaded_by_user_id: Mapped[uuid.UUID] = mapped_column(
    UUID(as_uuid=True), nullable=False
)
```

#### 最佳实践
```python
# ✅ 使用 CASCADE 自动删除
uploaded_by_user_id: Mapped[uuid.UUID] = mapped_column(
    ForeignKey("users.id", ondelete="CASCADE"), nullable=False
)

# ✅ 使用 SET NULL 保留历史
uploaded_by_user_id: Mapped[uuid.UUID | None] = mapped_column(
    ForeignKey("users.id", ondelete="SET NULL"), nullable=True
)
```

#### 修复建议
- **导入历史**: 使用 `SET NULL` (保留历史记录,但标记用户已删除)
- **待审核社区**: 使用 `CASCADE` (任务删除后,待审核社区也删除)

---

## 🟡 P1 重要问题 (应该修复)

### 问题4: 索引缺失 (性能问题)

#### 缺失索引列表
1. **community_import_history.uploaded_by_user_id** (外键列无索引)
2. **pending_communities.discovered_from_task_id** (外键列无索引)
3. **pending_communities.reviewed_by** (外键列无索引)

#### 性能影响
- 关联查询慢 (JOIN操作需要全表扫描)
- 外键约束检查慢
- Admin后台查询慢 (查询导入历史、待审核社区)

#### 修复方案
```python
# community_import_history
__table_args__ = (
    Index("idx_community_import_history_uploaded_by", "uploaded_by_user_id"),
    Index("idx_community_import_history_created_at", "created_at"),
)

# pending_communities
__table_args__ = (
    Index("idx_pending_communities_task_id", "discovered_from_task_id"),
    Index("idx_pending_communities_reviewed_by", "reviewed_by"),
    Index("idx_pending_communities_status", "status"),
)
```

---

### 问题5: JSONB字段缺少GIN索引 (查询性能问题)

#### 缺失GIN索引的JSONB字段
1. **posts_hot.metadata** (无GIN索引)
2. **community_pool.categories** (无GIN索引)
3. **community_pool.description_keywords** (无GIN索引)

#### 已有GIN索引 (✅ 正确)
- `analyses.insights` ✅
- `analyses.sources` ✅
- `posts_raw.metadata` ✅

#### 性能影响
- JSONB查询慢 (无法使用索引)
- 社区筛选慢 (按类别、关键词筛选)

#### 修复方案
```python
# posts_hot
__table_args__ = (
    Index("idx_posts_hot_metadata_gin", "metadata", postgresql_using="gin"),
)

# community_pool
__table_args__ = (
    Index("idx_community_pool_categories_gin", "categories", postgresql_using="gin"),
    Index("idx_community_pool_keywords_gin", "description_keywords", postgresql_using="gin"),
)
```

---

### 问题6: 数据库名称不统一 (配置混乱)

#### 当前状态
- **历史遗留**: `reddit_scanner`
- **当前标准**: `reddit_signal_scanner`
- **文档记录**: `docs/DATABASE_CONFIGURATION.md`

#### 影响
- 配置混乱,可能导致数据查询失败
- 开发者困惑,不知道该用哪个数据库

#### 修复状态
✅ 已在文档中明确标准,但需要确保所有脚本、配置文件都使用统一名称

---

## 🟢 P2 优化建议 (可选修复)

### 问题7: 缺少审计字段 (可追溯性问题)

#### 影响表
1. **community_pool**: 缺少 `created_by`, `updated_by`
2. **pending_communities**: 缺少 `updated_by`
3. **community_import_history**: 有 `uploaded_by` 但缺少 `updated_by`

#### 当前状态
```python
# community_pool - 只有时间戳,无操作人
class CommunityPool(TimestampMixin, Base):
    created_at: Mapped[datetime]  # ✅ 有
    updated_at: Mapped[datetime]  # ✅ 有
    # ❌ 缺少 created_by
    # ❌ 缺少 updated_by
```

#### 最佳实践
```python
# ✅ 完整的审计字段
class CommunityPool(TimestampMixin, Base):
    created_at: Mapped[datetime]
    updated_at: Mapped[datetime]
    created_by: Mapped[uuid.UUID] = mapped_column(
        ForeignKey("users.id", ondelete="SET NULL"), nullable=True
    )
    updated_by: Mapped[uuid.UUID] = mapped_column(
        ForeignKey("users.id", ondelete="SET NULL"), nullable=True
    )
```

#### 影响
- 无法追溯谁创建/修改了社区池记录
- 审计日志不完整
- 数据变更无法追责

---

### 问题8: 缺少软删除机制 (数据恢复问题)

#### 当前状态
- **有软删除**: 无 (大部分表直接物理删除)
- **有is_active**: `users`, `community_pool`, `community_cache` (但不是软删除)

#### 问题分析
1. 误删除数据无法恢复
2. 历史数据丢失
3. 审计追踪困难

#### 最佳实践
```python
# ✅ 软删除设计
class SoftDeleteMixin:
    deleted_at: Mapped[datetime | None] = mapped_column(
        DateTime(timezone=True), nullable=True
    )
    deleted_by: Mapped[uuid.UUID | None] = mapped_column(
        ForeignKey("users.id", ondelete="SET NULL"), nullable=True
    )

# ✅ 查询时自动过滤已删除记录
@declared_attr
def __table_args__(cls):
    return (
        Index("idx_deleted_at", "deleted_at"),
    )
```

#### SQLAlchemy最佳实践 (来自Exa Code)
```python
# ✅ 使用 @SQLDelete 和 @Where 装饰器
from sqlalchemy.annotations import SQLDelete, Where

@SQLDelete(sql="UPDATE community_pool SET deleted_at=CURRENT_TIMESTAMP WHERE id=?")
@Where(clause="deleted_at IS NULL")
class CommunityPool(Base):
    ...
```

---

### 问题9: 时间戳字段不一致 (规范性问题)

#### 当前状态
1. **使用TimestampMixin**: `users`, `tasks`, `community_pool`, `community_cache`, `insight_cards`, `evidences`, `beta_feedback`
2. **手动定义created_at**: `analyses`, `reports`, `crawl_metrics`, `quality_metrics`, `community_import_history`
3. **不同的默认值策略**:
   - `server_default=func.now()` (analyses, reports)
   - `default=lambda: datetime.now(timezone.utc)` (crawl_metrics, quality_metrics)
   - `server_default=func.now()` (community_import_history)

#### 代码证据
```python
# ✅ 使用 TimestampMixin (一致)
class User(TimestampMixin, Base):
    # 自动获得 created_at, updated_at

# ❌ 手动定义 (不一致)
class Analysis(Base):
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now(), nullable=False
    )
    # 缺少 updated_at

# ❌ 不同的默认值策略 (不一致)
class CrawlMetrics(Base):
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), default=lambda: datetime.now(timezone.utc)
    )
```

#### 统一建议
```python
# ✅ 统一使用 TimestampMixin
class TimestampMixin:
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        server_default=func.now(),  # 使用数据库时间
        nullable=False
    )
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        server_default=func.now(),
        onupdate=func.now(),  # 自动更新
        nullable=False
    )
```

---

### 问题10: 复合主键设计复杂 (维护性问题)

#### 当前复合主键
1. **posts_raw**: `(source, source_post_id, version)` - SCD2设计
2. **posts_hot**: `(source, source_post_id)` - 简单复合主键

#### 问题分析
1. **外键关联复杂**: 需要3个字段才能关联到posts_raw
2. **查询复杂**: WHERE条件需要3个字段
3. **性能影响**: 复合主键索引大,查询可能慢

#### 当前设计
```python
# posts_raw - 复合主键
__table_args__ = (
    PrimaryKeyConstraint(
        "source", "source_post_id", "version", name="pk_posts_raw"
    ),
)
```

#### 替代方案 (可选)
```python
# ✅ 方案1: 添加自增ID作为主键,复合键作为唯一约束
class PostRaw(Base):
    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    source: Mapped[str]
    source_post_id: Mapped[str]
    version: Mapped[int]

    __table_args__ = (
        UniqueConstraint("source", "source_post_id", "version"),
    )

# ✅ 方案2: 使用UUID主键,复合键作为唯一约束
class PostRaw(Base):
    id: Mapped[uuid.UUID] = uuid_pk_column()
    source: Mapped[str]
    source_post_id: Mapped[str]
    version: Mapped[int]

    __table_args__ = (
        UniqueConstraint("source", "source_post_id", "version"),
    )
```

#### 建议
- **保持现状**: SCD2设计合理,复合主键符合业务语义
- **优化索引**: 确保复合主键索引性能良好
- **新表避免**: 新表优先使用单列主键

---

## 📈 数据流分析总结

### 产品端数据流
1. 用户注册/登录 → `users`
2. 创建分析任务 → `tasks` (user_id外键)
3. 查询任务状态 → `tasks` + Redis缓存
4. SSE实时进度 → Redis + `tasks`
5. 查看报告 → `tasks` → `analyses` → `reports` (3表联查)
6. 查看洞察卡片 → `insight_cards` + `evidences` (2表联查)
7. 提交反馈 → `beta_feedback`

### Admin端数据流
1. 仪表盘统计 → `users`, `tasks`, `analyses` (聚合查询)
2. 社区池管理 → `community_pool`, `pending_communities`
3. 社区导入 → `community_import_history`
4. 社区验收 → `community_cache` (计算C-Score)
5. 用户反馈 → `beta_feedback`
6. 最近任务 → `tasks` + `users` + `analyses` (3表联查)
7. 活跃用户 → `users` + `tasks` (聚合查询)

### 自动抓取系统数据流
1. 爬虫任务 → `posts_raw` (冷库, SCD2设计)
2. 爬虫任务 → `posts_hot` (热缓存, 覆盖式)
3. 爬虫任务 → `community_watermarks` (水位线)
4. 爬虫任务 → `community_cache` (元数据更新)
5. 爬虫任务 → `crawl_metrics` (指标记录)

---

## 🎯 优化方案总览

### 立即修复 (P0)
1. ✅ 添加外键约束 (3个表)
2. ✅ 添加级联删除策略
3. ⚠️ 主键策略统一 (新表遵循规范)

### 近期修复 (P1)
4. ✅ 添加缺失索引 (3个表)
5. ✅ 添加JSONB GIN索引 (3个字段)
6. ✅ 确保数据库名称统一

### 长期优化 (P2)
7. 添加审计字段 (created_by, updated_by)
8. 添加软删除机制 (deleted_at)
9. 统一时间戳字段策略
10. 评估复合主键设计

---

## 🛠️ 详细迁移计划

### Phase 1: P0问题修复 (立即执行)

#### Migration 1: 添加外键约束

**文件**: `backend/alembic/versions/20251023_000018_add_missing_foreign_keys.py`

```python
"""Add missing foreign key constraints

Revision ID: 20251023_000018
Revises: 20251022_000017
Create Date: 2025-10-23
"""
from alembic import op
import sqlalchemy as sa

def upgrade() -> None:
    # 1. 修改 community_import_history.uploaded_by_user_id 为可空
    op.alter_column(
        'community_import_history',
        'uploaded_by_user_id',
        nullable=True,
        existing_type=sa.UUID()
    )

    # 2. 添加外键约束
    op.create_foreign_key(
        'fk_community_import_history_uploaded_by_user_id',
        'community_import_history',
        'users',
        ['uploaded_by_user_id'],
        ['id'],
        ondelete='SET NULL'
    )

    op.create_foreign_key(
        'fk_pending_communities_discovered_from_task_id',
        'pending_communities',
        'tasks',
        ['discovered_from_task_id'],
        ['id'],
        ondelete='SET NULL'
    )

    op.create_foreign_key(
        'fk_pending_communities_reviewed_by',
        'pending_communities',
        'users',
        ['reviewed_by'],
        ['id'],
        ondelete='SET NULL'
    )

    # 3. 添加索引 (外键列)
    op.create_index(
        'idx_community_import_history_uploaded_by',
        'community_import_history',
        ['uploaded_by_user_id']
    )

    op.create_index(
        'idx_pending_communities_task_id',
        'pending_communities',
        ['discovered_from_task_id']
    )

    op.create_index(
        'idx_pending_communities_reviewed_by',
        'pending_communities',
        ['reviewed_by']
    )

def downgrade() -> None:
    # 删除索引
    op.drop_index('idx_pending_communities_reviewed_by')
    op.drop_index('idx_pending_communities_task_id')
    op.drop_index('idx_community_import_history_uploaded_by')

    # 删除外键
    op.drop_constraint('fk_pending_communities_reviewed_by', 'pending_communities')
    op.drop_constraint('fk_pending_communities_discovered_from_task_id', 'pending_communities')
    op.drop_constraint('fk_community_import_history_uploaded_by_user_id', 'community_import_history')

    # 恢复非空约束
    op.alter_column(
        'community_import_history',
        'uploaded_by_user_id',
        nullable=False,
        existing_type=sa.UUID()
    )
```

**执行步骤**:
```bash
# 1. 生成迁移文件
cd backend
alembic revision -m "add_missing_foreign_keys"

# 2. 编辑迁移文件 (复制上述代码)

# 3. 执行迁移
alembic upgrade head

# 4. 验证
psql -d reddit_signal_scanner -c "\d community_import_history"
psql -d reddit_signal_scanner -c "\d pending_communities"
```

**风险评估**:
- ⚠️ 如果存在孤儿记录,迁移会失败
- ✅ 使用 `SET NULL` 策略,不会删除数据
- ✅ 可回滚

**数据清理脚本** (迁移前执行):
```sql
-- 检查孤儿记录
SELECT COUNT(*) FROM community_import_history
WHERE uploaded_by_user_id NOT IN (SELECT id FROM users);

SELECT COUNT(*) FROM pending_communities
WHERE discovered_from_task_id IS NOT NULL
  AND discovered_from_task_id NOT IN (SELECT id FROM tasks);

SELECT COUNT(*) FROM pending_communities
WHERE reviewed_by IS NOT NULL
  AND reviewed_by NOT IN (SELECT id FROM users);

-- 清理孤儿记录 (如果有)
UPDATE community_import_history
SET uploaded_by_user_id = NULL
WHERE uploaded_by_user_id NOT IN (SELECT id FROM users);

UPDATE pending_communities
SET discovered_from_task_id = NULL
WHERE discovered_from_task_id IS NOT NULL
  AND discovered_from_task_id NOT IN (SELECT id FROM tasks);

UPDATE pending_communities
SET reviewed_by = NULL
WHERE reviewed_by IS NOT NULL
  AND reviewed_by NOT IN (SELECT id FROM users);
```

---

### Phase 2: P1问题修复 (近期执行)

#### Migration 2: 添加JSONB GIN索引

**文件**: `backend/alembic/versions/20251023_000019_add_jsonb_gin_indexes.py`

```python
"""Add GIN indexes for JSONB fields

Revision ID: 20251023_000019
Revises: 20251023_000018
Create Date: 2025-10-23
"""
from alembic import op

def upgrade() -> None:
    # 1. posts_hot.metadata
    op.create_index(
        'idx_posts_hot_metadata_gin',
        'posts_hot',
        ['metadata'],
        postgresql_using='gin'
    )

    # 2. community_pool.categories
    op.create_index(
        'idx_community_pool_categories_gin',
        'community_pool',
        ['categories'],
        postgresql_using='gin'
    )

    # 3. community_pool.description_keywords
    op.create_index(
        'idx_community_pool_keywords_gin',
        'community_pool',
        ['description_keywords'],
        postgresql_using='gin'
    )

def downgrade() -> None:
    op.drop_index('idx_community_pool_keywords_gin')
    op.drop_index('idx_community_pool_categories_gin')
    op.drop_index('idx_posts_hot_metadata_gin')
```

**执行步骤**:
```bash
# 1. 生成迁移文件
alembic revision -m "add_jsonb_gin_indexes"

# 2. 执行迁移 (使用 CONCURRENTLY 避免锁表)
alembic upgrade head

# 3. 验证索引
psql -d reddit_signal_scanner -c "\d posts_hot"
psql -d reddit_signal_scanner -c "\d community_pool"
```

**性能影响**:
- ✅ 查询性能提升 10-100倍 (JSONB查询)
- ⚠️ 索引创建时间: 取决于数据量
- ⚠️ 索引大小: 约为数据大小的 30-50%

---

#### Migration 3: 添加其他缺失索引

**文件**: `backend/alembic/versions/20251023_000020_add_missing_indexes.py`

```python
"""Add missing indexes for performance

Revision ID: 20251023_000020
Revises: 20251023_000019
Create Date: 2025-10-23
"""
from alembic import op

def upgrade() -> None:
    # 1. pending_communities.status (频繁查询)
    op.create_index(
        'idx_pending_communities_status',
        'pending_communities',
        ['status']
    )

    # 2. community_import_history.created_at (排序查询)
    op.create_index(
        'idx_community_import_history_created_at',
        'community_import_history',
        ['created_at']
    )

    # 3. crawl_metrics 复合索引 (按日期+小时查询)
    op.create_index(
        'idx_crawl_metrics_date_hour',
        'crawl_metrics',
        ['metric_date', 'metric_hour']
    )

def downgrade() -> None:
    op.drop_index('idx_crawl_metrics_date_hour')
    op.drop_index('idx_community_import_history_created_at')
    op.drop_index('idx_pending_communities_status')
```

---

### Phase 3: P2优化 (长期规划)

#### 优化1: 添加审计字段

**影响**: 需要修改模型定义,添加 `created_by`, `updated_by` 字段

**建议**: 新表遵循规范,旧表逐步迁移

#### 优化2: 添加软删除机制

**影响**: 需要修改所有删除逻辑,添加 `deleted_at` 字段

**建议**: 评估业务需求,优先级较低

#### 优化3: 统一时间戳字段

**影响**: 需要修改所有模型定义,统一使用 `TimestampMixin`

**建议**: 新表遵循规范,旧表逐步迁移

---

## 📊 性能优化预期

### 查询性能提升

| 优化项 | 影响查询 | 预期提升 | 优先级 |
|-------|---------|---------|--------|
| 外键索引 | Admin后台关联查询 | 10-50倍 | P0 |
| JSONB GIN索引 | 社区筛选、帖子元数据查询 | 10-100倍 | P1 |
| 复合索引 | 爬虫指标查询 | 5-20倍 | P1 |

### 数据完整性提升

| 优化项 | 影响 | 风险降低 | 优先级 |
|-------|-----|---------|--------|
| 外键约束 | 防止孤儿记录 | 100% | P0 |
| 级联删除 | 自动清理关联数据 | 90% | P0 |
| CHECK约束 | 防止无效数据 | 80% | P1 |

---

## ✅ 验收标准

### P0问题验收
- [ ] 所有外键约束已添加
- [ ] 所有外键列已添加索引
- [ ] 级联删除策略已配置
- [ ] 无孤儿记录存在
- [ ] MyPy --strict 通过
- [ ] 所有测试通过

### P1问题验收
- [ ] 所有JSONB字段已添加GIN索引
- [ ] 所有频繁查询列已添加索引
- [ ] 查询性能提升 10倍以上
- [ ] 数据库名称统一为 `reddit_signal_scanner`

### P2优化验收
- [ ] 新表遵循审计字段规范
- [ ] 新表遵循时间戳字段规范
- [ ] 文档已更新

---

## 📝 后续行动计划

### 立即执行 (本周)
1. ✅ 生成 Migration 1 (外键约束)
2. ✅ 执行数据清理脚本
3. ✅ 执行 Migration 1
4. ✅ 验证外键约束
5. ✅ 运行全量测试

### 近期执行 (下周)
6. ✅ 生成 Migration 2 (JSONB GIN索引)
7. ✅ 生成 Migration 3 (其他索引)
8. ✅ 执行 Migration 2-3
9. ✅ 性能测试验证

### 长期规划 (Phase 2)
10. 评估审计字段需求
11. 评估软删除需求
12. 制定统一规范文档

---

**报告生成时间**: 2025-10-23
**分析工具**: Serena MCP + Sequential Thinking + Exa Code
**下一步**: 执行 Phase 1 迁移计划

